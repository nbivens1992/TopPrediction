{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Formation Tops from Well Log Data using CNN\n",
    "\n",
    "CNNs are powerful tools for pattern recognition and feature extraction in various types of data, including images, time-series, and, in your case, geological log curve data. Here's why they are suitable for this task:\n",
    "\n",
    "<b>Feature Extraction:</b> CNNs can automatically learn and extract relevant features from the input data. In your scenario, the model can learn to identify patterns in gamma ray, resistivity, and density porosity curves that are indicative of formation tops.\n",
    "\n",
    "<b>Spatial Hierarchy:</b> CNNs can capture the hierarchical spatial structures present in the data. This is crucial for understanding the geological layers and their properties.\n",
    "\n",
    "<b>Translation Invariance:</b> CNNs are robust to shifts and distortions in the input data, which is beneficial when dealing with natural variations in geological formations.\n",
    "Efficient Parameter Usage: CNNs share weights across different parts of the input, making them more parameter-efficient compared to fully connected networks. This is especially useful when dealing with large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "from keras.layers import Normalization, Lambda\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam, Nadam\n",
    "from keras.regularizers import l2\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-Net Architecture\n",
    "\n",
    "The U-Net architecture is a type of convolutional neural network that was originally designed for biomedical image segmentation. The combination of global and local views in a U-Net architecture allows the model to understand both the broader context and the finer details of the input data, which is crucial for tasks like predicting formation tops in geological data. Here are common parts of a U-Net architecture\n",
    "- Contracting Path: The contracting path is similar to a typical convolutional network. It consists of repeated application of convolutions, followed by a rectified linear unit (ReLU) and a max pooling operation. With each downsampling step, the network increases the number of feature channels.\n",
    "\n",
    "- Expansive Path: The expansive path consists of upsampling of the feature map followed by a convolution (\"up-convolution\"), which halves the number of feature channels, a concatenation with the correspondingly cropped feature map from the contracting path, and two more convolutions, each followed by a ReLU. The cropping is necessary due to the loss of border pixels in every convolution.\n",
    "\n",
    "- Skip Connections: The key innovation in U-Net is the use of skip connections, where outputs from the contracting path are concatenated with inputs to the expansive path. These connections provide the expansive path with the context information lost during downsampling, which is crucial for precise localization.\n",
    "\n",
    "### Global View \n",
    "\n",
    "The global view in a U-Net architecture refers to the initial layers of the network where the input data is progressively downsampled (pooled). The purpose of the global view is to:\n",
    "\n",
    "<b>Capture Context:</b> By looking at the broader picture, the global view helps the model understand the overall context of the data. In geological terms, this might mean understanding the general trends and structures across a wide depth range.\n",
    "\n",
    "<b>Reduce Dimensionality:</b> Pooling layers reduce the spatial dimensions of the feature maps, which decreases the computational complexity and helps in focusing on the more salient features.\n",
    "\n",
    "<b>Increase Receptive Field:</b> As the data is downsampled, the receptive field of the neurons increases, allowing them to capture more global features that are relevant for the prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_module(input_tensor, filter_channels, dilation3x3=32, dilation5x5=24,dilation7x7=24):\n",
    "    \n",
    "    # Branch 1: 1x1 conv\n",
    "    branch1x1 = layers.Conv1D(filter_channels, 1, padding='same', activation='relu')(input_tensor)\n",
    "    \n",
    "    # Branch 2: 1x1 conv followed by 3x3 conv\n",
    "    branch3x3 = layers.Conv1D(filter_channels, 1, padding='same', activation='relu')(input_tensor)\n",
    "    branch3x3 = layers.Conv1D(filter_channels, 3, padding='same', activation='relu', dilation_rate=dilation3x3)(branch3x3)\n",
    "    \n",
    "    # Branch 2: 1x1 conv followed by 3x3 conv\n",
    "    branch5x5 = layers.Conv1D(filter_channels//2, 1, padding='same', activation='relu')(input_tensor)\n",
    "    branch5x5 = layers.Conv1D(filter_channels//2, 5, padding='same', activation='relu', dilation_rate=dilation5x5)(branch5x5)\n",
    "    \n",
    "    pool3x3 = layers.AveragePooling1D(pool_size=3, strides=1, padding='same')(input_tensor)\n",
    "    pool3x3 = layers.Conv1D(filter_channels//2, 1, padding='same', activation='relu')(pool3x3)\n",
    "\n",
    "    \n",
    "    # Branch 2: 1x1 conv followed by 3x3 conv\n",
    "    branch7x7 = layers.Conv1D(filter_channels//2, 1, padding='same', activation='relu')(input_tensor)\n",
    "    branch7x7 = layers.Conv1D(filter_channels//2, 7, padding='same', activation='relu', dilation_rate= dilation7x7)(branch7x7)\n",
    "    \n",
    "        \n",
    "    # Concatenate all the branches\n",
    "    concatenated = layers.Concatenate(axis=-1)([ branch3x3, branch5x5,branch1x1,pool3x3,branch7x7])\n",
    "    \n",
    "    return concatenated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_global_view(initial_layer = 4, dropout = 0.5, dilation3x3 =1,dilation5x5=1,dilation7x7=1):\n",
    "    inputs = layers.Input(shape=(None, 4))  # Assuming the logs are 1D sequences\n",
    "    x = layers.Masking(mask_value=-99)(inputs)  # Using -99 as the mask value\n",
    "    \n",
    "    \n",
    "    # Encoding layer 1\n",
    "    conv1 = inception_module(x, initial_layer, dilation3x3=dilation3x3, dilation5x5=dilation5x5,dilation7x7=dilation7x7)\n",
    "    conv1 = layers.BatchNormalization()(conv1)\n",
    "    conv1 = layers.Dropout(dropout)(conv1)\n",
    "    pool1 = layers.AveragePooling1D()(conv1)\n",
    "\n",
    "    # Encoding layer 2\n",
    "    conv2 = inception_module(pool1, initial_layer*2, dilation3x3=dilation3x3, dilation5x5=dilation5x5,dilation7x7=dilation7x7)\n",
    "    conv2 = layers.BatchNormalization()(conv2)\n",
    "    conv2 = layers.Dropout(dropout)(conv2)\n",
    "    pool2 = layers.AveragePooling1D()(conv2)\n",
    "\n",
    "    # Middle layer\n",
    "    conv_middle = inception_module(pool2,initial_layer*4, dilation3x3=dilation3x3, dilation5x5=dilation5x5,dilation7x7=dilation7x7)\n",
    "    conv_middle = layers.BatchNormalization()(conv_middle)\n",
    "    conv_middle = layers.Dropout(dropout)(conv_middle)\n",
    "    \n",
    "\n",
    "    # Decoding layer 1\n",
    "    up1 = layers.UpSampling1D()(conv_middle)\n",
    "    merge1 = layers.concatenate([conv2, up1]) \n",
    "    decode1 = inception_module(merge1,initial_layer*2, dilation3x3=dilation3x3, dilation5x5=dilation5x5,dilation7x7=dilation7x7)\n",
    "    decode1 = layers.BatchNormalization()(decode1)\n",
    "    decode1 = layers.Dropout(dropout)(decode1)\n",
    "    \n",
    "    \n",
    "    # Decoding layer 2\n",
    "    up2 = layers.UpSampling1D()(decode1)\n",
    "    merge2 = layers.concatenate([conv1, up2])\n",
    "    decode2 = inception_module(merge2, initial_layer, dilation3x3=dilation3x3, dilation5x5=dilation5x5,dilation7x7=dilation7x7)\n",
    "    decode2 = layers.BatchNormalization()(decode2)\n",
    "    decode2 = layers.Dropout(dropout)(decode2)\n",
    "    \n",
    "    # output = layers.Activation(activation=\"tanh\")(decode2)\n",
    "\n",
    "    return models.Model(inputs, decode2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local View\n",
    "\n",
    "The local view, are specialized layers like inception modules with dilated convolutions, focuses on finer details. Its purposes include:\n",
    "\n",
    "Detail Preservation: The local view helps in preserving and highlighting the finer details and local features that might be crucial for accurate prediction of formation tops.\n",
    "High-Resolution Feature Maps: As the data is upsampled or processed through dilated convolutions, the feature maps regain their resolution, allowing the model to make more precise localizations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_local_view(initial_filters=2, input_shape=(None, 4), mask_value=-99, dilation3x3 =32,dilation5x5=24,dilation7x7=24):\n",
    "    # Input layer\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Masking layer\n",
    "    x = layers.Masking(mask_value=mask_value)(inputs)\n",
    "    \n",
    "    conv1 = inception_module(x,initial_filters, dilation3x3=dilation3x3, dilation5x5=dilation5x5,dilation7x7=dilation7x7)\n",
    "    # conv1 = layers.BatchNormalization()(conv1)\n",
    "    # conv1 = layers.Dropout(0.5)(conv1)\n",
    "    \n",
    "    conv2 = inception_module(conv1,initial_filters, dilation3x3=dilation3x3, dilation5x5=dilation5x5,dilation7x7=dilation7x7)\n",
    "    # conv2 = layers.BatchNormalization()(conv2)\n",
    "    # conv2 = layers.Dropout(0.5)(conv2)\n",
    "    \n",
    "    # conv3 = inception_module(conv2,initial_filters, dilation3x3=dilation3x3, dilation5x5=dilation5x5,dilation7x7=dilation7x7)\n",
    "    # conv3 = layers.BatchNormalization()(conv3)\n",
    "    # conv3 = layers.Dropout(0.5)(conv3)\n",
    "    \n",
    "    # conv4 = inception_module(conv3,initial_filters, dilation3x3=dilation3x3, dilation5x5=dilation5x5,dilation7x7=dilation7x7)\n",
    "    # conv4 = layers.BatchNormalization()(conv4)\n",
    "    # conv4 = layers.Dropout(0.5)(conv4)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return models.Model(inputs, conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation for U-Net Model\n",
    "\n",
    "Our U-Net model requires the input data to adhere to specific dimensional constraints for it to process the data effectively. To ensure compatibility with the model's architecture, we perform the following preprocessing steps on each well's log data:\n",
    "\n",
    "### Normalization\n",
    "Firstly, we normalize the data to ensure that the model receives inputs that are on a similar scale. This is crucial for the model's convergence and performance. The normalization is performed using the following formula:\n",
    "\n",
    "$$ \\text{normalized\\_data} = \\frac{\\text{data} - \\text{mean}}{\\text{std}} $$\n",
    "\n",
    "where `mean` and `std` are the mean and standard deviation of the training data, respectively.\n",
    "\n",
    "### Ensuring Even Length\n",
    "The U-Net architecture involves multiple layers of downsampling and upsampling. To avoid any off-by-one errors during these operations, we need to ensure that the input data's length is even and remains even when divided by 2 and 4. We achieve this by:\n",
    "\n",
    "1. **Appending Padding**: If the sequence length is odd, we append a padding row to make it even. This padding is set to a specific value (e.g., -99) that the model can recognize and ignore during processing.\n",
    "\n",
    "2. **Adjusting Maximum Length**: We calculate the maximum length across all sequences and adjust it to ensure that it is even and divisible by 2 and 4. This adjustment is necessary to maintain the integrity of the data's spatial dimensions throughout the U-Net's downsampling and upsampling pathways.\n",
    "\n",
    "3. **Padding to Maximum Length**: Finally, we pad all sequences to this adjusted maximum length. This uniformity is essential for batch processing and allows the model to process multiple sequences simultaneously.\n",
    "\n",
    "By adhering to these preprocessing steps, we ensure that our U-Net model receives well-formatted input data, which is crucial for accurate predictions. The padding added during these steps is carefully handled by the model and does not significantly impact its predictive performance.\n",
    "\n",
    "### Gaussian Smoothing\n",
    "Gaussian smoothing is a technique that is particularly useful for addressing data imbalance issues in machine learning tasks, especially when dealing with time series or spatial data. When you have a dataset with a binary classification problem and one class (like well top selection) is significantly underrepresented, this can lead to a model that doesn't perform well on the minority class because it hasn't had enough examples to learn from. This will create a gaussian kernal around the top selection to help make the mdoel mroe accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "In this section, we define and train our U-Net model for the task of predicting formation tops in geological data. The model utilizes a combination of global and local views to capture both the broader context and fine details necessary for accurate predictions.\n",
    "\n",
    "### Binary Cross entropy\n",
    "\n",
    "Binary Cross-Entropy, also known as log loss, measures the performance of a classification model whose output is a probability value between 0 and 1. It's a commonly used loss function for binary classification tasks. Binary Cross-Entropy loss increases as the predicted probability diverges from the actual label, being more punitive for predictions that are confidently incorrect.\n",
    "\n",
    "### Model Architecture\n",
    "\n",
    "The model architecture combines the outputs of the global and local views using a multiplication operation. This combined output is then passed through a soft attention mechanism, implemented using a tanh activation function, to highlight the regions of interest. The final output is obtained using a 1D convolutional layer with a sigmoid activation function, which provides the probability of a formation top at each depth.\n",
    "\n",
    "### Training Process\n",
    "The model is trained using the Adam optimizer and the focal loss function. We employ an early stopping mechanism to prevent overfitting, where training is halted if the validation loss does not improve for a specified number of epochs (patience). The training and validation losses are plotted at the end of the training process to visualize the model's learning progress.\n",
    "\n",
    "During training, each well's log data is processed in batches. The model is trained on each batch, and the losses are recorded. The training loop also includes a validation step to monitor the model's performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, X_val, y_val, learning_rate, epochs, nodes, dropout, dilation3x3 =32,dilation5x5=24,dilation7x7=24):\n",
    "    global_view = create_global_view(initial_layer=nodes,dropout = dropout, dilation3x3=dilation3x3, dilation5x5=dilation5x5,dilation7x7=dilation7x7)\n",
    "    local_view = create_local_view(initial_filters=nodes)\n",
    "    \n",
    "    global_output = global_view.output\n",
    "    local_output = local_view.output\n",
    "     \n",
    "    # Apply tanh activation to both global and local views\n",
    "    activated_global_view = layers.Activation('tanh')(global_output)\n",
    "    \n",
    "    \n",
    "    activated_local_view = local_output\n",
    "\n",
    "    # Element-wise multiplication of the activated global and local views\n",
    "    combined_features = layers.Multiply()([activated_global_view, activated_local_view])\n",
    "    \n",
    "\n",
    "    # HYPERPARAMETER: Adjust the number of filters (1) and kernel size (1)\n",
    "    output = layers.Conv1D(1, 1, activation=\"sigmoid\")(combined_features)\n",
    "    \n",
    "    \n",
    "    # output = layers.Conv1D(1, 1, activation=\"sigmoid\")(activated_local_view)\n",
    "\n",
    "    model = models.Model([global_view.input, local_view.input], output)\n",
    "    \n",
    "    # model = models.Model([local_view.input], output)\n",
    "    \n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    # optimizer = Nadam()\n",
    "    \n",
    "    # HYPERPARAMETER: Adjust the optimizer ('adam') and its parameters\n",
    "    model.compile(optimizer=optimizer, loss= tf.losses.BinaryCrossentropy())\n",
    "\n",
    "\n",
    "    # Early stopping parameters\n",
    "    patience = 5\n",
    "    min_delta = 0.001\n",
    "    best_val_loss = float('inf')\n",
    "    wait = 0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    # We'll only use this training loop and remove the redundant one.\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        \n",
    "        # Training\n",
    "        epoch_train_losses = []\n",
    "        for i in range(len(X_train)):\n",
    "            X_train_well = X_train[i].reshape(1, X_train[i].shape[0], X_train[i].shape[1])\n",
    "            y_train_well = y_train[i].reshape(1, y_train[i].shape[0], 1)\n",
    "           \n",
    "            loss = model.train_on_batch([X_train_well, X_train_well], y_train_well)  # Capturing the loss\n",
    "            # loss = model.train_on_batch([X_train_well], y_train_well)  # Capturing the loss\n",
    "            epoch_train_losses.append(loss)\n",
    "        mean_train_loss = np.mean(epoch_train_losses)\n",
    "        train_losses.append(np.mean(mean_train_loss))\n",
    "\n",
    "        # Validation (optional)\n",
    "        epoch_val_losses = []\n",
    "        for i in range(len(X_val)):\n",
    "            X_val_well = X_val[i].reshape(1, X_val[i].shape[0], X_val[i].shape[1])\n",
    "            y_val_well = y_val[i].reshape(1, y_val[i].shape[0], 1)\n",
    "            loss = model.test_on_batch([X_val_well, X_val_well], y_val_well)\n",
    "            # loss = model.test_on_batch([X_val_well], y_val_well)\n",
    "            epoch_val_losses.append(loss)\n",
    "        mean_val_loss = np.mean(epoch_val_losses)\n",
    "        val_losses.append(mean_val_loss)\n",
    "        print(f\"Training Loss: {train_losses[-1]:.5f}, Validation Loss: {mean_val_loss:.5f}\")\n",
    "\n",
    "        # Early stopping check\n",
    "        if (best_val_loss - mean_val_loss) > min_delta:\n",
    "            best_val_loss = mean_val_loss\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}. Best validation loss: {best_val_loss:.5f}\")\n",
    "                break\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label=\"Training Loss\")\n",
    "    plt.plot(val_losses, label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training and Validation Loss Curves\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def normalize_data(np_array):\n",
    "#     # Replace 'inf' with 'NaN' (if needed)\n",
    "#     np_array[np_array == np.inf] = np.nan\n",
    "#     np_array[np_array == -np.inf] = np.nan\n",
    "\n",
    "#     # Impute NaN values with the minimum non-NaN value in each column\n",
    "#     for i in range(np_array.shape[1]):  # Iterate over columns\n",
    "#         min_non_nan = np.nanmin(np_array[:, i])\n",
    "#         np_array[:, i] = np.nan_to_num(np_array[:, i], nan=min_non_nan)\n",
    "\n",
    "#     # Compute mean and std dev, avoiding division by zero\n",
    "#     mean = np.mean(np_array, axis=0)\n",
    "#     std = np.std(np_array, axis=0)\n",
    "#     std[std == 0] = 1  # Set 0 std dev to 1 to avoid division by zero\n",
    "\n",
    "#     # Normalize data\n",
    "#     normalized_array = (np_array - mean) / std\n",
    "\n",
    "#     return normalized_array\n",
    "\n",
    "def normalize_data(df, features):\n",
    "    # Compute mean and std only for specified features\n",
    "    mean = df[features].mean()\n",
    "    std = df[features].std()\n",
    "\n",
    "    # Apply normalization only to the specified features\n",
    "    df[features] = (df[features] - mean) / std\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def ensure_power_of_2_length(sequence, padding_value=-99):\n",
    "    current_rows = sequence.shape[0]\n",
    "\n",
    "    # Calculate the number of rows needed to make it a power of 2\n",
    "    if current_rows != 0:\n",
    "        power_of_2 = 2 ** int(np.ceil(np.log2(current_rows)))\n",
    "    else:\n",
    "        power_of_2 = 1\n",
    "\n",
    "    rows_needed_to_multiple_of_2 = power_of_2 - current_rows\n",
    "\n",
    "    # Determine the total rows needed\n",
    "    total_rows_needed = rows_needed_to_multiple_of_2\n",
    "\n",
    "    if total_rows_needed > 0:\n",
    "        # Create padding with the same number of columns as the sequence\n",
    "        padding_shape = (total_rows_needed,) + sequence.shape[1:]\n",
    "        padding = np.full(padding_shape, padding_value)\n",
    "\n",
    "        # Append padding to the sequence\n",
    "        sequence = np.vstack([sequence, padding])\n",
    "\n",
    "    return sequence\n",
    "\n",
    "def pad_to_max_length(sequence, max_length, padding_value=-99):\n",
    "    padding = [(0, max_length - sequence.shape[0]), (0, 0)]\n",
    "    return np.pad(sequence, padding, mode='constant', constant_values=padding_value)\n",
    "\n",
    "\n",
    "def adjust_max_length(max_length):\n",
    "    last_digit = max_length % 10\n",
    "    \n",
    "    if last_digit in [2, 6]:\n",
    "        return max_length + 2\n",
    "    elif last_digit == 0:\n",
    "        return max_length + 4\n",
    "    else:\n",
    "        return max_length\n",
    "    \n",
    "def smooth_labels(y, sigma=2):\n",
    "    # Ensure y is a 1D array\n",
    "    y = y.flatten()\n",
    "    smoothed_y = np.zeros_like(y, dtype=float)\n",
    "    for idx in np.where(y == 1)[0]:\n",
    "        gaussian = np.exp(-0.5 * ((np.arange(len(y)) - idx) / sigma) ** 2)\n",
    "        gaussian /= gaussian.sum()\n",
    "        smoothed_y += 5.1*gaussian  # Both are 1D arrays, so this should work\n",
    "    smoothed_y = np.clip(smoothed_y, None, 1)\n",
    "    return smoothed_y\n",
    "\n",
    "def pad_np_array(np_array, desired_length, padding_value=-99):\n",
    "    # Calculate the number of rows to add\n",
    "    num_rows_to_add = desired_length - np_array.shape[0]\n",
    "\n",
    "    # If the array is already longer or equal to the desired length, return the original array\n",
    "    if num_rows_to_add <= 0:\n",
    "        return np_array\n",
    "\n",
    "    # Create a new array with the required number of rows filled with the padding value\n",
    "    padding_array = np.full((num_rows_to_add, np_array.shape[1]), padding_value)\n",
    "\n",
    "    # Concatenate the original array with the padding array\n",
    "    padded_array = np.concatenate([np_array, padding_array], axis=0)\n",
    "\n",
    "    return padded_array\n",
    "\n",
    "def pad_dataframe(df, desired_length, padding_value=-99):\n",
    "    # Calculate the number of rows to add\n",
    "    num_rows_to_add = desired_length - len(df)\n",
    "    \n",
    "    # If the dataframe is already longer or equal to the desired length, return the original dataframe\n",
    "    if num_rows_to_add <= 0:\n",
    "        return df\n",
    "    \n",
    "    # Create a new dataframe with the required number of rows filled with the padding value\n",
    "    padding_df = pd.DataFrame(padding_value, index=range(num_rows_to_add), columns=df.columns)\n",
    "    \n",
    "    # Concatenate the original dataframe with the padding dataframe\n",
    "    padded_df = pd.concat([df, padding_df], axis=0).reset_index(drop=True)\n",
    "    \n",
    "    return padded_df\n",
    "\n",
    "def check_for_nans(array, name=\"Array\"):\n",
    "    if isinstance(array, list):\n",
    "        # Handle case where array is a list of arrays\n",
    "        for i, arr in enumerate(array):\n",
    "            if np.isnan(arr).any():\n",
    "                nan_rows = np.any(np.isnan(arr), axis=1)\n",
    "                print(f\"NaNs found in {name} at array index {i}. Rows with NaNs:\")\n",
    "                print(arr[nan_rows])\n",
    "    else:\n",
    "        # Handle case where array is a single NumPy array\n",
    "        if np.isnan(array).any():\n",
    "            nan_rows = np.any(np.isnan(array), axis=1)\n",
    "            print(f\"NaNs found in {name}. Rows with NaNs:\")\n",
    "            print(array[nan_rows])\n",
    "            \n",
    "            \n",
    "def check_for_nans_in_dataframe(df, name=\"DataFrame\"):\n",
    "    # Check if the DataFrame contains any NaN values\n",
    "    if df.isna().any().any():\n",
    "        # Get rows which contain NaNs\n",
    "        rows_with_nans = df[df.isna().any(axis=1)]\n",
    "        print(f\"NaNs found in {name}. Rows with NaNs:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(folder_path):\n",
    "    files = [f for f in os.listdir(folder_path) if f.endswith(\".csv\")]\n",
    "\n",
    "    max_length = 0\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        df = pd.read_csv(folder_path + file)\n",
    "        if len(df.index)>max_length:\n",
    "            max_length = len(df.index)\n",
    "        check_for_nans_in_dataframe(df,name = file)\n",
    "        dfs.append(df)\n",
    "    \n",
    "    \n",
    "    train_dfs, val_dfs = train_test_split(dfs, test_size=0.2, random_state=42) # Here 20% of the data is kept for validation\n",
    "\n",
    "    features = [\"VSH\", \"RESD\", \"DPHI\", \"NPHI\"]\n",
    "    \n",
    "    # Normalize data \n",
    "    train_dfs = [normalize_data(df,features) for df in train_dfs]\n",
    "    val_dfs = [normalize_data(df,features) for df in val_dfs]\n",
    "    \n",
    "    # The CNN model requires each well log to be of the same shape and the shape needs to be a multiple of 8 or it will cause an error\n",
    "    \n",
    "    # Pad to max_length with -99 as none of the logs will have this as a value\n",
    "    train_dfs = [pad_dataframe(df, max_length) for df in train_dfs]\n",
    "    val_dfs = [pad_dataframe(df, max_length) for df in val_dfs]\n",
    "    \n",
    "\n",
    "    # Extract features and labels for training and validation sets\n",
    "    X_train = np.array([df[features].values for df in train_dfs])\n",
    "    y_train = np.array([df[\"Pick\"].values for df in train_dfs])\n",
    "\n",
    "    X_val = np.array([df[features].values for df in val_dfs])\n",
    "    y_val = np.array([df[\"Pick\"].values for df in val_dfs])\n",
    "    \n",
    "    # Ensure the input is not only even but a multiple of 8 so that the CNN Model can handle it. NOTE that that afterwards there might be a new max length\n",
    "    X_train = [ensure_power_of_2_length(x) for x in X_train]\n",
    "    X_val = [ensure_power_of_2_length(x) for x in X_val]\n",
    "\n",
    "    # Compute max_length again after ensuring a multiple of 8 lengths. \n",
    "    max_length2 = max(max(x.shape[0] for x in X_train), max(x.shape[0] for x in X_val))\n",
    "\n",
    "    # Pad to new max_length\n",
    "    X_train = [pad_to_max_length(x, max_length2) for x in X_train]\n",
    "    X_val = [pad_to_max_length(x, max_length2) for x in X_val]\n",
    "\n",
    "    # apply gaussian kernal to y values\n",
    "    y_train = [smooth_labels(y) for y in y_train]\n",
    "    y_val = [smooth_labels(y) for y in y_val]\n",
    "\n",
    "    # Ensure even length for labels and then pad\n",
    "    y_train = [ensure_power_of_2_length(y.reshape(-1, 1),padding_value=0) for y in y_train]\n",
    "    y_val = [ensure_power_of_2_length(y.reshape(-1, 1),padding_value=0) for y in y_val]\n",
    "    \n",
    "    \n",
    "    # Now we need to pad the y values. The y values will be padded with 0 as they are not the picks\n",
    "    y_train = [pad_to_max_length(y, max_length2,padding_value=0) for y in y_train]\n",
    "    y_val = [pad_to_max_length(y, max_length2,padding_value=0) for y in y_val]\n",
    "    \n",
    "    [check_for_nans(x, \"X_train array \"+ str(i)) for i, x in enumerate(X_train)]\n",
    "    [check_for_nans(x, \"X_val array \" + str(i)) for i, x in enumerate(X_val)]\n",
    "    [check_for_nans(x, \"y_train array \" + str(i)) for i, x in enumerate(y_train)]\n",
    "    [check_for_nans(x, \"y_val array \" + str(i)) for i, x in enumerate(y_val)]\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data(folder_path):\n",
    "    files = [f for f in os.listdir(folder_path) if f.endswith(\".csv\")]\n",
    "    test_dfs = []\n",
    "    max_length = 0\n",
    "    for file in files:\n",
    "        df = pd.read_csv(folder_path + file)\n",
    "        if len(df.index)>max_length:\n",
    "            max_length = len(df.index)\n",
    "        test_dfs.append(df)\n",
    "\n",
    "    features = [\"VSH\", \"RESD\", \"DPHI\", \"NPHI\"]\n",
    "    \n",
    "    # Normalize data\n",
    "    \n",
    "    test_dfs = [normalize_data(df,features) for df in test_dfs]\n",
    "    \n",
    "    # The CNN model requires each well log to be of the same shape and the shape needs to be a multiple of 8 or it will cause an error\n",
    "    \n",
    "    # Pad INPUT to max_length with -99 as none of the logs will have this as a value\n",
    "    \n",
    "    test_dfs = [pad_dataframe(df, max_length) for df in test_dfs]\n",
    "    \n",
    "    # Extract features and labels for training and validation sets\n",
    "    X_test = np.array([df[features].values for df in test_dfs])\n",
    "    y_test = np.array([df[\"Pick\"].values for df in test_dfs])\n",
    "\n",
    "    # Ensure multiple of 8 for UNET\n",
    "    X_test = [ensure_power_of_2_length(x) for x in X_test]\n",
    "    \n",
    "    # Compute NEW max_length after ensuring lengths OF MULTIPLE OF 8\n",
    "    max_length2 = max(x.shape[0] for x in X_test)\n",
    "    \n",
    "    # Pad to max_length\n",
    "    X_test = [pad_to_max_length(x, max_length2) for x in X_test]\n",
    "    \n",
    "    # apply gaussian kernal to y values\n",
    "    y_test = [smooth_labels(y) for y in y_test]\n",
    "    \n",
    "    # Ensure even length for labels and then pad\n",
    "    y_test = [ensure_power_of_2_length(y.reshape(-1, 1),padding_value=0) for y in y_test]\n",
    "    \n",
    "    y_test = [pad_to_max_length(y, max_length2,padding_value=0) for y in y_test]\n",
    "    \n",
    "    test_dfs = [pad_dataframe(df, max_length2,padding_value=-99) for df in test_dfs]\n",
    "    \n",
    "    # # Update the 'Pick' column in test_dfs with y_test values\n",
    "    # for i, df in enumerate(test_dfs):\n",
    "    #     df['Pick'] = y_test[i][:len(df)]  # Assuming y_test[i] is already the correct length\n",
    "    \n",
    "    [check_for_nans(x, \"X_test \" + str(i)) for i, x in enumerate(X_test)]\n",
    "    [check_for_nans(x, \"y_test \" + str(i)) for i, x in enumerate(y_test)]\n",
    "    \n",
    "    return X_test, y_test, test_dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(test_df, X_test,y_test, model, formation_test_data):\n",
    "    x_reshape = X_test.reshape(1, X_test.shape[0], X_test.shape[1])\n",
    "    predictions = model.predict([x_reshape, x_reshape])\n",
    "    # predictions = model.predict([x_reshape])\n",
    "    \n",
    "    # Flatten the predictions to 1D array for easier indexing\n",
    "    predictions_flat = predictions.flatten()\n",
    "    \n",
    "    # Initialize binary_predictions to all zeros\n",
    "    binary_predictions = np.zeros_like(predictions_flat, dtype=int)\n",
    "    \n",
    "    # Find the index of the maximum prediction probability\n",
    "    max_prob_index = np.argmax(predictions_flat)\n",
    "    \n",
    "    # Set only the max index to 1\n",
    "    binary_predictions[max_prob_index] = 1\n",
    "    \n",
    "    test_df['Binary_Predict'] = binary_predictions.flatten()\n",
    "    test_df['Predict'] = predictions.flatten()\n",
    "    test_df['Acutal Pick']=y_test.flatten()\n",
    "    name=test_df['SitID'][0]\n",
    "    \n",
    "    os.makedirs(formation_test_data+\"/Predictions\", exist_ok=True)\n",
    "    # Save the DataFrame as a CSV file\n",
    "    output_path = os.path.join(formation_test_data+\"/Predictions\", f\"predictions_{name}.csv\")\n",
    "    test_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation on Test Data\n",
    "\n",
    "After training our model, it's crucial to evaluate its performance on data that it has never seen before, also known as the test data. This step helps us understand how well the model generalizes to new, unseen examples. We use several metrics for this evaluation: Precision, Recall, and the F1 Score.\n",
    "\n",
    "### Evaluation Metrics\n",
    "\n",
    "- **Precision**: This metric tells us the proportion of positive identifications that were actually correct. It is defined as the number of true positives divided by the number of true positives plus the number of false positives.\n",
    "\n",
    "- **Recall**: Also known as sensitivity, this metric tells us the proportion of actual positives that were identified correctly. It is defined as the number of true positives divided by the number of true positives plus the number of false negatives.\n",
    "\n",
    "- **F1 Score**: This is the harmonic mean of Precision and Recall and gives a combined measure of the two metrics. It is particularly useful when the class distribution is imbalanced.\n",
    "\n",
    "### Tolerance Window (`delta_T_depth`)\n",
    "\n",
    "Due to the nature of geological data, the exact pinpointing of formation tops might not be feasible. Therefore, we introduce a tolerance window, `delta_T_depth`, which allows for a small margin of error in the predictions based on depth values (e.g., meters). This tolerance window accounts for the fact that the model's predictions might be a few meters away from the actual formation tops.\n",
    "\n",
    "### Evaluation Process\n",
    "\n",
    "We loop over different values of `delta_T_depth` to understand how the model's performance varies with different levels of strictness in the predictions. For each `delta_T_depth` value, we calculate the Precision, Recall, and F1 Score for each well log in the test dataset based on the depth values. We then compute the average of these metrics across all well logs to get an overall understanding of the model's performance.\n",
    "\n",
    "The code snippet below demonstrates this evaluation process based on depth values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(test_dfs):\n",
    "    metrics_at_delta_T = {}\n",
    "    # Initialize lists to store metrics for each well log\n",
    "    all_precisions = []\n",
    "    all_recalls = []\n",
    "    all_F1_scores = []\n",
    "\n",
    "    # Define the different delta_T values in terms of depth (e.g., meters)\n",
    "    delta_T_depth_values = [0.5, 1, 2, 3, 6]  # Example values in meters\n",
    "\n",
    "    # Loop over each delta_T value\n",
    "    for delta_T_depth in delta_T_depth_values:\n",
    "        # Initialize lists to store metrics for each well log\n",
    "        all_precisions = []\n",
    "        all_recalls = []\n",
    "        all_F1_scores = []\n",
    "\n",
    "        # Loop over each well log\n",
    "        for i in range(len(test_dfs)):\n",
    "            ground_truth_depths = test_dfs[i].loc[test_dfs[i]['Pick'] == 1, 'DEPT']  # Depths of actual formation tops\n",
    "            prediction_depths = test_dfs[i].loc[test_dfs[i]['Binary_Predict'] == 1, 'DEPT']  # Depths of predicted formation tops\n",
    "\n",
    "            # 2. Precision\n",
    "            true_positives = sum(np.any(np.abs(gt_depth - prediction_depths) <= delta_T_depth) for gt_depth in ground_truth_depths)\n",
    "            prec = true_positives / len(prediction_depths) if len(prediction_depths) > 0 else 0\n",
    "            all_precisions.append(prec)\n",
    "\n",
    "            # 3. Recall\n",
    "            detected_tops = sum(np.any(np.abs(gt_depth - prediction_depths) <= delta_T_depth) for gt_depth in ground_truth_depths)\n",
    "            rec = detected_tops / len(ground_truth_depths) if len(ground_truth_depths) > 0 else 0\n",
    "            all_recalls.append(rec)\n",
    "\n",
    "            # 4. F1 Score\n",
    "            if prec + rec > 0:  # Avoid division by zero\n",
    "                F1 = 2 * (prec * rec) / (prec + rec)\n",
    "            else:\n",
    "                F1 = 0\n",
    "            all_F1_scores.append(F1)\n",
    "\n",
    "        # Compute average metrics across all well logs\n",
    "        average_precision = np.mean(all_precisions)\n",
    "        average_recall = np.mean(all_recalls)\n",
    "        average_F1_score = np.mean(all_F1_scores)\n",
    "\n",
    "        # Print the average metrics for the current delta_T_depth\n",
    "        print(f\"Metrics for delta_T_depth = {delta_T_depth}m:\")\n",
    "        print(\"Average Precision:\", average_precision)\n",
    "        print(\"Average Recall:\", average_recall)\n",
    "        print(\"Average F1 Score:\", average_F1_score)\n",
    "        print(\"----------\")\n",
    "        \n",
    "         # Store the metrics for the current delta_T_depth in the dictionary\n",
    "        metrics_at_delta_T[delta_T_depth] = {\n",
    "            'average_precision': average_precision,\n",
    "            'average_recall': average_recall,\n",
    "            'average_f1': average_F1_score\n",
    "        }\n",
    "    return metrics_at_delta_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1000', '2000', '3000', '4000', '5000', '6000', '7000', '9000', '9500', '10000', '11000', '12000', '13000', '14000']\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "# Train your model here\n",
    "folder_path = current_dir + \"/Data/Formation_DATA/\"\n",
    "\n",
    "formations = os.listdir(folder_path)\n",
    "formations = sorted(formations, key=lambda x: int(x))\n",
    "print(formations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def check_for_nans(array, name=\"Array\"):\n",
    "# #     if isinstance(array, list):\n",
    "# #         # Handle case where array is a list of arrays\n",
    "# #         for i, arr in enumerate(array):\n",
    "# #             if np.isnan(arr).any():\n",
    "# #                 nan_indices = np.argwhere(np.isnan(arr))\n",
    "# #                 print(f\"NaNs found in {name} at array index {i}, positions:\\n {nan_indices}\")\n",
    "# #     else:\n",
    "# #         # Handle case where array is a single NumPy array\n",
    "# #         if np.isnan(array).any():\n",
    "# #             nan_indices = np.argwhere(np.isnan(array))\n",
    "# #             print(f\"NaNs found in {name}, positions: {nan_indices}\")\n",
    "\n",
    "# for formation in formations:\n",
    "#     print(f\"formation: {formation}\")\n",
    "#     # Get training data\n",
    "#     formation_train_data = folder_path + f'{formation}/train/'\n",
    "#     X_train, y_train, X_val, y_val = get_train_data(formation_train_data)\n",
    "    \n",
    "#     # # Check for NaNs in training data\n",
    "#     # check_for_nans(X_train, \"X_train\")\n",
    "#     # check_for_nans(y_train, \"y_train\")\n",
    "#     # check_for_nans(X_val, \"X_val\")\n",
    "#     # check_for_nans(y_val, \"y_val\")\n",
    "\n",
    "#     # Get test data\n",
    "#     formation_test_data = folder_path + f'/{formation}/test/'\n",
    "#     X_test, y_test, test_dfs = get_test_data(formation_test_data)\n",
    "    \n",
    "#     # # Check for NaNs in test data\n",
    "#     # check_for_nans(X_test, \"X_test\")\n",
    "#     # check_for_nans(y_test, \"y_test\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting trainging for formation: 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "Training Loss: 0.29862, Validation Loss: 0.10916\n",
      "Epoch 2/200\n",
      "Training Loss: 0.05417, Validation Loss: 0.01948\n",
      "Epoch 3/200\n",
      "Training Loss: 0.02936, Validation Loss: 0.01641\n",
      "Epoch 4/200\n",
      "Training Loss: 0.02229, Validation Loss: 0.01490\n",
      "Epoch 5/200\n",
      "Training Loss: 0.01864, Validation Loss: 0.01339\n",
      "Epoch 6/200\n",
      "Training Loss: 0.01590, Validation Loss: 0.01179\n",
      "Epoch 7/200\n",
      "Training Loss: 0.01448, Validation Loss: 0.01102\n",
      "Epoch 8/200\n",
      "Training Loss: 0.01294, Validation Loss: 0.01038\n",
      "Epoch 9/200\n",
      "Training Loss: 0.01193, Validation Loss: 0.00979\n",
      "Epoch 10/200\n",
      "Training Loss: 0.01133, Validation Loss: 0.00997\n",
      "Epoch 11/200\n",
      "Training Loss: 0.01056, Validation Loss: 0.01010\n",
      "Epoch 12/200\n",
      "Training Loss: 0.00974, Validation Loss: 0.00938\n",
      "Epoch 13/200\n",
      "Training Loss: 0.00970, Validation Loss: 0.00912\n",
      "Epoch 14/200\n",
      "Training Loss: 0.00895, Validation Loss: 0.00938\n",
      "Epoch 15/200\n",
      "Training Loss: 0.00861, Validation Loss: 0.00938\n",
      "Epoch 16/200\n",
      "Training Loss: 0.00855, Validation Loss: 0.00982\n",
      "Epoch 17/200\n",
      "Training Loss: 0.00822, Validation Loss: 0.00991\n",
      "Early stopping at epoch 17. Best validation loss: 0.00938\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\nicholas.bivens_geot\\school\\TopPrediction/Model/1000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\nicholas.bivens_geot\\school\\TopPrediction/Model/1000/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Metrics for delta_T_depth = 0.5m:\n",
      "Average Precision: 0.7\n",
      "Average Recall: 0.7\n",
      "Average F1 Score: 0.7\n",
      "----------\n",
      "Metrics for delta_T_depth = 1m:\n",
      "Average Precision: 0.76\n",
      "Average Recall: 0.76\n",
      "Average F1 Score: 0.76\n",
      "----------\n",
      "Metrics for delta_T_depth = 2m:\n",
      "Average Precision: 0.8\n",
      "Average Recall: 0.8\n",
      "Average F1 Score: 0.8\n",
      "----------\n",
      "Metrics for delta_T_depth = 3m:\n",
      "Average Precision: 0.82\n",
      "Average Recall: 0.82\n",
      "Average F1 Score: 0.82\n",
      "----------\n",
      "Metrics for delta_T_depth = 6m:\n",
      "Average Precision: 0.88\n",
      "Average Recall: 0.88\n",
      "Average F1 Score: 0.88\n",
      "----------\n",
      "starting trainging for formation: 2000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nicholas.bivens_geot\\school\\TopPrediction\\test_CNN.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicholas.bivens_geot/school/TopPrediction/test_CNN.ipynb#X24sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m X_train, y_train,X_val, y_val \u001b[39m=\u001b[39m get_train_data(formation_train_data) \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicholas.bivens_geot/school/TopPrediction/test_CNN.ipynb#X24sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# train model at depth\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nicholas.bivens_geot/school/TopPrediction/test_CNN.ipynb#X24sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m model \u001b[39m=\u001b[39m train_model(X_train, y_train,X_val, y_val, learning_rate \u001b[39m=\u001b[39;49m \u001b[39m0.001\u001b[39;49m,epochs\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m, nodes\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m, dropout \u001b[39m=\u001b[39;49m \u001b[39m0.5\u001b[39;49m, dilation3x3\u001b[39m=\u001b[39;49m\u001b[39m48\u001b[39;49m, dilation5x5\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m,dilation7x7\u001b[39m=\u001b[39;49m\u001b[39m24\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicholas.bivens_geot/school/TopPrediction/test_CNN.ipynb#X24sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m models_list\u001b[39m.\u001b[39mappend(model)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicholas.bivens_geot/school/TopPrediction/test_CNN.ipynb#X24sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m current_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetcwd()\n",
      "\u001b[1;32mc:\\Users\\nicholas.bivens_geot\\school\\TopPrediction\\test_CNN.ipynb Cell 19\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nicholas.bivens_geot/school/TopPrediction/test_CNN.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_model\u001b[39m(X_train, y_train, X_val, y_val, learning_rate, epochs, nodes, dropout, dilation3x3 \u001b[39m=\u001b[39m\u001b[39m32\u001b[39m,dilation5x5\u001b[39m=\u001b[39m\u001b[39m24\u001b[39m,dilation7x7\u001b[39m=\u001b[39m\u001b[39m24\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nicholas.bivens_geot/school/TopPrediction/test_CNN.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     global_view \u001b[39m=\u001b[39m create_global_view(initial_layer\u001b[39m=\u001b[39;49mnodes,dropout \u001b[39m=\u001b[39;49m dropout, dilation3x3\u001b[39m=\u001b[39;49mdilation3x3, dilation5x5\u001b[39m=\u001b[39;49mdilation5x5,dilation7x7\u001b[39m=\u001b[39;49mdilation7x7)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nicholas.bivens_geot/school/TopPrediction/test_CNN.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     local_view \u001b[39m=\u001b[39m create_local_view(initial_filters\u001b[39m=\u001b[39mnodes)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nicholas.bivens_geot/school/TopPrediction/test_CNN.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     global_output \u001b[39m=\u001b[39m global_view\u001b[39m.\u001b[39moutput\n",
      "\u001b[1;32mc:\\Users\\nicholas.bivens_geot\\school\\TopPrediction\\test_CNN.ipynb Cell 19\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicholas.bivens_geot/school/TopPrediction/test_CNN.ipynb#X24sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m conv_middle \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mDropout(dropout)(conv_middle)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicholas.bivens_geot/school/TopPrediction/test_CNN.ipynb#X24sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# Decoding layer 1\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nicholas.bivens_geot/school/TopPrediction/test_CNN.ipynb#X24sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m up1 \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39;49mUpSampling1D()(conv_middle)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicholas.bivens_geot/school/TopPrediction/test_CNN.ipynb#X24sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m merge1 \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mconcatenate([conv2, up1]) \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nicholas.bivens_geot/school/TopPrediction/test_CNN.ipynb#X24sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m decode1 \u001b[39m=\u001b[39m inception_module(merge1,initial_layer\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m, dilation3x3\u001b[39m=\u001b[39mdilation3x3, dilation5x5\u001b[39m=\u001b[39mdilation5x5,dilation7x7\u001b[39m=\u001b[39mdilation7x7)\n",
      "File \u001b[1;32mc:\\Users\\nicholas.bivens_geot\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\nicholas.bivens_geot\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\keras\\src\\engine\\base_layer.py:1063\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1055\u001b[0m \u001b[39m# Functional Model construction mode is invoked when `Layer`s are called\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m \u001b[39m# on symbolic `KerasTensor`s, i.e.:\u001b[39;00m\n\u001b[0;32m   1057\u001b[0m \u001b[39m# >> inputs = tf.keras.Input(10)\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m \u001b[39m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[39;00m\n\u001b[0;32m   1059\u001b[0m \u001b[39m# >> model = tf.keras.Model(inputs, outputs)\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m \u001b[39mif\u001b[39;00m _in_functional_construction_mode(\n\u001b[0;32m   1061\u001b[0m     \u001b[39mself\u001b[39m, inputs, args, kwargs, input_list\n\u001b[0;32m   1062\u001b[0m ):\n\u001b[1;32m-> 1063\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_functional_construction_call(\n\u001b[0;32m   1064\u001b[0m         inputs, args, kwargs, input_list\n\u001b[0;32m   1065\u001b[0m     )\n\u001b[0;32m   1067\u001b[0m \u001b[39m# Maintains info about the `Layer.call` stack.\u001b[39;00m\n\u001b[0;32m   1068\u001b[0m call_context \u001b[39m=\u001b[39m base_layer_utils\u001b[39m.\u001b[39mcall_context()\n",
      "File \u001b[1;32mc:\\Users\\nicholas.bivens_geot\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\keras\\src\\engine\\base_layer.py:2603\u001b[0m, in \u001b[0;36mLayer._functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   2597\u001b[0m \u001b[39mwith\u001b[39;00m call_context\u001b[39m.\u001b[39menter(\n\u001b[0;32m   2598\u001b[0m     layer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, inputs\u001b[39m=\u001b[39minputs, build_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39mtraining_value\n\u001b[0;32m   2599\u001b[0m ):\n\u001b[0;32m   2600\u001b[0m     \u001b[39m# Check input assumptions set after layer building, e.g. input\u001b[39;00m\n\u001b[0;32m   2601\u001b[0m     \u001b[39m# shape.\u001b[39;00m\n\u001b[0;32m   2602\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 2603\u001b[0m         outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_keras_tensor_symbolic_call(\n\u001b[0;32m   2604\u001b[0m             inputs, input_masks, args, kwargs\n\u001b[0;32m   2605\u001b[0m         )\n\u001b[0;32m   2606\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   2607\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mDictWrapper\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(e):\n",
      "File \u001b[1;32mc:\\Users\\nicholas.bivens_geot\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\keras\\src\\engine\\base_layer.py:2449\u001b[0m, in \u001b[0;36mLayer._keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m   2445\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mmap_structure(\n\u001b[0;32m   2446\u001b[0m         keras_tensor\u001b[39m.\u001b[39mKerasTensor, output_signature\n\u001b[0;32m   2447\u001b[0m     )\n\u001b[0;32m   2448\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_infer_output_signature(\n\u001b[0;32m   2450\u001b[0m         inputs, args, kwargs, input_masks\n\u001b[0;32m   2451\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\nicholas.bivens_geot\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\keras\\src\\engine\\base_layer.py:2508\u001b[0m, in \u001b[0;36mLayer._infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m   2506\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_build(inputs)\n\u001b[0;32m   2507\u001b[0m         inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs)\n\u001b[1;32m-> 2508\u001b[0m         outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   2510\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n\u001b[0;32m   2511\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_mask_metadata(\n\u001b[0;32m   2512\u001b[0m     inputs, outputs, input_masks, build_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   2513\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\nicholas.bivens_geot\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nicholas.bivens_geot\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 690\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    691\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\nicholas.bivens_geot\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[0;32m    330\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[1;32m--> 331\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[0;32m    334\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[1;32mc:\\Users\\nicholas.bivens_geot\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    456\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 459\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    460\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\nicholas.bivens_geot\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\keras\\src\\layers\\reshaping\\up_sampling1d.py:78\u001b[0m, in \u001b[0;36mUpSampling1D.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputs):\n\u001b[1;32m---> 78\u001b[0m     output \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39;49mrepeat_elements(inputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msize, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     79\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\nicholas.bivens_geot\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\nicholas.bivens_geot\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\nicholas.bivens_geot\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\keras\\src\\backend.py:3790\u001b[0m, in \u001b[0;36mrepeat_elements\u001b[1;34m(x, rep, axis)\u001b[0m\n\u001b[0;32m   3783\u001b[0m \u001b[39m# Here we use tf.tile to mimic behavior of np.repeat so that\u001b[39;00m\n\u001b[0;32m   3784\u001b[0m \u001b[39m# we can handle dynamic shapes (that include None).\u001b[39;00m\n\u001b[0;32m   3785\u001b[0m \u001b[39m# To do that, we need an auxiliary axis to repeat elements along\u001b[39;00m\n\u001b[0;32m   3786\u001b[0m \u001b[39m# it and then merge them along the desired axis.\u001b[39;00m\n\u001b[0;32m   3787\u001b[0m \n\u001b[0;32m   3788\u001b[0m \u001b[39m# Repeating\u001b[39;00m\n\u001b[0;32m   3789\u001b[0m auxiliary_axis \u001b[39m=\u001b[39m axis \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 3790\u001b[0m x_shape \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mshape(x)\n\u001b[0;32m   3791\u001b[0m x_rep \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mexpand_dims(x, axis\u001b[39m=\u001b[39mauxiliary_axis)\n\u001b[0;32m   3792\u001b[0m reps \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones(\u001b[39mlen\u001b[39m(x\u001b[39m.\u001b[39mshape) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nicholas.bivens_geot\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\nicholas.bivens_geot\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\nicholas.bivens_geot\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:639\u001b[0m, in \u001b[0;36mshape_v2\u001b[1;34m(input, out_type, name)\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[0;32m    591\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[0;32m    592\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshape_v2\u001b[39m(\u001b[39minput\u001b[39m, out_type\u001b[39m=\u001b[39mdtypes\u001b[39m.\u001b[39mint32, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    593\u001b[0m   \u001b[39m# pylint: disable=redefined-builtin\u001b[39;00m\n\u001b[0;32m    594\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Returns a tensor containing the shape of the input tensor.\u001b[39;00m\n\u001b[0;32m    595\u001b[0m \n\u001b[0;32m    596\u001b[0m \u001b[39m  See also `tf.size`, `tf.rank`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[39m    A `Tensor` of type `out_type`.\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 639\u001b[0m   \u001b[39mreturn\u001b[39;00m shape(\u001b[39minput\u001b[39;49m, name, out_type)\n",
      "File \u001b[1;32mc:\\Users\\nicholas.bivens_geot\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\nicholas.bivens_geot\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\nicholas.bivens_geot\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:666\u001b[0m, in \u001b[0;36mshape\u001b[1;34m(input, name, out_type)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[39m@tf_export\u001b[39m(v1\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    643\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[0;32m    644\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshape\u001b[39m(\u001b[39minput\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out_type\u001b[39m=\u001b[39mdtypes\u001b[39m.\u001b[39mint32):\n\u001b[0;32m    645\u001b[0m   \u001b[39m# pylint: disable=redefined-builtin\u001b[39;00m\n\u001b[0;32m    646\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Returns the shape of a tensor.\u001b[39;00m\n\u001b[0;32m    647\u001b[0m \n\u001b[0;32m    648\u001b[0m \u001b[39m  This operation returns a 1-D integer tensor representing the shape of `input`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[39m    A `Tensor` of type `out_type`.\u001b[39;00m\n\u001b[0;32m    665\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 666\u001b[0m   \u001b[39mreturn\u001b[39;00m shape_internal(\u001b[39minput\u001b[39;49m, name, optimize\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, out_type\u001b[39m=\u001b[39;49mout_type)\n",
      "File \u001b[1;32mc:\\Users\\nicholas.bivens_geot\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:707\u001b[0m, in \u001b[0;36mshape_internal\u001b[1;34m(input, name, optimize, out_type)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m out_type:\n\u001b[0;32m    706\u001b[0m   out_type \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mint32\n\u001b[1;32m--> 707\u001b[0m \u001b[39mreturn\u001b[39;00m gen_array_ops\u001b[39m.\u001b[39;49mshape(\u001b[39minput\u001b[39;49m, name\u001b[39m=\u001b[39;49mname, out_type\u001b[39m=\u001b[39;49mout_type)\n",
      "File \u001b[1;32mc:\\Users\\nicholas.bivens_geot\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:11732\u001b[0m, in \u001b[0;36mshape\u001b[1;34m(input, out_type, name)\u001b[0m\n\u001b[0;32m  11730\u001b[0m   out_type \u001b[39m=\u001b[39m _dtypes\u001b[39m.\u001b[39mint32\n\u001b[0;32m  11731\u001b[0m out_type \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39mmake_type(out_type, \u001b[39m\"\u001b[39m\u001b[39mout_type\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m> 11732\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[0;32m  11733\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mShape\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39minput\u001b[39;49m, out_type\u001b[39m=\u001b[39;49mout_type, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m  11734\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[0;32m  11735\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[1;32mc:\\Users\\nicholas.bivens_geot\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:795\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    790\u001b[0m must_colocate_inputs \u001b[39m=\u001b[39m [val \u001b[39mfor\u001b[39;00m arg, val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(op_def\u001b[39m.\u001b[39minput_arg, inputs)\n\u001b[0;32m    791\u001b[0m                         \u001b[39mif\u001b[39;00m arg\u001b[39m.\u001b[39mis_ref]\n\u001b[0;32m    792\u001b[0m \u001b[39mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[0;32m    793\u001b[0m   \u001b[39m# Add Op to graph\u001b[39;00m\n\u001b[0;32m    794\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 795\u001b[0m   op \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(op_type_name, inputs, dtypes\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    796\u001b[0m                              name\u001b[39m=\u001b[39;49mscope, input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m    797\u001b[0m                              attrs\u001b[39m=\u001b[39;49mattr_protos, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m    799\u001b[0m \u001b[39m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[0;32m    800\u001b[0m \u001b[39m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[0;32m    801\u001b[0m \u001b[39m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[39m# for more details.\u001b[39;00m\n\u001b[0;32m    803\u001b[0m outputs \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39moutputs\n",
      "File \u001b[1;32mc:\\Users\\nicholas.bivens_geot\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:670\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    668\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture(inp)\n\u001b[0;32m    669\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[1;32m--> 670\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    671\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[0;32m    672\u001b[0m     compute_device)\n",
      "File \u001b[1;32mc:\\Users\\nicholas.bivens_geot\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3381\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3378\u001b[0m \u001b[39m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   3379\u001b[0m \u001b[39m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   3380\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 3381\u001b[0m   ret \u001b[39m=\u001b[39m Operation\u001b[39m.\u001b[39;49mfrom_node_def(\n\u001b[0;32m   3382\u001b[0m       node_def,\n\u001b[0;32m   3383\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   3384\u001b[0m       inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[0;32m   3385\u001b[0m       output_types\u001b[39m=\u001b[39;49mdtypes,\n\u001b[0;32m   3386\u001b[0m       control_inputs\u001b[39m=\u001b[39;49mcontrol_inputs,\n\u001b[0;32m   3387\u001b[0m       input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m   3388\u001b[0m       original_op\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_original_op,\n\u001b[0;32m   3389\u001b[0m       op_def\u001b[39m=\u001b[39;49mop_def,\n\u001b[0;32m   3390\u001b[0m   )\n\u001b[0;32m   3391\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_helper(ret, compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[0;32m   3392\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\nicholas.bivens_geot\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1889\u001b[0m, in \u001b[0;36mOperation.from_node_def\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1886\u001b[0m     control_input_ops\u001b[39m.\u001b[39mappend(control_op)\n\u001b[0;32m   1888\u001b[0m \u001b[39m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[1;32m-> 1889\u001b[0m c_op \u001b[39m=\u001b[39m _create_c_op(g, node_def, inputs, control_input_ops, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m   1890\u001b[0m \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m Operation(c_op, GraphTensor)\n\u001b[0;32m   1891\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init(g)\n",
      "File \u001b[1;32mc:\\Users\\nicholas.bivens_geot\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\nicholas.bivens_geot\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1748\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[0;32m   1744\u001b[0m   pywrap_tf_session\u001b[39m.\u001b[39mTF_SetAttrValueProto(op_desc, compat\u001b[39m.\u001b[39mas_str(name),\n\u001b[0;32m   1745\u001b[0m                                          serialized)\n\u001b[0;32m   1747\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1748\u001b[0m   c_op \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39;49mTF_FinishOperation(op_desc)\n\u001b[0;32m   1749\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mInvalidArgumentError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1750\u001b[0m   \u001b[39m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[0;32m   1751\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(e\u001b[39m.\u001b[39mmessage)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize dictionaries to store metrics for each formation and delta_T\n",
    "recall_metrics = {0.5: [], 1: [], 2: [], 3: [], 6: []}\n",
    "precision_metrics = {0.5: [], 1: [], 2: [], 3: [], 6: []}\n",
    "f1_metrics = {0.5: [], 1: [], 2: [], 3: [], 6: []}\n",
    "\n",
    "models_list=[]\n",
    "model_metrics = {}\n",
    "\n",
    "# formations = ['4000','5000','12000','13000']\n",
    "\n",
    "for formation in formations:\n",
    "    print(f\"starting trainging for formation: {formation}\")\n",
    "    # get training data\n",
    "    formation_train_data = folder_path+f'{formation}/train/'\n",
    "    X_train, y_train,X_val, y_val = get_train_data(formation_train_data) \n",
    "    # train model at depth\n",
    "    model = train_model(X_train, y_train,X_val, y_val, learning_rate = 0.001,epochs=200, nodes=16, dropout = 0.5, dilation3x3=48, dilation5x5=4,dilation7x7=24)\n",
    "    models_list.append(model)\n",
    "    current_dir = os.getcwd()\n",
    "    model_path = current_dir + f\"/Model/{formation}/\"\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model.save(model_path)\n",
    "    \n",
    "    # get test data\n",
    "    formation_test_data = folder_path+f'/{formation}/test/'\n",
    "    X_test, y_test, test_dfs = get_test_data(formation_test_data)\n",
    "    \n",
    "    # make predictions\n",
    "    for i, df in enumerate(test_dfs):\n",
    "        make_predictions(df,X_test[i],y_test[i], model, formation_test_data)\n",
    "    \n",
    "    model_deltaT_metrics= evaluate_model(test_dfs)\n",
    "    # Store metrics for each delta_T\n",
    "    for delta_T, metrics in model_deltaT_metrics.items():\n",
    "        recall_metrics[delta_T].append(metrics['average_recall'])\n",
    "        precision_metrics[delta_T].append(metrics['average_precision'])\n",
    "        f1_metrics[delta_T].append(metrics['average_f1'])\n",
    "        \n",
    "# Convert dictionaries to pandas DataFrames\n",
    "recall_df = pd.DataFrame(recall_metrics, index=formations)\n",
    "precision_df = pd.DataFrame(precision_metrics, index=formations)\n",
    "f1_df = pd.DataFrame(f1_metrics, index=formations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f0a85_ th {\n",
       "  font-size: 12pt;\n",
       "  text-align: center;\n",
       "  font-weight: bold;\n",
       "  color: Black;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_f0a85_ td {\n",
       "  text-align: center;\n",
       "  font-size: 11pt;\n",
       "  color: black;\n",
       "}\n",
       "#T_f0a85_ tr:nth-of-type(odd) {\n",
       "  background-color: #f2f2f2;\n",
       "}\n",
       "#T_f0a85_ tr:nth-of-type(even) {\n",
       "  background-color: white;\n",
       "}\n",
       "#T_f0a85_ tr:hover {\n",
       "  background-color: #ffff99;\n",
       "}\n",
       "#T_f0a85_ table {\n",
       "  border-collapse: collapse;\n",
       "  margin: auto;\n",
       "}\n",
       "#T_f0a85_ th {\n",
       "  border: 1px solid black;\n",
       "}\n",
       "#T_f0a85_  td {\n",
       "  border: 1px solid black;\n",
       "}\n",
       "#T_f0a85_ thead {\n",
       "  vertical-align: bottom;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_f0a85_ tbody {\n",
       "  vertical-align: middle;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_f0a85_ .index_name {\n",
       "  text-align: center;\n",
       "  vertical-align: middle;\n",
       "}\n",
       "#T_f0a85_ .col_heading {\n",
       "  text-align: center;\n",
       "  vertical-align: bottom;\n",
       "}\n",
       "#T_f0a85_row0_col0, #T_f0a85_row0_col1, #T_f0a85_row0_col2, #T_f0a85_row0_col3, #T_f0a85_row0_col4, #T_f0a85_row1_col0, #T_f0a85_row1_col1, #T_f0a85_row1_col2, #T_f0a85_row1_col3, #T_f0a85_row1_col4, #T_f0a85_row2_col0, #T_f0a85_row2_col1, #T_f0a85_row2_col2, #T_f0a85_row2_col3, #T_f0a85_row2_col4, #T_f0a85_row3_col0, #T_f0a85_row3_col1, #T_f0a85_row3_col2, #T_f0a85_row3_col3, #T_f0a85_row3_col4, #T_f0a85_row4_col0, #T_f0a85_row4_col1, #T_f0a85_row4_col2, #T_f0a85_row4_col3, #T_f0a85_row4_col4, #T_f0a85_row5_col0, #T_f0a85_row5_col1, #T_f0a85_row5_col2, #T_f0a85_row5_col3, #T_f0a85_row5_col4, #T_f0a85_row6_col0, #T_f0a85_row6_col1, #T_f0a85_row6_col2, #T_f0a85_row6_col3, #T_f0a85_row6_col4, #T_f0a85_row7_col0, #T_f0a85_row7_col1, #T_f0a85_row7_col2, #T_f0a85_row7_col3, #T_f0a85_row7_col4, #T_f0a85_row8_col0, #T_f0a85_row8_col1, #T_f0a85_row8_col2, #T_f0a85_row8_col3, #T_f0a85_row8_col4, #T_f0a85_row9_col0, #T_f0a85_row9_col1, #T_f0a85_row9_col2, #T_f0a85_row9_col3, #T_f0a85_row9_col4, #T_f0a85_row10_col0, #T_f0a85_row10_col1, #T_f0a85_row10_col2, #T_f0a85_row10_col3, #T_f0a85_row10_col4, #T_f0a85_row11_col0, #T_f0a85_row11_col1, #T_f0a85_row11_col2, #T_f0a85_row11_col3, #T_f0a85_row11_col4, #T_f0a85_row12_col0, #T_f0a85_row12_col1, #T_f0a85_row12_col2, #T_f0a85_row12_col3, #T_f0a85_row12_col4, #T_f0a85_row13_col0, #T_f0a85_row13_col1, #T_f0a85_row13_col2, #T_f0a85_row13_col3, #T_f0a85_row13_col4 {\n",
       "  width: 100px;\n",
       "  height: 30px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f0a85_\">\n",
       "  <caption>Delta T</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >0.5</th>\n",
       "      <th class=\"col_heading level0 col1\" >1.0</th>\n",
       "      <th class=\"col_heading level0 col2\" >2.0</th>\n",
       "      <th class=\"col_heading level0 col3\" >3.0</th>\n",
       "      <th class=\"col_heading level0 col4\" >6.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f0a85_level0_row0\" class=\"row_heading level0 row0\" >1000</th>\n",
       "      <td id=\"T_f0a85_row0_col0\" class=\"data row0 col0\" >0.560000</td>\n",
       "      <td id=\"T_f0a85_row0_col1\" class=\"data row0 col1\" >0.760000</td>\n",
       "      <td id=\"T_f0a85_row0_col2\" class=\"data row0 col2\" >0.800000</td>\n",
       "      <td id=\"T_f0a85_row0_col3\" class=\"data row0 col3\" >0.840000</td>\n",
       "      <td id=\"T_f0a85_row0_col4\" class=\"data row0 col4\" >0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0a85_level0_row1\" class=\"row_heading level0 row1\" >2000</th>\n",
       "      <td id=\"T_f0a85_row1_col0\" class=\"data row1 col0\" >0.700000</td>\n",
       "      <td id=\"T_f0a85_row1_col1\" class=\"data row1 col1\" >0.840000</td>\n",
       "      <td id=\"T_f0a85_row1_col2\" class=\"data row1 col2\" >0.900000</td>\n",
       "      <td id=\"T_f0a85_row1_col3\" class=\"data row1 col3\" >0.900000</td>\n",
       "      <td id=\"T_f0a85_row1_col4\" class=\"data row1 col4\" >0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0a85_level0_row2\" class=\"row_heading level0 row2\" >3000</th>\n",
       "      <td id=\"T_f0a85_row2_col0\" class=\"data row2 col0\" >0.540000</td>\n",
       "      <td id=\"T_f0a85_row2_col1\" class=\"data row2 col1\" >0.740000</td>\n",
       "      <td id=\"T_f0a85_row2_col2\" class=\"data row2 col2\" >0.920000</td>\n",
       "      <td id=\"T_f0a85_row2_col3\" class=\"data row2 col3\" >0.940000</td>\n",
       "      <td id=\"T_f0a85_row2_col4\" class=\"data row2 col4\" >0.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0a85_level0_row3\" class=\"row_heading level0 row3\" >4000</th>\n",
       "      <td id=\"T_f0a85_row3_col0\" class=\"data row3 col0\" >0.280000</td>\n",
       "      <td id=\"T_f0a85_row3_col1\" class=\"data row3 col1\" >0.460000</td>\n",
       "      <td id=\"T_f0a85_row3_col2\" class=\"data row3 col2\" >0.680000</td>\n",
       "      <td id=\"T_f0a85_row3_col3\" class=\"data row3 col3\" >0.800000</td>\n",
       "      <td id=\"T_f0a85_row3_col4\" class=\"data row3 col4\" >0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0a85_level0_row4\" class=\"row_heading level0 row4\" >5000</th>\n",
       "      <td id=\"T_f0a85_row4_col0\" class=\"data row4 col0\" >0.300000</td>\n",
       "      <td id=\"T_f0a85_row4_col1\" class=\"data row4 col1\" >0.460000</td>\n",
       "      <td id=\"T_f0a85_row4_col2\" class=\"data row4 col2\" >0.600000</td>\n",
       "      <td id=\"T_f0a85_row4_col3\" class=\"data row4 col3\" >0.640000</td>\n",
       "      <td id=\"T_f0a85_row4_col4\" class=\"data row4 col4\" >0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0a85_level0_row5\" class=\"row_heading level0 row5\" >6000</th>\n",
       "      <td id=\"T_f0a85_row5_col0\" class=\"data row5 col0\" >0.640000</td>\n",
       "      <td id=\"T_f0a85_row5_col1\" class=\"data row5 col1\" >0.820000</td>\n",
       "      <td id=\"T_f0a85_row5_col2\" class=\"data row5 col2\" >0.920000</td>\n",
       "      <td id=\"T_f0a85_row5_col3\" class=\"data row5 col3\" >0.940000</td>\n",
       "      <td id=\"T_f0a85_row5_col4\" class=\"data row5 col4\" >0.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0a85_level0_row6\" class=\"row_heading level0 row6\" >7000</th>\n",
       "      <td id=\"T_f0a85_row6_col0\" class=\"data row6 col0\" >0.620000</td>\n",
       "      <td id=\"T_f0a85_row6_col1\" class=\"data row6 col1\" >0.820000</td>\n",
       "      <td id=\"T_f0a85_row6_col2\" class=\"data row6 col2\" >0.860000</td>\n",
       "      <td id=\"T_f0a85_row6_col3\" class=\"data row6 col3\" >0.900000</td>\n",
       "      <td id=\"T_f0a85_row6_col4\" class=\"data row6 col4\" >0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0a85_level0_row7\" class=\"row_heading level0 row7\" >9000</th>\n",
       "      <td id=\"T_f0a85_row7_col0\" class=\"data row7 col0\" >0.260000</td>\n",
       "      <td id=\"T_f0a85_row7_col1\" class=\"data row7 col1\" >0.420000</td>\n",
       "      <td id=\"T_f0a85_row7_col2\" class=\"data row7 col2\" >0.560000</td>\n",
       "      <td id=\"T_f0a85_row7_col3\" class=\"data row7 col3\" >0.680000</td>\n",
       "      <td id=\"T_f0a85_row7_col4\" class=\"data row7 col4\" >0.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0a85_level0_row8\" class=\"row_heading level0 row8\" >9500</th>\n",
       "      <td id=\"T_f0a85_row8_col0\" class=\"data row8 col0\" >0.340000</td>\n",
       "      <td id=\"T_f0a85_row8_col1\" class=\"data row8 col1\" >0.420000</td>\n",
       "      <td id=\"T_f0a85_row8_col2\" class=\"data row8 col2\" >0.600000</td>\n",
       "      <td id=\"T_f0a85_row8_col3\" class=\"data row8 col3\" >0.700000</td>\n",
       "      <td id=\"T_f0a85_row8_col4\" class=\"data row8 col4\" >0.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0a85_level0_row9\" class=\"row_heading level0 row9\" >10000</th>\n",
       "      <td id=\"T_f0a85_row9_col0\" class=\"data row9 col0\" >0.500000</td>\n",
       "      <td id=\"T_f0a85_row9_col1\" class=\"data row9 col1\" >0.640000</td>\n",
       "      <td id=\"T_f0a85_row9_col2\" class=\"data row9 col2\" >0.740000</td>\n",
       "      <td id=\"T_f0a85_row9_col3\" class=\"data row9 col3\" >0.780000</td>\n",
       "      <td id=\"T_f0a85_row9_col4\" class=\"data row9 col4\" >0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0a85_level0_row10\" class=\"row_heading level0 row10\" >11000</th>\n",
       "      <td id=\"T_f0a85_row10_col0\" class=\"data row10 col0\" >0.200000</td>\n",
       "      <td id=\"T_f0a85_row10_col1\" class=\"data row10 col1\" >0.280000</td>\n",
       "      <td id=\"T_f0a85_row10_col2\" class=\"data row10 col2\" >0.440000</td>\n",
       "      <td id=\"T_f0a85_row10_col3\" class=\"data row10 col3\" >0.560000</td>\n",
       "      <td id=\"T_f0a85_row10_col4\" class=\"data row10 col4\" >0.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0a85_level0_row11\" class=\"row_heading level0 row11\" >12000</th>\n",
       "      <td id=\"T_f0a85_row11_col0\" class=\"data row11 col0\" >0.120000</td>\n",
       "      <td id=\"T_f0a85_row11_col1\" class=\"data row11 col1\" >0.240000</td>\n",
       "      <td id=\"T_f0a85_row11_col2\" class=\"data row11 col2\" >0.400000</td>\n",
       "      <td id=\"T_f0a85_row11_col3\" class=\"data row11 col3\" >0.480000</td>\n",
       "      <td id=\"T_f0a85_row11_col4\" class=\"data row11 col4\" >0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0a85_level0_row12\" class=\"row_heading level0 row12\" >13000</th>\n",
       "      <td id=\"T_f0a85_row12_col0\" class=\"data row12 col0\" >0.200000</td>\n",
       "      <td id=\"T_f0a85_row12_col1\" class=\"data row12 col1\" >0.280000</td>\n",
       "      <td id=\"T_f0a85_row12_col2\" class=\"data row12 col2\" >0.440000</td>\n",
       "      <td id=\"T_f0a85_row12_col3\" class=\"data row12 col3\" >0.460000</td>\n",
       "      <td id=\"T_f0a85_row12_col4\" class=\"data row12 col4\" >0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0a85_level0_row13\" class=\"row_heading level0 row13\" >14000</th>\n",
       "      <td id=\"T_f0a85_row13_col0\" class=\"data row13 col0\" >0.520000</td>\n",
       "      <td id=\"T_f0a85_row13_col1\" class=\"data row13 col1\" >0.620000</td>\n",
       "      <td id=\"T_f0a85_row13_col2\" class=\"data row13 col2\" >0.700000</td>\n",
       "      <td id=\"T_f0a85_row13_col3\" class=\"data row13 col3\" >0.740000</td>\n",
       "      <td id=\"T_f0a85_row13_col4\" class=\"data row13 col4\" >0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1f5cf5c4df0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_dd3a2_ th {\n",
       "  font-size: 12pt;\n",
       "  text-align: center;\n",
       "  font-weight: bold;\n",
       "  color: Black;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_dd3a2_ td {\n",
       "  text-align: center;\n",
       "  font-size: 11pt;\n",
       "  color: black;\n",
       "}\n",
       "#T_dd3a2_ tr:nth-of-type(odd) {\n",
       "  background-color: #f2f2f2;\n",
       "}\n",
       "#T_dd3a2_ tr:nth-of-type(even) {\n",
       "  background-color: white;\n",
       "}\n",
       "#T_dd3a2_ tr:hover {\n",
       "  background-color: #ffff99;\n",
       "}\n",
       "#T_dd3a2_ table {\n",
       "  border-collapse: collapse;\n",
       "  margin: auto;\n",
       "}\n",
       "#T_dd3a2_ th {\n",
       "  border: 1px solid black;\n",
       "}\n",
       "#T_dd3a2_  td {\n",
       "  border: 1px solid black;\n",
       "}\n",
       "#T_dd3a2_ thead {\n",
       "  vertical-align: bottom;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_dd3a2_ tbody {\n",
       "  vertical-align: middle;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_dd3a2_ .index_name {\n",
       "  text-align: center;\n",
       "  vertical-align: middle;\n",
       "}\n",
       "#T_dd3a2_ .col_heading {\n",
       "  text-align: center;\n",
       "  vertical-align: bottom;\n",
       "}\n",
       "#T_dd3a2_row0_col0, #T_dd3a2_row0_col1, #T_dd3a2_row0_col2, #T_dd3a2_row0_col3, #T_dd3a2_row0_col4, #T_dd3a2_row1_col0, #T_dd3a2_row1_col1, #T_dd3a2_row1_col2, #T_dd3a2_row1_col3, #T_dd3a2_row1_col4, #T_dd3a2_row2_col0, #T_dd3a2_row2_col1, #T_dd3a2_row2_col2, #T_dd3a2_row2_col3, #T_dd3a2_row2_col4, #T_dd3a2_row3_col0, #T_dd3a2_row3_col1, #T_dd3a2_row3_col2, #T_dd3a2_row3_col3, #T_dd3a2_row3_col4, #T_dd3a2_row4_col0, #T_dd3a2_row4_col1, #T_dd3a2_row4_col2, #T_dd3a2_row4_col3, #T_dd3a2_row4_col4, #T_dd3a2_row5_col0, #T_dd3a2_row5_col1, #T_dd3a2_row5_col2, #T_dd3a2_row5_col3, #T_dd3a2_row5_col4, #T_dd3a2_row6_col0, #T_dd3a2_row6_col1, #T_dd3a2_row6_col2, #T_dd3a2_row6_col3, #T_dd3a2_row6_col4, #T_dd3a2_row7_col0, #T_dd3a2_row7_col1, #T_dd3a2_row7_col2, #T_dd3a2_row7_col3, #T_dd3a2_row7_col4, #T_dd3a2_row8_col0, #T_dd3a2_row8_col1, #T_dd3a2_row8_col2, #T_dd3a2_row8_col3, #T_dd3a2_row8_col4, #T_dd3a2_row9_col0, #T_dd3a2_row9_col1, #T_dd3a2_row9_col2, #T_dd3a2_row9_col3, #T_dd3a2_row9_col4, #T_dd3a2_row10_col0, #T_dd3a2_row10_col1, #T_dd3a2_row10_col2, #T_dd3a2_row10_col3, #T_dd3a2_row10_col4, #T_dd3a2_row11_col0, #T_dd3a2_row11_col1, #T_dd3a2_row11_col2, #T_dd3a2_row11_col3, #T_dd3a2_row11_col4, #T_dd3a2_row12_col0, #T_dd3a2_row12_col1, #T_dd3a2_row12_col2, #T_dd3a2_row12_col3, #T_dd3a2_row12_col4, #T_dd3a2_row13_col0, #T_dd3a2_row13_col1, #T_dd3a2_row13_col2, #T_dd3a2_row13_col3, #T_dd3a2_row13_col4 {\n",
       "  width: 100px;\n",
       "  height: 30px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_dd3a2_\">\n",
       "  <caption>Delta T</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >0.5</th>\n",
       "      <th class=\"col_heading level0 col1\" >1.0</th>\n",
       "      <th class=\"col_heading level0 col2\" >2.0</th>\n",
       "      <th class=\"col_heading level0 col3\" >3.0</th>\n",
       "      <th class=\"col_heading level0 col4\" >6.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_dd3a2_level0_row0\" class=\"row_heading level0 row0\" >1000</th>\n",
       "      <td id=\"T_dd3a2_row0_col0\" class=\"data row0 col0\" >0.560000</td>\n",
       "      <td id=\"T_dd3a2_row0_col1\" class=\"data row0 col1\" >0.760000</td>\n",
       "      <td id=\"T_dd3a2_row0_col2\" class=\"data row0 col2\" >0.800000</td>\n",
       "      <td id=\"T_dd3a2_row0_col3\" class=\"data row0 col3\" >0.840000</td>\n",
       "      <td id=\"T_dd3a2_row0_col4\" class=\"data row0 col4\" >0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dd3a2_level0_row1\" class=\"row_heading level0 row1\" >2000</th>\n",
       "      <td id=\"T_dd3a2_row1_col0\" class=\"data row1 col0\" >0.700000</td>\n",
       "      <td id=\"T_dd3a2_row1_col1\" class=\"data row1 col1\" >0.840000</td>\n",
       "      <td id=\"T_dd3a2_row1_col2\" class=\"data row1 col2\" >0.900000</td>\n",
       "      <td id=\"T_dd3a2_row1_col3\" class=\"data row1 col3\" >0.900000</td>\n",
       "      <td id=\"T_dd3a2_row1_col4\" class=\"data row1 col4\" >0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dd3a2_level0_row2\" class=\"row_heading level0 row2\" >3000</th>\n",
       "      <td id=\"T_dd3a2_row2_col0\" class=\"data row2 col0\" >0.540000</td>\n",
       "      <td id=\"T_dd3a2_row2_col1\" class=\"data row2 col1\" >0.740000</td>\n",
       "      <td id=\"T_dd3a2_row2_col2\" class=\"data row2 col2\" >0.920000</td>\n",
       "      <td id=\"T_dd3a2_row2_col3\" class=\"data row2 col3\" >0.940000</td>\n",
       "      <td id=\"T_dd3a2_row2_col4\" class=\"data row2 col4\" >0.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dd3a2_level0_row3\" class=\"row_heading level0 row3\" >4000</th>\n",
       "      <td id=\"T_dd3a2_row3_col0\" class=\"data row3 col0\" >0.280000</td>\n",
       "      <td id=\"T_dd3a2_row3_col1\" class=\"data row3 col1\" >0.460000</td>\n",
       "      <td id=\"T_dd3a2_row3_col2\" class=\"data row3 col2\" >0.680000</td>\n",
       "      <td id=\"T_dd3a2_row3_col3\" class=\"data row3 col3\" >0.800000</td>\n",
       "      <td id=\"T_dd3a2_row3_col4\" class=\"data row3 col4\" >0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dd3a2_level0_row4\" class=\"row_heading level0 row4\" >5000</th>\n",
       "      <td id=\"T_dd3a2_row4_col0\" class=\"data row4 col0\" >0.300000</td>\n",
       "      <td id=\"T_dd3a2_row4_col1\" class=\"data row4 col1\" >0.460000</td>\n",
       "      <td id=\"T_dd3a2_row4_col2\" class=\"data row4 col2\" >0.600000</td>\n",
       "      <td id=\"T_dd3a2_row4_col3\" class=\"data row4 col3\" >0.640000</td>\n",
       "      <td id=\"T_dd3a2_row4_col4\" class=\"data row4 col4\" >0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dd3a2_level0_row5\" class=\"row_heading level0 row5\" >6000</th>\n",
       "      <td id=\"T_dd3a2_row5_col0\" class=\"data row5 col0\" >0.640000</td>\n",
       "      <td id=\"T_dd3a2_row5_col1\" class=\"data row5 col1\" >0.820000</td>\n",
       "      <td id=\"T_dd3a2_row5_col2\" class=\"data row5 col2\" >0.920000</td>\n",
       "      <td id=\"T_dd3a2_row5_col3\" class=\"data row5 col3\" >0.940000</td>\n",
       "      <td id=\"T_dd3a2_row5_col4\" class=\"data row5 col4\" >0.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dd3a2_level0_row6\" class=\"row_heading level0 row6\" >7000</th>\n",
       "      <td id=\"T_dd3a2_row6_col0\" class=\"data row6 col0\" >0.620000</td>\n",
       "      <td id=\"T_dd3a2_row6_col1\" class=\"data row6 col1\" >0.820000</td>\n",
       "      <td id=\"T_dd3a2_row6_col2\" class=\"data row6 col2\" >0.860000</td>\n",
       "      <td id=\"T_dd3a2_row6_col3\" class=\"data row6 col3\" >0.900000</td>\n",
       "      <td id=\"T_dd3a2_row6_col4\" class=\"data row6 col4\" >0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dd3a2_level0_row7\" class=\"row_heading level0 row7\" >9000</th>\n",
       "      <td id=\"T_dd3a2_row7_col0\" class=\"data row7 col0\" >0.260000</td>\n",
       "      <td id=\"T_dd3a2_row7_col1\" class=\"data row7 col1\" >0.420000</td>\n",
       "      <td id=\"T_dd3a2_row7_col2\" class=\"data row7 col2\" >0.560000</td>\n",
       "      <td id=\"T_dd3a2_row7_col3\" class=\"data row7 col3\" >0.680000</td>\n",
       "      <td id=\"T_dd3a2_row7_col4\" class=\"data row7 col4\" >0.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dd3a2_level0_row8\" class=\"row_heading level0 row8\" >9500</th>\n",
       "      <td id=\"T_dd3a2_row8_col0\" class=\"data row8 col0\" >0.340000</td>\n",
       "      <td id=\"T_dd3a2_row8_col1\" class=\"data row8 col1\" >0.420000</td>\n",
       "      <td id=\"T_dd3a2_row8_col2\" class=\"data row8 col2\" >0.600000</td>\n",
       "      <td id=\"T_dd3a2_row8_col3\" class=\"data row8 col3\" >0.700000</td>\n",
       "      <td id=\"T_dd3a2_row8_col4\" class=\"data row8 col4\" >0.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dd3a2_level0_row9\" class=\"row_heading level0 row9\" >10000</th>\n",
       "      <td id=\"T_dd3a2_row9_col0\" class=\"data row9 col0\" >0.500000</td>\n",
       "      <td id=\"T_dd3a2_row9_col1\" class=\"data row9 col1\" >0.640000</td>\n",
       "      <td id=\"T_dd3a2_row9_col2\" class=\"data row9 col2\" >0.740000</td>\n",
       "      <td id=\"T_dd3a2_row9_col3\" class=\"data row9 col3\" >0.780000</td>\n",
       "      <td id=\"T_dd3a2_row9_col4\" class=\"data row9 col4\" >0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dd3a2_level0_row10\" class=\"row_heading level0 row10\" >11000</th>\n",
       "      <td id=\"T_dd3a2_row10_col0\" class=\"data row10 col0\" >0.200000</td>\n",
       "      <td id=\"T_dd3a2_row10_col1\" class=\"data row10 col1\" >0.280000</td>\n",
       "      <td id=\"T_dd3a2_row10_col2\" class=\"data row10 col2\" >0.440000</td>\n",
       "      <td id=\"T_dd3a2_row10_col3\" class=\"data row10 col3\" >0.560000</td>\n",
       "      <td id=\"T_dd3a2_row10_col4\" class=\"data row10 col4\" >0.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dd3a2_level0_row11\" class=\"row_heading level0 row11\" >12000</th>\n",
       "      <td id=\"T_dd3a2_row11_col0\" class=\"data row11 col0\" >0.120000</td>\n",
       "      <td id=\"T_dd3a2_row11_col1\" class=\"data row11 col1\" >0.240000</td>\n",
       "      <td id=\"T_dd3a2_row11_col2\" class=\"data row11 col2\" >0.400000</td>\n",
       "      <td id=\"T_dd3a2_row11_col3\" class=\"data row11 col3\" >0.480000</td>\n",
       "      <td id=\"T_dd3a2_row11_col4\" class=\"data row11 col4\" >0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dd3a2_level0_row12\" class=\"row_heading level0 row12\" >13000</th>\n",
       "      <td id=\"T_dd3a2_row12_col0\" class=\"data row12 col0\" >0.200000</td>\n",
       "      <td id=\"T_dd3a2_row12_col1\" class=\"data row12 col1\" >0.280000</td>\n",
       "      <td id=\"T_dd3a2_row12_col2\" class=\"data row12 col2\" >0.440000</td>\n",
       "      <td id=\"T_dd3a2_row12_col3\" class=\"data row12 col3\" >0.460000</td>\n",
       "      <td id=\"T_dd3a2_row12_col4\" class=\"data row12 col4\" >0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_dd3a2_level0_row13\" class=\"row_heading level0 row13\" >14000</th>\n",
       "      <td id=\"T_dd3a2_row13_col0\" class=\"data row13 col0\" >0.520000</td>\n",
       "      <td id=\"T_dd3a2_row13_col1\" class=\"data row13 col1\" >0.620000</td>\n",
       "      <td id=\"T_dd3a2_row13_col2\" class=\"data row13 col2\" >0.700000</td>\n",
       "      <td id=\"T_dd3a2_row13_col3\" class=\"data row13 col3\" >0.740000</td>\n",
       "      <td id=\"T_dd3a2_row13_col4\" class=\"data row13 col4\" >0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1f5cf5c6f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_35c9b_ th {\n",
       "  font-size: 12pt;\n",
       "  text-align: center;\n",
       "  font-weight: bold;\n",
       "  color: Black;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_35c9b_ td {\n",
       "  text-align: center;\n",
       "  font-size: 11pt;\n",
       "  color: black;\n",
       "}\n",
       "#T_35c9b_ tr:nth-of-type(odd) {\n",
       "  background-color: #f2f2f2;\n",
       "}\n",
       "#T_35c9b_ tr:nth-of-type(even) {\n",
       "  background-color: white;\n",
       "}\n",
       "#T_35c9b_ tr:hover {\n",
       "  background-color: #ffff99;\n",
       "}\n",
       "#T_35c9b_ table {\n",
       "  border-collapse: collapse;\n",
       "  margin: auto;\n",
       "}\n",
       "#T_35c9b_ th {\n",
       "  border: 1px solid black;\n",
       "}\n",
       "#T_35c9b_  td {\n",
       "  border: 1px solid black;\n",
       "}\n",
       "#T_35c9b_ thead {\n",
       "  vertical-align: bottom;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_35c9b_ tbody {\n",
       "  vertical-align: middle;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_35c9b_ .index_name {\n",
       "  text-align: center;\n",
       "  vertical-align: middle;\n",
       "}\n",
       "#T_35c9b_ .col_heading {\n",
       "  text-align: center;\n",
       "  vertical-align: bottom;\n",
       "}\n",
       "#T_35c9b_row0_col0, #T_35c9b_row0_col1, #T_35c9b_row0_col2, #T_35c9b_row0_col3, #T_35c9b_row0_col4, #T_35c9b_row1_col0, #T_35c9b_row1_col1, #T_35c9b_row1_col2, #T_35c9b_row1_col3, #T_35c9b_row1_col4, #T_35c9b_row2_col0, #T_35c9b_row2_col1, #T_35c9b_row2_col2, #T_35c9b_row2_col3, #T_35c9b_row2_col4, #T_35c9b_row3_col0, #T_35c9b_row3_col1, #T_35c9b_row3_col2, #T_35c9b_row3_col3, #T_35c9b_row3_col4, #T_35c9b_row4_col0, #T_35c9b_row4_col1, #T_35c9b_row4_col2, #T_35c9b_row4_col3, #T_35c9b_row4_col4, #T_35c9b_row5_col0, #T_35c9b_row5_col1, #T_35c9b_row5_col2, #T_35c9b_row5_col3, #T_35c9b_row5_col4, #T_35c9b_row6_col0, #T_35c9b_row6_col1, #T_35c9b_row6_col2, #T_35c9b_row6_col3, #T_35c9b_row6_col4, #T_35c9b_row7_col0, #T_35c9b_row7_col1, #T_35c9b_row7_col2, #T_35c9b_row7_col3, #T_35c9b_row7_col4, #T_35c9b_row8_col0, #T_35c9b_row8_col1, #T_35c9b_row8_col2, #T_35c9b_row8_col3, #T_35c9b_row8_col4, #T_35c9b_row9_col0, #T_35c9b_row9_col1, #T_35c9b_row9_col2, #T_35c9b_row9_col3, #T_35c9b_row9_col4, #T_35c9b_row10_col0, #T_35c9b_row10_col1, #T_35c9b_row10_col2, #T_35c9b_row10_col3, #T_35c9b_row10_col4, #T_35c9b_row11_col0, #T_35c9b_row11_col1, #T_35c9b_row11_col2, #T_35c9b_row11_col3, #T_35c9b_row11_col4, #T_35c9b_row12_col0, #T_35c9b_row12_col1, #T_35c9b_row12_col2, #T_35c9b_row12_col3, #T_35c9b_row12_col4, #T_35c9b_row13_col0, #T_35c9b_row13_col1, #T_35c9b_row13_col2, #T_35c9b_row13_col3, #T_35c9b_row13_col4 {\n",
       "  width: 100px;\n",
       "  height: 30px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_35c9b_\">\n",
       "  <caption>Delta T</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >0.5</th>\n",
       "      <th class=\"col_heading level0 col1\" >1.0</th>\n",
       "      <th class=\"col_heading level0 col2\" >2.0</th>\n",
       "      <th class=\"col_heading level0 col3\" >3.0</th>\n",
       "      <th class=\"col_heading level0 col4\" >6.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_35c9b_level0_row0\" class=\"row_heading level0 row0\" >1000</th>\n",
       "      <td id=\"T_35c9b_row0_col0\" class=\"data row0 col0\" >0.560000</td>\n",
       "      <td id=\"T_35c9b_row0_col1\" class=\"data row0 col1\" >0.760000</td>\n",
       "      <td id=\"T_35c9b_row0_col2\" class=\"data row0 col2\" >0.800000</td>\n",
       "      <td id=\"T_35c9b_row0_col3\" class=\"data row0 col3\" >0.840000</td>\n",
       "      <td id=\"T_35c9b_row0_col4\" class=\"data row0 col4\" >0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_35c9b_level0_row1\" class=\"row_heading level0 row1\" >2000</th>\n",
       "      <td id=\"T_35c9b_row1_col0\" class=\"data row1 col0\" >0.700000</td>\n",
       "      <td id=\"T_35c9b_row1_col1\" class=\"data row1 col1\" >0.840000</td>\n",
       "      <td id=\"T_35c9b_row1_col2\" class=\"data row1 col2\" >0.900000</td>\n",
       "      <td id=\"T_35c9b_row1_col3\" class=\"data row1 col3\" >0.900000</td>\n",
       "      <td id=\"T_35c9b_row1_col4\" class=\"data row1 col4\" >0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_35c9b_level0_row2\" class=\"row_heading level0 row2\" >3000</th>\n",
       "      <td id=\"T_35c9b_row2_col0\" class=\"data row2 col0\" >0.540000</td>\n",
       "      <td id=\"T_35c9b_row2_col1\" class=\"data row2 col1\" >0.740000</td>\n",
       "      <td id=\"T_35c9b_row2_col2\" class=\"data row2 col2\" >0.920000</td>\n",
       "      <td id=\"T_35c9b_row2_col3\" class=\"data row2 col3\" >0.940000</td>\n",
       "      <td id=\"T_35c9b_row2_col4\" class=\"data row2 col4\" >0.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_35c9b_level0_row3\" class=\"row_heading level0 row3\" >4000</th>\n",
       "      <td id=\"T_35c9b_row3_col0\" class=\"data row3 col0\" >0.280000</td>\n",
       "      <td id=\"T_35c9b_row3_col1\" class=\"data row3 col1\" >0.460000</td>\n",
       "      <td id=\"T_35c9b_row3_col2\" class=\"data row3 col2\" >0.680000</td>\n",
       "      <td id=\"T_35c9b_row3_col3\" class=\"data row3 col3\" >0.800000</td>\n",
       "      <td id=\"T_35c9b_row3_col4\" class=\"data row3 col4\" >0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_35c9b_level0_row4\" class=\"row_heading level0 row4\" >5000</th>\n",
       "      <td id=\"T_35c9b_row4_col0\" class=\"data row4 col0\" >0.300000</td>\n",
       "      <td id=\"T_35c9b_row4_col1\" class=\"data row4 col1\" >0.460000</td>\n",
       "      <td id=\"T_35c9b_row4_col2\" class=\"data row4 col2\" >0.600000</td>\n",
       "      <td id=\"T_35c9b_row4_col3\" class=\"data row4 col3\" >0.640000</td>\n",
       "      <td id=\"T_35c9b_row4_col4\" class=\"data row4 col4\" >0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_35c9b_level0_row5\" class=\"row_heading level0 row5\" >6000</th>\n",
       "      <td id=\"T_35c9b_row5_col0\" class=\"data row5 col0\" >0.640000</td>\n",
       "      <td id=\"T_35c9b_row5_col1\" class=\"data row5 col1\" >0.820000</td>\n",
       "      <td id=\"T_35c9b_row5_col2\" class=\"data row5 col2\" >0.920000</td>\n",
       "      <td id=\"T_35c9b_row5_col3\" class=\"data row5 col3\" >0.940000</td>\n",
       "      <td id=\"T_35c9b_row5_col4\" class=\"data row5 col4\" >0.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_35c9b_level0_row6\" class=\"row_heading level0 row6\" >7000</th>\n",
       "      <td id=\"T_35c9b_row6_col0\" class=\"data row6 col0\" >0.620000</td>\n",
       "      <td id=\"T_35c9b_row6_col1\" class=\"data row6 col1\" >0.820000</td>\n",
       "      <td id=\"T_35c9b_row6_col2\" class=\"data row6 col2\" >0.860000</td>\n",
       "      <td id=\"T_35c9b_row6_col3\" class=\"data row6 col3\" >0.900000</td>\n",
       "      <td id=\"T_35c9b_row6_col4\" class=\"data row6 col4\" >0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_35c9b_level0_row7\" class=\"row_heading level0 row7\" >9000</th>\n",
       "      <td id=\"T_35c9b_row7_col0\" class=\"data row7 col0\" >0.260000</td>\n",
       "      <td id=\"T_35c9b_row7_col1\" class=\"data row7 col1\" >0.420000</td>\n",
       "      <td id=\"T_35c9b_row7_col2\" class=\"data row7 col2\" >0.560000</td>\n",
       "      <td id=\"T_35c9b_row7_col3\" class=\"data row7 col3\" >0.680000</td>\n",
       "      <td id=\"T_35c9b_row7_col4\" class=\"data row7 col4\" >0.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_35c9b_level0_row8\" class=\"row_heading level0 row8\" >9500</th>\n",
       "      <td id=\"T_35c9b_row8_col0\" class=\"data row8 col0\" >0.340000</td>\n",
       "      <td id=\"T_35c9b_row8_col1\" class=\"data row8 col1\" >0.420000</td>\n",
       "      <td id=\"T_35c9b_row8_col2\" class=\"data row8 col2\" >0.600000</td>\n",
       "      <td id=\"T_35c9b_row8_col3\" class=\"data row8 col3\" >0.700000</td>\n",
       "      <td id=\"T_35c9b_row8_col4\" class=\"data row8 col4\" >0.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_35c9b_level0_row9\" class=\"row_heading level0 row9\" >10000</th>\n",
       "      <td id=\"T_35c9b_row9_col0\" class=\"data row9 col0\" >0.500000</td>\n",
       "      <td id=\"T_35c9b_row9_col1\" class=\"data row9 col1\" >0.640000</td>\n",
       "      <td id=\"T_35c9b_row9_col2\" class=\"data row9 col2\" >0.740000</td>\n",
       "      <td id=\"T_35c9b_row9_col3\" class=\"data row9 col3\" >0.780000</td>\n",
       "      <td id=\"T_35c9b_row9_col4\" class=\"data row9 col4\" >0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_35c9b_level0_row10\" class=\"row_heading level0 row10\" >11000</th>\n",
       "      <td id=\"T_35c9b_row10_col0\" class=\"data row10 col0\" >0.200000</td>\n",
       "      <td id=\"T_35c9b_row10_col1\" class=\"data row10 col1\" >0.280000</td>\n",
       "      <td id=\"T_35c9b_row10_col2\" class=\"data row10 col2\" >0.440000</td>\n",
       "      <td id=\"T_35c9b_row10_col3\" class=\"data row10 col3\" >0.560000</td>\n",
       "      <td id=\"T_35c9b_row10_col4\" class=\"data row10 col4\" >0.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_35c9b_level0_row11\" class=\"row_heading level0 row11\" >12000</th>\n",
       "      <td id=\"T_35c9b_row11_col0\" class=\"data row11 col0\" >0.120000</td>\n",
       "      <td id=\"T_35c9b_row11_col1\" class=\"data row11 col1\" >0.240000</td>\n",
       "      <td id=\"T_35c9b_row11_col2\" class=\"data row11 col2\" >0.400000</td>\n",
       "      <td id=\"T_35c9b_row11_col3\" class=\"data row11 col3\" >0.480000</td>\n",
       "      <td id=\"T_35c9b_row11_col4\" class=\"data row11 col4\" >0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_35c9b_level0_row12\" class=\"row_heading level0 row12\" >13000</th>\n",
       "      <td id=\"T_35c9b_row12_col0\" class=\"data row12 col0\" >0.200000</td>\n",
       "      <td id=\"T_35c9b_row12_col1\" class=\"data row12 col1\" >0.280000</td>\n",
       "      <td id=\"T_35c9b_row12_col2\" class=\"data row12 col2\" >0.440000</td>\n",
       "      <td id=\"T_35c9b_row12_col3\" class=\"data row12 col3\" >0.460000</td>\n",
       "      <td id=\"T_35c9b_row12_col4\" class=\"data row12 col4\" >0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_35c9b_level0_row13\" class=\"row_heading level0 row13\" >14000</th>\n",
       "      <td id=\"T_35c9b_row13_col0\" class=\"data row13 col0\" >0.520000</td>\n",
       "      <td id=\"T_35c9b_row13_col1\" class=\"data row13 col1\" >0.620000</td>\n",
       "      <td id=\"T_35c9b_row13_col2\" class=\"data row13 col2\" >0.700000</td>\n",
       "      <td id=\"T_35c9b_row13_col3\" class=\"data row13 col3\" >0.740000</td>\n",
       "      <td id=\"T_35c9b_row13_col4\" class=\"data row13 col4\" >0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1f5cf5c7d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def style_dataframe(df, title):\n",
    "    styled_df = df.style.set_table_styles(\n",
    "        [{'selector': 'th', 'props': [('font-size', '12pt'), ('text-align', 'center'), ('font-weight', 'bold'), ('color', 'Black'), ('background-color', 'lightgrey')]},\n",
    "         {'selector': 'td', 'props': [('text-align', 'center'), ('font-size', '11pt'), ('color', 'black')]},  # Text color set to black\n",
    "         {'selector': 'tr:nth-of-type(odd)', 'props': [('background-color', '#f2f2f2')]},\n",
    "         {'selector': 'tr:nth-of-type(even)', 'props': [('background-color', 'white')]},\n",
    "         {'selector': 'tr:hover', 'props': [('background-color', '#ffff99')]},\n",
    "         {'selector': 'table', 'props': [('border-collapse', 'collapse'), ('margin', 'auto')]},\n",
    "         {'selector': 'th, td', 'props': [('border', '1px solid black')]}]\n",
    "    ).set_properties(**{'width': '100px', 'height': '30px'}).set_caption(\"Delta T\")\n",
    "\n",
    "    # Custom CSS for positioning the index and column labels\n",
    "    styled_df = styled_df.set_table_styles([\n",
    "        {'selector': 'thead', 'props': [('vertical-align', 'bottom'), ('text-align', 'center')]},\n",
    "        {'selector': 'tbody', 'props': [('vertical-align', 'middle'), ('text-align', 'center')]},\n",
    "        {'selector': '.index_name', 'props': [('text-align', 'center'), ('vertical-align', 'middle')]},\n",
    "        {'selector': '.col_heading', 'props': [('text-align', 'center'), ('vertical-align', 'bottom')]}\n",
    "    ], overwrite=False, axis=0)\n",
    "\n",
    "    return styled_df\n",
    "\n",
    "# Apply styling to the DataFrames with titles\n",
    "styled_recall_df = style_dataframe(recall_df, \"Recall\")\n",
    "styled_precision_df = style_dataframe(precision_df, \"Precision\")\n",
    "styled_f1_df = style_dataframe(f1_df, \"F1\")\n",
    "\n",
    "# Display the styled DataFrames\n",
    "display(styled_recall_df)\n",
    "display(styled_precision_df)\n",
    "display(styled_f1_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_dir = os.getcwd()\n",
    "# # Train your model here\n",
    "# model_path = current_dir + \"/Model/\"\n",
    "\n",
    "# # Load the model\n",
    "# loaded_model = load_model(model_path, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming y_test is a list of 2D arrays with shape (n, 1)\n",
    "# y_test_smoothed = [smooth_labels(y, sigma=2) for y in y_test]\n",
    "\n",
    "# # Example usage\n",
    "# z_test = y_test[0].flatten()  # Flatten the array to 1D\n",
    "# smoothed_z_test = smooth_labels(z_test, sigma=2) # Flatten the smoothed labels to 1D\n",
    "\n",
    "# # Plot the results\n",
    "# plt.plot(y_test[0], label='Original Labels')\n",
    "# plt.plot(y_test_smoothed[0], label='Smoothed Labels')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # Define the range around the pick to focus on\n",
    "# focus_index = 15  # Index of the pick\n",
    "# range_around_pick = 10  # Number of indices to include on either side\n",
    "\n",
    "# # Plot the results focusing on the specified range\n",
    "# plt.figure(figsize=(10, 5))  # Increase figure size for better visibility\n",
    "# plt.plot(range(focus_index - range_around_pick, focus_index + range_around_pick + 1),\n",
    "#          y_test[0][focus_index - range_around_pick:focus_index + range_around_pick + 1],\n",
    "#          label='Original Labels')\n",
    "# plt.plot(range(focus_index - range_around_pick, focus_index + range_around_pick + 1),\n",
    "#          y_test_smoothed[0][focus_index - range_around_pick:focus_index + range_around_pick + 1],\n",
    "#          label='Smoothed Labels')\n",
    "# plt.legend()\n",
    "# plt.title(f\"Labels around index {focus_index}\")\n",
    "# plt.xlabel(\"Index\")\n",
    "# plt.ylabel(\"Label Value\")\n",
    "# plt.show()\n",
    "\n",
    "# print(max(y_test[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
