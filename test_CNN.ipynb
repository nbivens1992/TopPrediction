{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Formation Tops from Well Log Data using CNN\n",
    "\n",
    "CNNs are powerful tools for pattern recognition and feature extraction in various types of data, including images, time-series, and, in your case, geological log curve data. Here's why they are suitable for this task:\n",
    "\n",
    "<b>Feature Extraction:</b> CNNs can automatically learn and extract relevant features from the input data. In your scenario, the model can learn to identify patterns in gamma ray, resistivity, and density porosity curves that are indicative of formation tops.\n",
    "\n",
    "<b>Spatial Hierarchy:</b> CNNs can capture the hierarchical spatial structures present in the data. This is crucial for understanding the geological layers and their properties.\n",
    "\n",
    "<b>Translation Invariance:</b> CNNs are robust to shifts and distortions in the input data, which is beneficial when dealing with natural variations in geological formations.\n",
    "Efficient Parameter Usage: CNNs share weights across different parts of the input, making them more parameter-efficient compared to fully connected networks. This is especially useful when dealing with large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "from keras.layers import Normalization, Lambda\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-Net Architecture\n",
    "\n",
    "The U-Net architecture is a type of convolutional neural network that was originally designed for biomedical image segmentation. The combination of global and local views in a U-Net architecture allows the model to understand both the broader context and the finer details of the input data, which is crucial for tasks like predicting formation tops in geological data. Here are common parts of a U-Net architecture\n",
    "- Contracting Path: The contracting path is similar to a typical convolutional network. It consists of repeated application of convolutions, followed by a rectified linear unit (ReLU) and a max pooling operation. With each downsampling step, the network increases the number of feature channels.\n",
    "\n",
    "- Expansive Path: The expansive path consists of upsampling of the feature map followed by a convolution (\"up-convolution\"), which halves the number of feature channels, a concatenation with the correspondingly cropped feature map from the contracting path, and two more convolutions, each followed by a ReLU. The cropping is necessary due to the loss of border pixels in every convolution.\n",
    "\n",
    "- Skip Connections: The key innovation in U-Net is the use of skip connections, where outputs from the contracting path are concatenated with inputs to the expansive path. These connections provide the expansive path with the context information lost during downsampling, which is crucial for precise localization.\n",
    "\n",
    "### Global View \n",
    "\n",
    "The global view in a U-Net architecture refers to the initial layers of the network where the input data is progressively downsampled (pooled). The purpose of the global view is to:\n",
    "\n",
    "<b>Capture Context:</b> By looking at the broader picture, the global view helps the model understand the overall context of the data. In geological terms, this might mean understanding the general trends and structures across a wide depth range.\n",
    "\n",
    "<b>Reduce Dimensionality:</b> Pooling layers reduce the spatial dimensions of the feature maps, which decreases the computational complexity and helps in focusing on the more salient features.\n",
    "\n",
    "<b>Increase Receptive Field:</b> As the data is downsampled, the receptive field of the neurons increases, allowing them to capture more global features that are relevant for the prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_global_view(initial_layer = 8, dropout = 0.5):\n",
    "    inputs = layers.Input(shape=(None, 3))  # Assuming the logs are 1D sequences\n",
    "    \n",
    "    x = layers.Masking(mask_value=-99)(inputs)  # Using -99 as the mask value\n",
    "\n",
    "    # Encoding layer 1\n",
    "    conv1 = layers.Conv1D(initial_layer, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    conv1 = layers.BatchNormalization()(conv1)\n",
    "    conv1 = layers.Dropout(dropout)(conv1)\n",
    "    pool1 = layers.MaxPooling1D()(conv1)\n",
    "\n",
    "    # Encoding layer 2\n",
    "    conv2 = layers.Conv1D(2*initial_layer, 3, activation=\"relu\", padding=\"same\")(pool1)\n",
    "    conv2 = layers.BatchNormalization()(conv2)\n",
    "    conv2 = layers.Dropout(dropout)(conv2)\n",
    "    pool2 = layers.MaxPooling1D()(conv2)\n",
    "\n",
    "    # Middle layer\n",
    "    conv_middle = layers.Conv1D(4*initial_layer, 3, activation=\"relu\", padding=\"same\")(pool2)\n",
    "    conv_middle = layers.BatchNormalization()(conv_middle)\n",
    "    \n",
    "    conv_middle = layers.Dropout(dropout)(conv_middle)\n",
    "\n",
    "    # Decoding layer 1\n",
    "    up1 = layers.UpSampling1D()(conv_middle)\n",
    "    \n",
    "    # # Ensure sizes match before concatenating\n",
    "    # cropped_conv2 = layers.Cropping1D(cropping=((1,0)))(conv2)\n",
    "    merge1 = layers.concatenate([conv2, up1])\n",
    "    \n",
    "    decode1 = layers.Conv1D(2*initial_layer, 3, activation=\"relu\", padding=\"same\")(merge1)\n",
    "    decode1 = layers.BatchNormalization()(decode1)\n",
    "    decode1 = layers.Dropout(dropout)(decode1)\n",
    "\n",
    "    # Decoding layer 2\n",
    "    up2 = layers.UpSampling1D()(decode1)\n",
    "    \n",
    "    # Ensure sizes match before concatenating for the second merge\n",
    "    # cropped_conv1 = layers.Cropping1D(cropping=((2,0)))(conv1)  # Adjusted cropping\n",
    "    merge2 = layers.concatenate([conv1, up2])\n",
    "\n",
    "    decode2 = layers.Conv1D(initial_layer, 3, activation=\"relu\", padding=\"same\")(merge2)\n",
    "    decode2 = layers.BatchNormalization()(decode2)\n",
    "    decode2 = layers.Dropout(dropout)(decode2)\n",
    "\n",
    "    return models.Model(inputs, decode2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local View\n",
    "\n",
    "The local view, often represented by the latter layers of the U-Net or specialized layers like inception modules with dilated convolutions, focuses on finer details. Its purposes include:\n",
    "\n",
    "Detail Preservation: The local view helps in preserving and highlighting the finer details and local features that might be crucial for accurate prediction of formation tops.\n",
    "High-Resolution Feature Maps: As the data is upsampled or processed through dilated convolutions, the feature maps regain their resolution, allowing the model to make more precise localizations.\n",
    "Combining Context with Detail: By concatenating the upsampled feature maps with the corresponding feature maps from the downsampling path (skip connections), the model effectively combines the global context with local details, which is essential for accurate segmentation or prediction tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local View\n",
    "def create_local_view(initial_layer = 4):\n",
    "    inputs = layers.Input(shape=(None, 3))\n",
    "    x = layers.Masking(mask_value=-99)(inputs)  # Using -99 as the mask values\n",
    "    \n",
    "    # Inception layers with dilated convolutions\n",
    "    conv1 = layers.Conv1D(initial_layer, 1, padding=\"same\", dilation_rate=1)(x)\n",
    "    conv3 = layers.Conv1D(initial_layer, 3, padding=\"same\", dilation_rate=8)(x)\n",
    "    concat = layers.Concatenate()([conv1, conv3])\n",
    "    return models.Model(inputs, concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation for U-Net Model\n",
    "\n",
    "Our U-Net model requires the input data to adhere to specific dimensional constraints for it to process the data effectively. To ensure compatibility with the model's architecture, we perform the following preprocessing steps on each well's log data:\n",
    "\n",
    "### Normalization\n",
    "Firstly, we normalize the data to ensure that the model receives inputs that are on a similar scale. This is crucial for the model's convergence and performance. The normalization is performed using the following formula:\n",
    "\n",
    "$$ \\text{normalized\\_data} = \\frac{\\text{data} - \\text{mean}}{\\text{std}} $$\n",
    "\n",
    "where `mean` and `std` are the mean and standard deviation of the training data, respectively.\n",
    "\n",
    "### Ensuring Even Length\n",
    "The U-Net architecture involves multiple layers of downsampling and upsampling. To avoid any off-by-one errors during these operations, we need to ensure that the input data's length is even and remains even when divided by 2 and 4. We achieve this by:\n",
    "\n",
    "1. **Appending Padding**: If the sequence length is odd, we append a padding row to make it even. This padding is set to a specific value (e.g., -99) that the model can recognize and ignore during processing.\n",
    "\n",
    "2. **Adjusting Maximum Length**: We calculate the maximum length across all sequences and adjust it to ensure that it is even and divisible by 2 and 4. This adjustment is necessary to maintain the integrity of the data's spatial dimensions throughout the U-Net's downsampling and upsampling pathways.\n",
    "\n",
    "3. **Padding to Maximum Length**: Finally, we pad all sequences to this adjusted maximum length. This uniformity is essential for batch processing and allows the model to process multiple sequences simultaneously.\n",
    "\n",
    "By adhering to these preprocessing steps, we ensure that our U-Net model receives well-formatted input data, which is crucial for accurate predictions. The padding added during these steps is carefully handled by the model and does not significantly impact its predictive performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize function\n",
    "def normalize_data(data, mean, std):\n",
    "    return (data - mean) / std\n",
    "\n",
    "\n",
    "def ensure_even_length(sequence, padding_value=-99):\n",
    "    # If the sequence length is odd, append padding to make it even\n",
    "    if sequence.shape[0] % 2 != 0:\n",
    "        padding_shape = list(sequence.shape)\n",
    "        padding_shape[0] = 1  # we only need to add one row\n",
    "        \n",
    "        # Create a padding with the same number of columns as the sequence\n",
    "        padding = np.full(padding_shape, padding_value)\n",
    "        \n",
    "        # Append padding to the sequence\n",
    "        sequence = np.vstack([sequence, padding])\n",
    "        \n",
    "    return sequence\n",
    "\n",
    "def pad_to_max_length(sequence, max_length, padding_value=-99):\n",
    "    padding = [(0, max_length - sequence.shape[0]), (0, 0)]\n",
    "    return np.pad(sequence, padding, mode='constant', constant_values=padding_value)\n",
    "\n",
    "\n",
    "def adjust_max_length(max_length):\n",
    "    last_digit = max_length % 10\n",
    "    \n",
    "    if last_digit in [2, 6]:\n",
    "        return max_length + 2\n",
    "    elif last_digit == 0:\n",
    "        return max_length + 4\n",
    "    else:\n",
    "        return max_length\n",
    "    \n",
    "# def smooth_labels(y, sigma=1):\n",
    "#     # Ensure y is a 1D array\n",
    "#     y = y.flatten()\n",
    "#     smoothed_y = np.zeros_like(y, dtype=float)\n",
    "#     for idx in np.where(y == 1)[0]:\n",
    "#         gaussian = np.exp(-0.5 * ((np.arange(len(y)) - idx) / sigma) ** 2)\n",
    "#         gaussian /= gaussian.sum()\n",
    "#         smoothed_y += 3* gaussian  # Both are 1D arrays, so this should work\n",
    "#     return smoothed_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nbive\\AppData\\Local\\Temp\\ipykernel_15568\\2880759853.py:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_train = np.array([df[features].values for df in train_dfs])\n",
      "C:\\Users\\nbive\\AppData\\Local\\Temp\\ipykernel_15568\\2880759853.py:22: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  y_train = np.array([df[\"Pick\"].values for df in train_dfs])\n",
      "C:\\Users\\nbive\\AppData\\Local\\Temp\\ipykernel_15568\\2880759853.py:24: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_val = np.array([df[features].values for df in val_dfs])\n",
      "C:\\Users\\nbive\\AppData\\Local\\Temp\\ipykernel_15568\\2880759853.py:25: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  y_val = np.array([df[\"Pick\"].values for df in val_dfs])\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "# Train your model here\n",
    "folder_path = current_dir + \"/Data/Train_Validate/\"\n",
    "files = [f for f in os.listdir(folder_path) if f.endswith(\".csv\")]\n",
    "\n",
    "dfs = []\n",
    "for file in files:\n",
    "    df = pd.read_csv(folder_path + file)\n",
    "    dfs.append(df)\n",
    "\n",
    "train_dfs, val_dfs = train_test_split(dfs, test_size=0.2, random_state=42) # Here 20% of the data is kept for validation\n",
    "\n",
    "features = [\"GR\", \"ILD\", \"DPHI\"]\n",
    "\n",
    "# Compute the mean and standard deviation of the training data\n",
    "all_train_data = np.vstack([df[features].values for df in train_dfs])\n",
    "mean = np.mean(all_train_data, axis=0)\n",
    "std = np.std(all_train_data, axis=0)\n",
    "\n",
    "# Extract features and labels for training and validation sets\n",
    "X_train = np.array([df[features].values for df in train_dfs])\n",
    "y_train = np.array([df[\"Pick\"].values for df in train_dfs])\n",
    "\n",
    "X_val = np.array([df[features].values for df in val_dfs])\n",
    "y_val = np.array([df[\"Pick\"].values for df in val_dfs])\n",
    "\n",
    "\n",
    "# Normalize data\n",
    "X_train = [normalize_data(x, mean, std) for x in X_train]\n",
    "X_val = [normalize_data(x, mean, std) for x in X_val]\n",
    "\n",
    "# Ensure even length\n",
    "X_train = [ensure_even_length(x) for x in X_train]\n",
    "X_val = [ensure_even_length(x) for x in X_val]\n",
    "\n",
    "# Compute max_length after ensuring even lengths\n",
    "max_length = max(max(x.shape[0] for x in X_train), max(x.shape[0] for x in X_val))+2\n",
    "\n",
    "# The UNET structure requires the total size of the input when divided by 4  or divided by 2 be even. \n",
    "max_length = adjust_max_length(max_length)\n",
    "\n",
    "# Pad to max_length\n",
    "X_train = [pad_to_max_length(x, max_length) for x in X_train]\n",
    "X_val = [pad_to_max_length(x, max_length) for x in X_val]\n",
    "\n",
    "# # smooth y values\n",
    "# y_train = [smooth_labels(y) for y in y_train]\n",
    "# y_val = [smooth_labels(y) for y in y_val]\n",
    "\n",
    "# Ensure even length for labels and then pad\n",
    "y_train = [ensure_even_length(y.reshape(-1, 1),padding_value=0) for y in y_train]\n",
    "y_val = [ensure_even_length(y.reshape(-1, 1),padding_value=0) for y in y_val]\n",
    "\n",
    "y_train = [pad_to_max_length(y, max_length,padding_value=0) for y in y_train]\n",
    "y_val = [pad_to_max_length(y, max_length,padding_value=0) for y in y_val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "In this section, we define and train our U-Net model for the task of predicting formation tops in geological data. The model utilizes a combination of global and local views to capture both the broader context and fine details necessary for accurate predictions.\n",
    "\n",
    "### Focal Loss Function\n",
    "\n",
    "To address the class imbalance problem inherent in our task, where formation tops (class 1) are significantly less common than non-tops (class 0), we employ a custom loss function known as focal loss. This loss function is designed to focus more on hard-to-classify examples and down-weight the contribution of easy-to-classify examples, thereby helping the model to learn more from the minority class.\n",
    "\n",
    "### Model Architecture\n",
    "\n",
    "The model architecture combines the outputs of the global and local views using a multiplication operation. This combined output is then passed through a soft attention mechanism, implemented using a tanh activation function, to highlight the regions of interest. The final output is obtained using a 1D convolutional layer with a sigmoid activation function, which provides the probability of a formation top at each depth.\n",
    "\n",
    "### Training Process\n",
    "The model is trained using the Adam optimizer and the focal loss function. We employ an early stopping mechanism to prevent overfitting, where training is halted if the validation loss does not improve for a specified number of epochs (patience). The training and validation losses are plotted at the end of the training process to visualize the model's learning progress.\n",
    "\n",
    "During training, each well's log data is processed in batches. The model is trained on each batch, and the losses are recorded. The training loop also includes a validation step to monitor the model's performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def focal_loss(gamma=2., alpha=0.8):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) - K.sum((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n",
    "    return focal_loss_fixed\n",
    "\n",
    "def train_model(X_train, y_train, X_val, y_val, learning_rate, epochs):\n",
    "    global_view = create_global_view()\n",
    "    local_view = create_local_view()\n",
    "\n",
    "    combined = layers.Multiply()([global_view.output, local_view.output])\n",
    "\n",
    "    # Soft Attention\n",
    "    attention_output = layers.Activation(\"tanh\")(combined)\n",
    "\n",
    "    # HYPERPARAMETER: Adjust the number of filters (1) and kernel size (1)\n",
    "    output = layers.Conv1D(1, 1, activation=\"sigmoid\")(attention_output)\n",
    "\n",
    "    model = models.Model([global_view.input, local_view.input], output)\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "    # HYPERPARAMETER: Adjust the optimizer ('adam') and its parameters\n",
    "    model.compile(optimizer=optimizer, loss= focal_loss())\n",
    "    \n",
    "    # # HYPERPARAMETER: Adjust the optimizer ('adam') and its parameters\n",
    "    # model.compile(optimizer=optimizer, loss= tf.losses.BinaryCrossentropy())\n",
    "\n",
    "\n",
    "    # Early stopping parameters\n",
    "    patience = 5\n",
    "    min_delta = 0.001\n",
    "    best_val_loss = float('inf')\n",
    "    wait = 0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "\n",
    "    # We'll only use this training loop and remove the redundant one.\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        \n",
    "        # Training\n",
    "        epoch_train_losses = []\n",
    "        for i in range(len(X_train)):\n",
    "            X_train_well = X_train[i].reshape(1, X_train[i].shape[0], X_train[i].shape[1])\n",
    "            y_train_well = y_train[i].reshape(1, y_train[i].shape[0], 1)\n",
    "            loss = model.train_on_batch([X_train_well, X_train_well], y_train_well)  # Capturing the loss\n",
    "            epoch_train_losses.append(loss)\n",
    "        mean_train_loss = np.mean(epoch_train_losses)\n",
    "        train_losses.append(np.mean(mean_train_loss))\n",
    "\n",
    "        # Validation (optional)\n",
    "        epoch_val_losses = []\n",
    "        for i in range(len(X_val)):\n",
    "            X_val_well = X_val[i].reshape(1, X_val[i].shape[0], X_val[i].shape[1])\n",
    "            y_val_well = y_val[i].reshape(1, y_val[i].shape[0], 1)\n",
    "            loss = model.test_on_batch([X_val_well, X_val_well], y_val_well)\n",
    "            epoch_val_losses.append(loss)\n",
    "        mean_val_loss = np.mean(epoch_val_losses)\n",
    "        val_losses.append(mean_val_loss)\n",
    "        print(f\"Training Loss: {train_losses[-1]:.5f}, Validation Loss: {mean_val_loss:.5f}\")\n",
    "\n",
    "        # Early stopping check\n",
    "        if (best_val_loss - mean_val_loss) > min_delta:\n",
    "            best_val_loss = mean_val_loss\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}. Best validation loss: {best_val_loss:.5f}\")\n",
    "                break\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label=\"Training Loss\")\n",
    "    plt.plot(val_losses, label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training and Validation Loss Curves\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "Training Loss: 25.80183, Validation Loss: 17.15444\n",
      "Epoch 2/200\n",
      "Training Loss: 14.27378, Validation Loss: 11.30185\n",
      "Epoch 3/200\n",
      "Training Loss: 10.17689, Validation Loss: 10.48547\n",
      "Epoch 4/200\n",
      "Training Loss: 8.73621, Validation Loss: 10.56932\n",
      "Epoch 5/200\n",
      "Training Loss: 8.14922, Validation Loss: 10.25911\n",
      "Epoch 6/200\n",
      "Training Loss: 7.68202, Validation Loss: 10.37844\n",
      "Epoch 7/200\n",
      "Training Loss: 7.36001, Validation Loss: 9.92813\n",
      "Epoch 8/200\n",
      "Training Loss: 7.08509, Validation Loss: 9.92469\n",
      "Epoch 9/200\n",
      "Training Loss: 6.93961, Validation Loss: 9.44401\n",
      "Epoch 10/200\n",
      "Training Loss: 6.62903, Validation Loss: 9.19486\n",
      "Epoch 11/200\n",
      "Training Loss: 6.54269, Validation Loss: 9.10037\n",
      "Epoch 12/200\n",
      "Training Loss: 6.41400, Validation Loss: 8.99090\n",
      "Epoch 13/200\n",
      "Training Loss: 6.14924, Validation Loss: 8.91324\n",
      "Epoch 14/200\n",
      "Training Loss: 6.09700, Validation Loss: 8.35577\n",
      "Epoch 15/200\n",
      "Training Loss: 6.08888, Validation Loss: 8.32989\n",
      "Epoch 16/200\n",
      "Training Loss: 6.03764, Validation Loss: 8.47978\n",
      "Epoch 17/200\n",
      "Training Loss: 6.00208, Validation Loss: 8.10834\n",
      "Epoch 18/200\n",
      "Training Loss: 5.87990, Validation Loss: 8.28457\n",
      "Epoch 19/200\n",
      "Training Loss: 5.61992, Validation Loss: 8.28341\n",
      "Epoch 20/200\n",
      "Training Loss: 5.57870, Validation Loss: 8.01931\n",
      "Epoch 21/200\n",
      "Training Loss: 5.46869, Validation Loss: 7.87800\n",
      "Epoch 22/200\n",
      "Training Loss: 5.46833, Validation Loss: 7.58250\n",
      "Epoch 23/200\n",
      "Training Loss: 5.39645, Validation Loss: 7.67166\n",
      "Epoch 24/200\n",
      "Training Loss: 5.35341, Validation Loss: 7.64828\n",
      "Epoch 25/200\n",
      "Training Loss: 5.49357, Validation Loss: 7.22654\n",
      "Epoch 26/200\n",
      "Training Loss: 5.29927, Validation Loss: 7.29135\n",
      "Epoch 27/200\n",
      "Training Loss: 5.21464, Validation Loss: 7.08973\n",
      "Epoch 28/200\n",
      "Training Loss: 5.24211, Validation Loss: 7.33273\n",
      "Epoch 29/200\n",
      "Training Loss: 5.21678, Validation Loss: 7.04382\n",
      "Epoch 30/200\n",
      "Training Loss: 5.19862, Validation Loss: 7.12141\n",
      "Epoch 31/200\n",
      "Training Loss: 5.10427, Validation Loss: 7.44134\n",
      "Epoch 32/200\n",
      "Training Loss: 5.13542, Validation Loss: 6.65424\n",
      "Epoch 33/200\n",
      "Training Loss: 5.15133, Validation Loss: 6.79485\n",
      "Epoch 34/200\n",
      "Training Loss: 5.01361, Validation Loss: 6.93168\n",
      "Epoch 35/200\n",
      "Training Loss: 5.05440, Validation Loss: 6.88794\n",
      "Epoch 36/200\n",
      "Training Loss: 5.04701, Validation Loss: 6.65637\n",
      "Epoch 37/200\n",
      "Training Loss: 4.95285, Validation Loss: 6.72564\n",
      "Early stopping at epoch 37. Best validation loss: 6.65424\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = train_model(X_train, y_train,X_val, y_val, learning_rate = 0.001,epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\nbive\\anaconda3\\DS2 Project/Model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\nbive\\anaconda3\\DS2 Project/Model/assets\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "# Train your model here\n",
    "model_path = current_dir + \"/Model/\"\n",
    "\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_dir = os.getcwd()\n",
    "# # Train your model here\n",
    "# model_path = current_dir + \"/Model/\"\n",
    "\n",
    "# # Load the model\n",
    "# loaded_model = load_model(model_path, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nbive\\AppData\\Local\\Temp\\ipykernel_15568\\2726643326.py:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_test = np.array([df[features].values for df in test_dfs])\n",
      "C:\\Users\\nbive\\AppData\\Local\\Temp\\ipykernel_15568\\2726643326.py:16: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  y_test = np.array([df[\"Pick\"].values for df in test_dfs])\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "# Train your model here\n",
    "folder_path = current_dir + \"/Data/Test/\"\n",
    "files = [f for f in os.listdir(folder_path) if f.endswith(\".csv\")]\n",
    "\n",
    "test_dfs = []\n",
    "for file in files:\n",
    "    df = pd.read_csv(folder_path + file)\n",
    "    test_dfs.append(df)\n",
    "\n",
    "features = [\"GR\", \"ILD\", \"DPHI\"]\n",
    "\n",
    "\n",
    "# Extract features and labels for training and validation sets\n",
    "X_test = np.array([df[features].values for df in test_dfs])\n",
    "y_test = np.array([df[\"Pick\"].values for df in test_dfs])\n",
    "\n",
    "# Normalize data\n",
    "X_test = [normalize_data(x, mean, std) for x in X_test]\n",
    "\n",
    "# Ensure even length\n",
    "X_test = [ensure_even_length(x) for x in X_test]\n",
    "\n",
    "# Compute max_length after ensuring even lengths\n",
    "max_length = max(max(x.shape[0] for x in X_train), max(x.shape[0] for x in X_test))\n",
    "max_length = adjust_max_length(max_length)\n",
    "\n",
    "\n",
    "\n",
    "# Pad to max_length\n",
    "X_test = [pad_to_max_length(x, max_length) for x in X_test]\n",
    "\n",
    "# # Ensure even length for labels and then pad\n",
    "# y_test = [smooth_labels(y) for y in y_test]\n",
    "y_test = [ensure_even_length(y.reshape(-1, 1),padding_value=0) for y in y_test]\n",
    "y_test = [pad_to_max_length(y, max_length,padding_value=0) for y in y_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming y_test is a list of 2D arrays with shape (n, 1)\n",
    "# y_test_smoothed = [smooth_labels(y, sigma=2) for y in y_test]\n",
    "\n",
    "# # Example usage\n",
    "# z_test = y_test[0].flatten()  # Flatten the array to 1D\n",
    "# smoothed_z_test = smooth_labels(z_test, sigma=2) # Flatten the smoothed labels to 1D\n",
    "\n",
    "# # Plot the results\n",
    "# plt.plot(y_test[0], label='Original Labels')\n",
    "# plt.plot(y_test_smoothed[0], label='Smoothed Labels')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # Define the range around the pick to focus on\n",
    "# focus_index = 15  # Index of the pick\n",
    "# range_around_pick = 10  # Number of indices to include on either side\n",
    "\n",
    "# # Plot the results focusing on the specified range\n",
    "# plt.figure(figsize=(10, 5))  # Increase figure size for better visibility\n",
    "# plt.plot(range(focus_index - range_around_pick, focus_index + range_around_pick + 1),\n",
    "#          y_test[0][focus_index - range_around_pick:focus_index + range_around_pick + 1],\n",
    "#          label='Original Labels')\n",
    "# plt.plot(range(focus_index - range_around_pick, focus_index + range_around_pick + 1),\n",
    "#          y_test_smoothed[0][focus_index - range_around_pick:focus_index + range_around_pick + 1],\n",
    "#          label='Smoothed Labels')\n",
    "# plt.legend()\n",
    "# plt.title(f\"Labels around index {focus_index}\")\n",
    "# plt.xlabel(\"Index\")\n",
    "# plt.ylabel(\"Label Value\")\n",
    "# plt.show()\n",
    "\n",
    "# print(max(y_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 972ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "1/1 [==============================] - 0s 239ms/step\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n"
     ]
    }
   ],
   "source": [
    "def pad_dataframe(df, desired_length, padding_value=-99):\n",
    "    # Calculate the number of rows to add\n",
    "    num_rows_to_add = desired_length - len(df)\n",
    "    \n",
    "    # If the dataframe is already longer or equal to the desired length, return the original dataframe\n",
    "    if num_rows_to_add <= 0:\n",
    "        return df\n",
    "    \n",
    "    # Create a new dataframe with the required number of rows filled with the padding value\n",
    "    padding_df = pd.DataFrame(padding_value, index=range(num_rows_to_add), columns=df.columns)\n",
    "    \n",
    "    # Concatenate the original dataframe with the padding dataframe\n",
    "    padded_df = pd.concat([df, padding_df], axis=0).reset_index(drop=True)\n",
    "    \n",
    "    return padded_df\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    test_dfs[i]= pad_dataframe(test_dfs[i],desired_length=max_length)\n",
    "    x_reshape = X_test[i].reshape(1, X_test[i].shape[0], X_test[i].shape[1])\n",
    "    predictions = model.predict([x_reshape, x_reshape])\n",
    "    binary_predictions = (predictions >= 0.3).astype(int)\n",
    "    test_dfs[i]['Binary_Predict'] = binary_predictions.flatten()\n",
    "    test_dfs[i]['Predict'] = predictions.flatten()\n",
    "    # test_dfs[i]['Gauss']= y_test[i].flatten()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the directory exists\n",
    "output_dir = os.path.join(current_dir, \"Data\", \"Predictions\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Loop through X_test and y_test\n",
    "for df in test_dfs:\n",
    "    name=df['SitID'][0]\n",
    "    # Save the DataFrame as a CSV file\n",
    "    output_path = os.path.join(output_dir, f\"predictions_{name}.csv\")\n",
    "    df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dataframes that actually has picks: 136\n",
      "Number of dataframes that has no picks: 14\n"
     ]
    }
   ],
   "source": [
    "actually_has_picks = []\n",
    "\n",
    "# Create a new list to store the dataframes we want to keep\n",
    "no_picks = []\n",
    "\n",
    "for df in test_dfs:\n",
    "    if sum(df['Binary_Predict']) > 0:\n",
    "        actually_has_picks.append(df)\n",
    "    else:\n",
    "        no_picks.append(df)\n",
    "\n",
    "\n",
    "print(f\"Number of dataframes that actually has picks: {len(actually_has_picks)}\")\n",
    "print(f\"Number of dataframes that has no picks: {len(no_picks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation on Test Data\n",
    "\n",
    "After training our model, it's crucial to evaluate its performance on data that it has never seen before, also known as the test data. This step helps us understand how well the model generalizes to new, unseen examples. We use several metrics for this evaluation: Precision, Recall, and the F1 Score.\n",
    "\n",
    "### Evaluation Metrics\n",
    "\n",
    "- **Precision**: This metric tells us the proportion of positive identifications that were actually correct. It is defined as the number of true positives divided by the number of true positives plus the number of false positives.\n",
    "\n",
    "- **Recall**: Also known as sensitivity, this metric tells us the proportion of actual positives that were identified correctly. It is defined as the number of true positives divided by the number of true positives plus the number of false negatives.\n",
    "\n",
    "- **F1 Score**: This is the harmonic mean of Precision and Recall and gives a combined measure of the two metrics. It is particularly useful when the class distribution is imbalanced.\n",
    "\n",
    "### Tolerance Window (`delta_T_depth`)\n",
    "\n",
    "Due to the nature of geological data, the exact pinpointing of formation tops might not be feasible. Therefore, we introduce a tolerance window, `delta_T_depth`, which allows for a small margin of error in the predictions based on depth values (e.g., meters). This tolerance window accounts for the fact that the model's predictions might be a few meters away from the actual formation tops.\n",
    "\n",
    "### Evaluation Process\n",
    "\n",
    "We loop over different values of `delta_T_depth` to understand how the model's performance varies with different levels of strictness in the predictions. For each `delta_T_depth` value, we calculate the Precision, Recall, and F1 Score for each well log in the test dataset based on the depth values. We then compute the average of these metrics across all well logs to get an overall understanding of the model's performance.\n",
    "\n",
    "The code snippet below demonstrates this evaluation process based on depth values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for delta_T_depth = 1m:\n",
      "Average Precision: 0.1174205659882472\n",
      "Average Recall: 0.29662698412698413\n",
      "Average F1 Score: 0.15444306269894437\n",
      "----------\n",
      "Metrics for delta_T_depth = 2m:\n",
      "Average Precision: 0.1392898756891852\n",
      "Average Recall: 0.34957936507936505\n",
      "Average F1 Score: 0.18395041308669893\n",
      "----------\n",
      "Metrics for delta_T_depth = 5m:\n",
      "Average Precision: 0.20316880036824733\n",
      "Average Recall: 0.4687063492063493\n",
      "Average F1 Score: 0.2555780302056498\n",
      "----------\n",
      "Metrics for delta_T_depth = 10m:\n",
      "Average Precision: 0.24910778880865972\n",
      "Average Recall: 0.5548624338624338\n",
      "Average F1 Score: 0.30984364471676\n",
      "----------\n",
      "Metrics for delta_T_depth = 20m:\n",
      "Average Precision: 0.30934390437635195\n",
      "Average Recall: 0.6613624338624339\n",
      "Average F1 Score: 0.3752753402424252\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store metrics for each well log\n",
    "all_precisions = []\n",
    "all_recalls = []\n",
    "all_F1_scores = []\n",
    "\n",
    "# Define the different delta_T values in terms of depth (e.g., meters)\n",
    "delta_T_depth_values = [1, 2, 5, 10,20]  # Example values in meters\n",
    "\n",
    "# Loop over each delta_T value\n",
    "for delta_T_depth in delta_T_depth_values:\n",
    "    # Initialize lists to store metrics for each well log\n",
    "    all_precisions = []\n",
    "    all_recalls = []\n",
    "    all_F1_scores = []\n",
    "\n",
    "    # Loop over each well log\n",
    "    for i in range(len(test_dfs)):\n",
    "        ground_truth_depths = test_dfs[i].loc[test_dfs[i]['Pick'] == 1, 'DEPT']  # Depths of actual formation tops\n",
    "        prediction_depths = test_dfs[i].loc[test_dfs[i]['Binary_Predict'] == 1, 'DEPT']  # Depths of predicted formation tops\n",
    "\n",
    "        # 2. Precision\n",
    "        true_positives = sum(any(abs(gt_depth - prediction_depths) <= delta_T_depth) for gt_depth in ground_truth_depths)\n",
    "        prec = true_positives / len(prediction_depths) if len(prediction_depths) > 0 else 0\n",
    "        all_precisions.append(prec)\n",
    "\n",
    "        # 3. Recall\n",
    "        detected_tops = sum(any(abs(gt_depth - prediction_depths) <= delta_T_depth) for gt_depth in ground_truth_depths)\n",
    "        rec = detected_tops / len(ground_truth_depths) if len(ground_truth_depths) > 0 else 0\n",
    "        all_recalls.append(rec)\n",
    "\n",
    "        # 4. F1 Score\n",
    "        if prec + rec > 0:  # Avoid division by zero\n",
    "            F1 = 2 * (prec * rec) / (prec + rec)\n",
    "        else:\n",
    "            F1 = 0\n",
    "        all_F1_scores.append(F1)\n",
    "\n",
    "    # Compute average metrics across all well logs\n",
    "    average_precision = np.mean(all_precisions)\n",
    "    average_recall = np.mean(all_recalls)\n",
    "    average_F1_score = np.mean(all_F1_scores)\n",
    "\n",
    "    # Print the average metrics for the current delta_T_depth\n",
    "    print(f\"Metrics for delta_T_depth = {delta_T_depth}m:\")\n",
    "    print(\"Average Precision:\", average_precision)\n",
    "    print(\"Average Recall:\", average_recall)\n",
    "    print(\"Average F1 Score:\", average_F1_score)\n",
    "    print(\"----------\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
