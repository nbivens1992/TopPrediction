{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Formation Tops from Well Log Data using CNN\n",
    "\n",
    "CNNs are powerful tools for pattern recognition and feature extraction in various types of data, including images, time-series, and, in your case, geological log curve data. Here's why they are suitable for this task:\n",
    "\n",
    "<b>Feature Extraction:</b> CNNs can automatically learn and extract relevant features from the input data. In your scenario, the model can learn to identify patterns in gamma ray, resistivity, and density porosity curves that are indicative of formation tops.\n",
    "\n",
    "<b>Spatial Hierarchy:</b> CNNs can capture the hierarchical spatial structures present in the data. This is crucial for understanding the geological layers and their properties.\n",
    "\n",
    "<b>Translation Invariance:</b> CNNs are robust to shifts and distortions in the input data, which is beneficial when dealing with natural variations in geological formations.\n",
    "Efficient Parameter Usage: CNNs share weights across different parts of the input, making them more parameter-efficient compared to fully connected networks. This is especially useful when dealing with large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "from keras.layers import Normalization, Lambda\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-Net Architecture\n",
    "\n",
    "The U-Net architecture is a type of convolutional neural network that was originally designed for biomedical image segmentation. The combination of global and local views in a U-Net architecture allows the model to understand both the broader context and the finer details of the input data, which is crucial for tasks like predicting formation tops in geological data. Here are common parts of a U-Net architecture\n",
    "- Contracting Path: The contracting path is similar to a typical convolutional network. It consists of repeated application of convolutions, followed by a rectified linear unit (ReLU) and a max pooling operation. With each downsampling step, the network increases the number of feature channels.\n",
    "\n",
    "- Expansive Path: The expansive path consists of upsampling of the feature map followed by a convolution (\"up-convolution\"), which halves the number of feature channels, a concatenation with the correspondingly cropped feature map from the contracting path, and two more convolutions, each followed by a ReLU. The cropping is necessary due to the loss of border pixels in every convolution.\n",
    "\n",
    "- Skip Connections: The key innovation in U-Net is the use of skip connections, where outputs from the contracting path are concatenated with inputs to the expansive path. These connections provide the expansive path with the context information lost during downsampling, which is crucial for precise localization.\n",
    "\n",
    "### Global View \n",
    "\n",
    "The global view in a U-Net architecture refers to the initial layers of the network where the input data is progressively downsampled (pooled). The purpose of the global view is to:\n",
    "\n",
    "<b>Capture Context:</b> By looking at the broader picture, the global view helps the model understand the overall context of the data. In geological terms, this might mean understanding the general trends and structures across a wide depth range.\n",
    "\n",
    "<b>Reduce Dimensionality:</b> Pooling layers reduce the spatial dimensions of the feature maps, which decreases the computational complexity and helps in focusing on the more salient features.\n",
    "\n",
    "<b>Increase Receptive Field:</b> As the data is downsampled, the receptive field of the neurons increases, allowing them to capture more global features that are relevant for the prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_module(input_tensor, filter_channels):\n",
    "    # Branch 1: 1x1 conv\n",
    "    branch1x1 = layers.Conv1D(filter_channels, 1, padding='same', activation='relu',dilation_rate=2)(input_tensor)\n",
    "    \n",
    "    # Branch 2: 1x1 conv followed by 3x3 conv\n",
    "    branch3x3 = layers.Conv1D(filter_channels, 3, padding='same', activation='relu', dilation_rate=4)(input_tensor)\n",
    "    \n",
    "    # Branch 3: 1x1 conv followed by 5x5 conv\n",
    "    branch5x5 = layers.Conv1D(filter_channels, 5, padding='same', activation='relu', dilation_rate=8)(input_tensor)\n",
    "    \n",
    "    # branch_pool = layers.MaxPooling1D(3, strides=1, padding='same')(input_tensor)\n",
    "    # branch_pool = layers.Conv1D(filter_channels, 1, padding='same', activation='relu')(input_tensor)\n",
    "    \n",
    "    # Concatenate all the branches\n",
    "    concatenated = layers.Concatenate(axis=-1)([branch1x1, branch3x3, branch5x5])\n",
    "    \n",
    "    return concatenated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_global_view(initial_layer = 4, dropout = 0.2):\n",
    "    inputs = layers.Input(shape=(None, 3))  # Assuming the logs are 1D sequences\n",
    "    x = layers.Masking(mask_value=-99)(inputs)  # Using -99 as the mask value\n",
    "    \n",
    "    # Encoding layer 1\n",
    "    conv1 = inception_module(x, initial_layer)\n",
    "    conv1 = layers.BatchNormalization()(conv1)\n",
    "    conv1 = layers.Dropout(dropout)(conv1)\n",
    "    pool1 = layers.MaxPooling1D()(conv1)\n",
    "\n",
    "    # Encoding layer 2\n",
    "    conv2 = inception_module(pool1, initial_layer*2)\n",
    "    conv2 = layers.BatchNormalization()(conv2)\n",
    "    conv2 = layers.Dropout(dropout)(conv2)\n",
    "    pool2 = layers.MaxPooling1D()(conv2)\n",
    "\n",
    "    # Middle layer\n",
    "    conv_middle = inception_module(pool2,initial_layer*4)\n",
    "    conv_middle = layers.BatchNormalization()(conv_middle)\n",
    "    conv_middle = layers.Dropout(dropout)(conv_middle)\n",
    "    \n",
    "    # # Middle layer2\n",
    "    # conv_middle = layers.Conv1D(2*initial_layer, 3, activation=\"relu\", padding=\"same\",dilation_rate=4)(pool1)\n",
    "    # conv_middle = layers.BatchNormalization()(conv_middle)\n",
    "    # conv_middle = layers.Dropout(dropout)(conv_middle)\n",
    "\n",
    "    # Decoding layer 1\n",
    "    up1 = layers.UpSampling1D()(conv_middle)\n",
    "    merge1 = layers.concatenate([conv2, up1]) \n",
    "    # merge1 = layers.concatenate([conv1, up1])\n",
    "    \n",
    "    decode1 = inception_module(merge1,initial_layer*2)\n",
    "    decode1 = layers.BatchNormalization()(decode1)\n",
    "    decode1 = layers.Dropout(dropout)(decode1)\n",
    "    # Decoding layer 2\n",
    "    up2 = layers.UpSampling1D()(decode1)\n",
    "    \n",
    "    # Ensure sizes match before concatenating for the second merge\n",
    "    merge2 = layers.concatenate([conv1, up2])\n",
    "\n",
    "    decode2 = inception_module(merge2, initial_layer)\n",
    "    decode2 = layers.BatchNormalization()(decode2)\n",
    "    decode2 = layers.Dropout(dropout)(decode2)\n",
    "    \n",
    "    # output = layers.Activation(activation=\"tanh\")(decode2)\n",
    "\n",
    "    return models.Model(inputs, decode2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local View\n",
    "\n",
    "The local view, often represented by the latter layers of the U-Net or specialized layers like inception modules with dilated convolutions, focuses on finer details. Its purposes include:\n",
    "\n",
    "Detail Preservation: The local view helps in preserving and highlighting the finer details and local features that might be crucial for accurate prediction of formation tops.\n",
    "High-Resolution Feature Maps: As the data is upsampled or processed through dilated convolutions, the feature maps regain their resolution, allowing the model to make more precise localizations.\n",
    "Combining Context with Detail: By concatenating the upsampled feature maps with the corresponding feature maps from the downsampling path (skip connections), the model effectively combines the global context with local details, which is essential for accurate segmentation or prediction tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_local_view(initial_filters=2, input_shape=(None, 3), mask_value=-99):\n",
    "    # Input layer\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Masking layer\n",
    "    x = layers.Masking(mask_value=mask_value)(inputs)\n",
    "    \n",
    "    conv1 = inception_module(x,initial_filters)\n",
    "    \n",
    "    conv2 = inception_module(conv1,initial_filters)\n",
    "    \n",
    "    # conv3 = inception_module(conv2,initial_filters)\n",
    "    \n",
    "    # output = layers.Conv1D(1, kernel_size=1, padding='same', activation='tanh')(conv2)\n",
    "    \n",
    "    return models.Model(inputs, conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation for U-Net Model\n",
    "\n",
    "Our U-Net model requires the input data to adhere to specific dimensional constraints for it to process the data effectively. To ensure compatibility with the model's architecture, we perform the following preprocessing steps on each well's log data:\n",
    "\n",
    "### Normalization\n",
    "Firstly, we normalize the data to ensure that the model receives inputs that are on a similar scale. This is crucial for the model's convergence and performance. The normalization is performed using the following formula:\n",
    "\n",
    "$$ \\text{normalized\\_data} = \\frac{\\text{data} - \\text{mean}}{\\text{std}} $$\n",
    "\n",
    "where `mean` and `std` are the mean and standard deviation of the training data, respectively.\n",
    "\n",
    "### Ensuring Even Length\n",
    "The U-Net architecture involves multiple layers of downsampling and upsampling. To avoid any off-by-one errors during these operations, we need to ensure that the input data's length is even and remains even when divided by 2 and 4. We achieve this by:\n",
    "\n",
    "1. **Appending Padding**: If the sequence length is odd, we append a padding row to make it even. This padding is set to a specific value (e.g., -99) that the model can recognize and ignore during processing.\n",
    "\n",
    "2. **Adjusting Maximum Length**: We calculate the maximum length across all sequences and adjust it to ensure that it is even and divisible by 2 and 4. This adjustment is necessary to maintain the integrity of the data's spatial dimensions throughout the U-Net's downsampling and upsampling pathways.\n",
    "\n",
    "3. **Padding to Maximum Length**: Finally, we pad all sequences to this adjusted maximum length. This uniformity is essential for batch processing and allows the model to process multiple sequences simultaneously.\n",
    "\n",
    "By adhering to these preprocessing steps, we ensure that our U-Net model receives well-formatted input data, which is crucial for accurate predictions. The padding added during these steps is carefully handled by the model and does not significantly impact its predictive performance.\n",
    "\n",
    "### Gaussian Smoothing\n",
    "Gaussian smoothing is a technique that is particularly useful for addressing data imbalance issues in machine learning tasks, especially when dealing with time series or spatial data. When you have a dataset with a binary classification problem and one class (like well top selection) is significantly underrepresented, this can lead to a model that doesn't perform well on the minority class because it hasn't had enough examples to learn from. This will create a gaussian kernal around the top selection to help make the mdoel mroe accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "In this section, we define and train our U-Net model for the task of predicting formation tops in geological data. The model utilizes a combination of global and local views to capture both the broader context and fine details necessary for accurate predictions.\n",
    "\n",
    "### Binary Cross entropy\n",
    "\n",
    "Binary Cross-Entropy, also known as log loss, measures the performance of a classification model whose output is a probability value between 0 and 1. It's a commonly used loss function for binary classification tasks. Binary Cross-Entropy loss increases as the predicted probability diverges from the actual label, being more punitive for predictions that are confidently incorrect.\n",
    "\n",
    "### Model Architecture\n",
    "\n",
    "The model architecture combines the outputs of the global and local views using a multiplication operation. This combined output is then passed through a soft attention mechanism, implemented using a tanh activation function, to highlight the regions of interest. The final output is obtained using a 1D convolutional layer with a sigmoid activation function, which provides the probability of a formation top at each depth.\n",
    "\n",
    "### Training Process\n",
    "The model is trained using the Adam optimizer and the focal loss function. We employ an early stopping mechanism to prevent overfitting, where training is halted if the validation loss does not improve for a specified number of epochs (patience). The training and validation losses are plotted at the end of the training process to visualize the model's learning progress.\n",
    "\n",
    "During training, each well's log data is processed in batches. The model is trained on each batch, and the losses are recorded. The training loop also includes a validation step to monitor the model's performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras import backend as K\n",
    "\n",
    "# def focal_loss(gamma=2., alpha=0.8):\n",
    "#     def focal_loss_fixed(y_true, y_pred):\n",
    "#         pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "#         pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "#         return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) - K.sum((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n",
    "#     return focal_loss_fixed\n",
    "\n",
    "def train_model(X_train, y_train, X_val, y_val, learning_rate, epochs, nodes, dropout):\n",
    "    global_view = create_global_view(initial_layer=nodes,dropout = dropout)\n",
    "    local_view = create_local_view(initial_filters=nodes)\n",
    "    \n",
    "    # Apply tanh activation to both global and local views\n",
    "    activated_global_view = layers.Activation('sigmoid')(global_view.output)\n",
    "    activated_local_view = layers.Activation('sigmoid')(local_view.output)\n",
    "\n",
    "\n",
    "    # Element-wise multiplication of the activated global and local views\n",
    "    combined_features = layers.Multiply()([activated_global_view, activated_local_view])\n",
    "    \n",
    "    # # Generate attention scores, here we assume a simple 1D convolution followed by a softmax activation to get normalized attention scores\n",
    "    # attention_scores = layers.Conv1D(1, kernel_size=1, padding='same', activation='tanh')(combined_features)\n",
    "    \n",
    "    # # Apply attention scores to combined features\n",
    "    # attended_features = layers.Multiply()([attention_scores, combined_features])\n",
    "\n",
    "    # HYPERPARAMETER: Adjust the number of filters (1) and kernel size (1)\n",
    "    output = layers.Conv1D(1, 1, activation=\"sigmoid\")(combined_features)\n",
    "\n",
    "    model = models.Model([global_view.input, local_view.input], output)\n",
    "    optimizer = Adam()\n",
    "\n",
    "    # # HYPERPARAMETER: Adjust the optimizer ('adam') and its parameters\n",
    "    # model.compile(optimizer=optimizer, loss= focal_loss(alpha=alpha))\n",
    "    \n",
    "    # HYPERPARAMETER: Adjust the optimizer ('adam') and its parameters\n",
    "    model.compile(optimizer=optimizer, loss= tf.losses.BinaryCrossentropy())\n",
    "\n",
    "\n",
    "    # Early stopping parameters\n",
    "    patience = 5\n",
    "    min_delta = 0.001\n",
    "    best_val_loss = float('inf')\n",
    "    wait = 0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    # We'll only use this training loop and remove the redundant one.\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        \n",
    "        # Training\n",
    "        epoch_train_losses = []\n",
    "        for i in range(len(X_train)):\n",
    "            X_train_well = X_train[i].reshape(1, X_train[i].shape[0], X_train[i].shape[1])\n",
    "            y_train_well = y_train[i].reshape(1, y_train[i].shape[0], 1)\n",
    "           \n",
    "            loss = model.train_on_batch([X_train_well, X_train_well], y_train_well)  # Capturing the loss\n",
    "            epoch_train_losses.append(loss)\n",
    "        mean_train_loss = np.mean(epoch_train_losses)\n",
    "        train_losses.append(np.mean(mean_train_loss))\n",
    "\n",
    "        # Validation (optional)\n",
    "        epoch_val_losses = []\n",
    "        for i in range(len(X_val)):\n",
    "            X_val_well = X_val[i].reshape(1, X_val[i].shape[0], X_val[i].shape[1])\n",
    "            y_val_well = y_val[i].reshape(1, y_val[i].shape[0], 1)\n",
    "            loss = model.test_on_batch([X_val_well, X_val_well], y_val_well)\n",
    "            epoch_val_losses.append(loss)\n",
    "        mean_val_loss = np.mean(epoch_val_losses)\n",
    "        val_losses.append(mean_val_loss)\n",
    "        print(f\"Training Loss: {train_losses[-1]:.5f}, Validation Loss: {mean_val_loss:.5f}\")\n",
    "\n",
    "        # Early stopping check\n",
    "        if (best_val_loss - mean_val_loss) > min_delta:\n",
    "            best_val_loss = mean_val_loss\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}. Best validation loss: {best_val_loss:.5f}\")\n",
    "                break\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label=\"Training Loss\")\n",
    "    plt.plot(val_losses, label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training and Validation Loss Curves\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(folder_path):\n",
    "    files = [f for f in os.listdir(folder_path) if f.endswith(\".csv\")]\n",
    "\n",
    "    max_length = 0\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        df = pd.read_csv(folder_path + file)\n",
    "        if len(df.index)>max_length:\n",
    "            max_length = len(df.index)\n",
    "        dfs.append(df)\n",
    "        \n",
    "    train_dfs, val_dfs = train_test_split(dfs, test_size=0.2, random_state=42) # Here 20% of the data is kept for validation\n",
    "    \n",
    "    train_dfs = [pad_dataframe(df, max_length) for df in train_dfs]\n",
    "    val_dfs = [pad_dataframe(df, max_length) for df in val_dfs]\n",
    "\n",
    "    features = [\"GR\", \"ILD\", \"DPHI\"]\n",
    "\n",
    "    # Compute the mean and standard deviation of the training data\n",
    "    all_train_data = np.vstack([df[features].values for df in train_dfs])\n",
    "    mean = np.mean(all_train_data, axis=0)\n",
    "    std = np.std(all_train_data, axis=0)\n",
    "\n",
    "    # Extract features and labels for training and validation sets\n",
    "    X_train = np.array([df[features].values for df in train_dfs])\n",
    "    y_train = np.array([df[\"Pick\"].values for df in train_dfs])\n",
    "\n",
    "    X_val = np.array([df[features].values for df in val_dfs])\n",
    "    y_val = np.array([df[\"Pick\"].values for df in val_dfs])\n",
    "\n",
    "\n",
    "    # Normalize data\n",
    "    X_train = [normalize_data(x, mean, std) for x in X_train]\n",
    "    X_val = [normalize_data(x, mean, std) for x in X_val]\n",
    "\n",
    "    # Ensure even length\n",
    "    X_train = [ensure_even_length(x) for x in X_train]\n",
    "    X_val = [ensure_even_length(x) for x in X_val]\n",
    "\n",
    "    # Compute max_length after ensuring even lengths\n",
    "    max_length2 = max(max(x.shape[0] for x in X_train), max(x.shape[0] for x in X_val))\n",
    "\n",
    "    # Pad to max_length\n",
    "    X_train = [pad_to_max_length(x, max_length2) for x in X_train]\n",
    "    X_val = [pad_to_max_length(x, max_length2) for x in X_val]\n",
    "\n",
    "    # # smooth y values\n",
    "    y_train = [smooth_labels(y) for y in y_train]\n",
    "    y_val = [smooth_labels(y) for y in y_val]\n",
    "\n",
    "    # Ensure even length for labels and then pad\n",
    "    y_train = [ensure_even_length(y.reshape(-1, 1),padding_value=0) for y in y_train]\n",
    "    y_val = [ensure_even_length(y.reshape(-1, 1),padding_value=0) for y in y_val]\n",
    "\n",
    "    y_train = [pad_to_max_length(y, max_length2,padding_value=0) for y in y_train]\n",
    "    y_val = [pad_to_max_length(y, max_length2,padding_value=0) for y in y_val]\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val , mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data(folder_path, train_mean, train_std):\n",
    "    files = [f for f in os.listdir(folder_path) if f.endswith(\".csv\")]\n",
    "    test_dfs = []\n",
    "    max_length = 0\n",
    "    for file in files:\n",
    "        df = pd.read_csv(folder_path + file)\n",
    "        if len(df.index)>max_length:\n",
    "            max_length = len(df.index)\n",
    "        test_dfs.append(df)\n",
    "\n",
    "    features = [\"GR\", \"ILD\", \"DPHI\"]\n",
    "\n",
    "    test_dfs = [pad_dataframe(df, max_length) for df in test_dfs]\n",
    "    \n",
    "    # Extract features and labels for training and validation sets\n",
    "    X_test = np.array([df[features].values for df in test_dfs])\n",
    "    y_test = np.array([df[\"Pick\"].values for df in test_dfs])\n",
    "\n",
    "    # Normalize data\n",
    "    X_test = [normalize_data(x, train_mean, train_std) for x in X_test]\n",
    "\n",
    "    # Ensure multiple of 8 for UNET\n",
    "    X_test = [ensure_even_length(x) for x in X_test]\n",
    "    \n",
    "    # Compute max_length after ensuring even lengths\n",
    "    max_length = max(x.shape[0] for x in X_test)\n",
    "    \n",
    "    # Pad to max_length\n",
    "    X_test = [pad_to_max_length(x, max_length) for x in X_test]\n",
    "    \n",
    "    # # Ensure multiple of 8 length for labels and then pad\n",
    "    y_test = [smooth_labels(y) for y in y_test]\n",
    "    \n",
    "    # Ensure even length for labels and then pad\n",
    "    y_test = [ensure_even_length(y.reshape(-1, 1),padding_value=0) for y in y_test]\n",
    "    \n",
    "    y_test = [pad_to_max_length(y, max_length,padding_value=0) for y in y_test]\n",
    "    \n",
    "    test_dfs = [pad_dataframe(df, max_length) for df in test_dfs]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # # Update the 'Pick' column in test_dfs with y_test values\n",
    "    # for i, df in enumerate(test_dfs):\n",
    "    #     df['Pick'] = y_test[i][:len(df)]  # Assuming y_test[i] is already the correct length\n",
    "    \n",
    "    \n",
    "    return X_test, y_test, test_dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(test_df, X_test,y_test, model, formation_test_data, top_percentile=99):\n",
    "    x_reshape = X_test.reshape(1, X_test.shape[0], X_test.shape[1])\n",
    "    predictions = model.predict([x_reshape, x_reshape])\n",
    "    \n",
    "    # Flatten the predictions to 1D array for easier indexing\n",
    "    predictions_flat = predictions.flatten()\n",
    "    \n",
    "    # Initialize binary_predictions to all zeros\n",
    "    binary_predictions = np.zeros_like(predictions_flat, dtype=int)\n",
    "    \n",
    "    # Find the index of the maximum prediction probability\n",
    "    max_prob_index = np.argmax(predictions_flat)\n",
    "    \n",
    "    # Set only the max index to 1\n",
    "    binary_predictions[max_prob_index] = 1\n",
    "    \n",
    "    test_df['Binary_Predict'] = binary_predictions.flatten()\n",
    "    test_df['Predict'] = predictions.flatten()\n",
    "    test_df['Acutal Pick']=y_test.flatten()\n",
    "    name=test_df['SitID'][0]\n",
    "    \n",
    "    os.makedirs(formation_test_data+\"/Predictions\", exist_ok=True)\n",
    "    # Save the DataFrame as a CSV file\n",
    "    output_path = os.path.join(formation_test_data+\"/Predictions\", f\"predictions_{name}.csv\")\n",
    "    test_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation on Test Data\n",
    "\n",
    "After training our model, it's crucial to evaluate its performance on data that it has never seen before, also known as the test data. This step helps us understand how well the model generalizes to new, unseen examples. We use several metrics for this evaluation: Precision, Recall, and the F1 Score.\n",
    "\n",
    "### Evaluation Metrics\n",
    "\n",
    "- **Precision**: This metric tells us the proportion of positive identifications that were actually correct. It is defined as the number of true positives divided by the number of true positives plus the number of false positives.\n",
    "\n",
    "- **Recall**: Also known as sensitivity, this metric tells us the proportion of actual positives that were identified correctly. It is defined as the number of true positives divided by the number of true positives plus the number of false negatives.\n",
    "\n",
    "- **F1 Score**: This is the harmonic mean of Precision and Recall and gives a combined measure of the two metrics. It is particularly useful when the class distribution is imbalanced.\n",
    "\n",
    "### Tolerance Window (`delta_T_depth`)\n",
    "\n",
    "Due to the nature of geological data, the exact pinpointing of formation tops might not be feasible. Therefore, we introduce a tolerance window, `delta_T_depth`, which allows for a small margin of error in the predictions based on depth values (e.g., meters). This tolerance window accounts for the fact that the model's predictions might be a few meters away from the actual formation tops.\n",
    "\n",
    "### Evaluation Process\n",
    "\n",
    "We loop over different values of `delta_T_depth` to understand how the model's performance varies with different levels of strictness in the predictions. For each `delta_T_depth` value, we calculate the Precision, Recall, and F1 Score for each well log in the test dataset based on the depth values. We then compute the average of these metrics across all well logs to get an overall understanding of the model's performance.\n",
    "\n",
    "The code snippet below demonstrates this evaluation process based on depth values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(test_dfs):\n",
    "    metrics_at_delta_T = {}\n",
    "    # Initialize lists to store metrics for each well log\n",
    "    all_precisions = []\n",
    "    all_recalls = []\n",
    "    all_F1_scores = []\n",
    "\n",
    "    # Define the different delta_T values in terms of depth (e.g., meters)\n",
    "    delta_T_depth_values = [0.5, 1, 2, 3, 6]  # Example values in meters\n",
    "\n",
    "    # Loop over each delta_T value\n",
    "    for delta_T_depth in delta_T_depth_values:\n",
    "        # Initialize lists to store metrics for each well log\n",
    "        all_precisions = []\n",
    "        all_recalls = []\n",
    "        all_F1_scores = []\n",
    "\n",
    "        # Loop over each well log\n",
    "        for i in range(len(test_dfs)):\n",
    "            ground_truth_depths = test_dfs[i].loc[test_dfs[i]['Pick'] == 1, 'DEPT']  # Depths of actual formation tops\n",
    "            prediction_depths = test_dfs[i].loc[test_dfs[i]['Binary_Predict'] == 1, 'DEPT']  # Depths of predicted formation tops\n",
    "\n",
    "            # 2. Precision\n",
    "            true_positives = sum(np.any(np.abs(gt_depth - prediction_depths) <= delta_T_depth) for gt_depth in ground_truth_depths)\n",
    "            prec = true_positives / len(prediction_depths) if len(prediction_depths) > 0 else 0\n",
    "            all_precisions.append(prec)\n",
    "\n",
    "            # 3. Recall\n",
    "            detected_tops = sum(np.any(np.abs(gt_depth - prediction_depths) <= delta_T_depth) for gt_depth in ground_truth_depths)\n",
    "            rec = detected_tops / len(ground_truth_depths) if len(ground_truth_depths) > 0 else 0\n",
    "            all_recalls.append(rec)\n",
    "\n",
    "            # 4. F1 Score\n",
    "            if prec + rec > 0:  # Avoid division by zero\n",
    "                F1 = 2 * (prec * rec) / (prec + rec)\n",
    "            else:\n",
    "                F1 = 0\n",
    "            all_F1_scores.append(F1)\n",
    "\n",
    "        # Compute average metrics across all well logs\n",
    "        average_precision = np.mean(all_precisions)\n",
    "        average_recall = np.mean(all_recalls)\n",
    "        average_F1_score = np.mean(all_F1_scores)\n",
    "\n",
    "        # Print the average metrics for the current delta_T_depth\n",
    "        print(f\"Metrics for delta_T_depth = {delta_T_depth}m:\")\n",
    "        print(\"Average Precision:\", average_precision)\n",
    "        print(\"Average Recall:\", average_recall)\n",
    "        print(\"Average F1 Score:\", average_F1_score)\n",
    "        print(\"----------\")\n",
    "        \n",
    "         # Store the metrics for the current delta_T_depth in the dictionary\n",
    "        metrics_at_delta_T[delta_T_depth] = {\n",
    "            'average_precision': average_precision,\n",
    "            'average_recall': average_recall,\n",
    "            'average_f1': average_F1_score\n",
    "        }\n",
    "    return metrics_at_delta_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1000', '2000', '3000', '4000', '5000', '6000', '7000', '9000', '9500', '10000', '11000', '12000', '13000', '14000']\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "# Train your model here\n",
    "folder_path = current_dir + \"/Data/Formation_DATA/\"\n",
    "\n",
    "formations = os.listdir(folder_path)\n",
    "formations = sorted(formations, key=lambda x: int(x))\n",
    "print(formations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize function\n",
    "def normalize_data(data, mean, std):\n",
    "    return (data - mean) / std\n",
    "\n",
    "\n",
    "def ensure_even_length(sequence, padding_value=-99):\n",
    "    current_rows = sequence.shape[0]\n",
    "\n",
    "    # Calculate the number of rows needed to make it a multiple of 8\n",
    "    rows_needed_to_multiple_of_8 = 8 - (current_rows % 8)\n",
    "\n",
    "    # Determine the total rows needed\n",
    "    total_rows_needed = rows_needed_to_multiple_of_8\n",
    "\n",
    "    if total_rows_needed > 0:\n",
    "        # Create padding with the same number of columns as the sequence\n",
    "        padding_shape = (total_rows_needed,) + sequence.shape[1:]\n",
    "        padding = np.full(padding_shape, padding_value)\n",
    "\n",
    "        # Append padding to the sequence\n",
    "        sequence = np.vstack([sequence, padding])\n",
    "\n",
    "    return sequence\n",
    "\n",
    "def pad_to_max_length(sequence, max_length, padding_value=-99):\n",
    "    padding = [(0, max_length - sequence.shape[0]), (0, 0)]\n",
    "    return np.pad(sequence, padding, mode='constant', constant_values=padding_value)\n",
    "\n",
    "\n",
    "def adjust_max_length(max_length):\n",
    "    last_digit = max_length % 10\n",
    "    \n",
    "    if last_digit in [2, 6]:\n",
    "        return max_length + 2\n",
    "    elif last_digit == 0:\n",
    "        return max_length + 4\n",
    "    else:\n",
    "        return max_length\n",
    "    \n",
    "def smooth_labels(y, sigma=2):\n",
    "    # Ensure y is a 1D array\n",
    "    y = y.flatten()\n",
    "    smoothed_y = np.zeros_like(y, dtype=float)\n",
    "    for idx in np.where(y == 1)[0]:\n",
    "        gaussian = np.exp(-0.5 * ((np.arange(len(y)) - idx) / sigma) ** 2)\n",
    "        gaussian /= gaussian.sum()\n",
    "        smoothed_y += 5.1*gaussian  # Both are 1D arrays, so this should work\n",
    "    smoothed_y = np.clip(smoothed_y, None, 1)\n",
    "    return smoothed_y\n",
    "\n",
    "def pad_dataframe(df, desired_length, padding_value=-99):\n",
    "    # Calculate the number of rows to add\n",
    "    num_rows_to_add = desired_length - len(df)\n",
    "    \n",
    "    # If the dataframe is already longer or equal to the desired length, return the original dataframe\n",
    "    if num_rows_to_add <= 0:\n",
    "        return df\n",
    "    \n",
    "    # Create a new dataframe with the required number of rows filled with the padding value\n",
    "    padding_df = pd.DataFrame(padding_value, index=range(num_rows_to_add), columns=df.columns)\n",
    "    \n",
    "    # Concatenate the original dataframe with the padding dataframe\n",
    "    padded_df = pd.concat([df, padding_df], axis=0).reset_index(drop=True)\n",
    "    \n",
    "    return padded_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting trainging for formation: 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "Training Loss: 0.36467, Validation Loss: 0.16567\n",
      "Epoch 2/200\n",
      "Training Loss: 0.15286, Validation Loss: 0.09302\n",
      "Epoch 3/200\n",
      "Training Loss: 0.08921, Validation Loss: 0.06287\n",
      "Epoch 4/200\n",
      "Training Loss: 0.06230, Validation Loss: 0.04827\n",
      "Epoch 5/200\n",
      "Training Loss: 0.04843, Validation Loss: 0.03997\n",
      "Epoch 6/200\n",
      "Training Loss: 0.03978, Validation Loss: 0.03200\n",
      "Epoch 7/200\n",
      "Training Loss: 0.03403, Validation Loss: 0.02799\n",
      "Epoch 8/200\n",
      "Training Loss: 0.03099, Validation Loss: 0.02630\n",
      "Epoch 9/200\n",
      "Training Loss: 0.02907, Validation Loss: 0.02539\n",
      "Epoch 10/200\n",
      "Training Loss: 0.02768, Validation Loss: 0.02473\n",
      "Epoch 11/200\n",
      "Training Loss: 0.02681, Validation Loss: 0.02477\n",
      "Epoch 12/200\n",
      "Training Loss: 0.02620, Validation Loss: 0.02406\n",
      "Epoch 13/200\n",
      "Training Loss: 0.02568, Validation Loss: 0.02354\n",
      "Epoch 14/200\n",
      "Training Loss: 0.02531, Validation Loss: 0.02318\n",
      "Epoch 15/200\n",
      "Training Loss: 0.02489, Validation Loss: 0.02280\n",
      "Epoch 16/200\n",
      "Training Loss: 0.02452, Validation Loss: 0.02268\n",
      "Epoch 17/200\n",
      "Training Loss: 0.02352, Validation Loss: 0.02070\n",
      "Epoch 18/200\n",
      "Training Loss: 0.02256, Validation Loss: 0.01948\n",
      "Epoch 19/200\n",
      "Training Loss: 0.02205, Validation Loss: 0.01821\n",
      "Epoch 20/200\n",
      "Training Loss: 0.02023, Validation Loss: 0.01628\n",
      "Epoch 21/200\n",
      "Training Loss: 0.01866, Validation Loss: 0.01530\n",
      "Epoch 22/200\n",
      "Training Loss: 0.01816, Validation Loss: 0.01652\n",
      "Epoch 23/200\n",
      "Training Loss: 0.01779, Validation Loss: 0.01494\n",
      "Epoch 24/200\n",
      "Training Loss: 0.01737, Validation Loss: 0.01643\n",
      "Epoch 25/200\n",
      "Training Loss: 0.01721, Validation Loss: 0.01666\n",
      "Epoch 26/200\n",
      "Training Loss: 0.01700, Validation Loss: 0.01864\n",
      "Epoch 27/200\n",
      "Training Loss: 0.01672, Validation Loss: 0.01568\n",
      "Epoch 28/200\n",
      "Training Loss: 0.01644, Validation Loss: 0.01494\n",
      "Early stopping at epoch 28. Best validation loss: 0.01494\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\nbive\\anaconda3\\DS2 Project/Model/1000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\nbive\\anaconda3\\DS2 Project/Model/1000/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 991ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Metrics for delta_T_depth = 0.5m:\n",
      "Average Precision: 0.16\n",
      "Average Recall: 0.16\n",
      "Average F1 Score: 0.16\n",
      "----------\n",
      "Metrics for delta_T_depth = 1m:\n",
      "Average Precision: 0.32\n",
      "Average Recall: 0.32\n",
      "Average F1 Score: 0.32\n",
      "----------\n",
      "Metrics for delta_T_depth = 2m:\n",
      "Average Precision: 0.58\n",
      "Average Recall: 0.58\n",
      "Average F1 Score: 0.58\n",
      "----------\n",
      "Metrics for delta_T_depth = 3m:\n",
      "Average Precision: 0.7\n",
      "Average Recall: 0.7\n",
      "Average F1 Score: 0.7\n",
      "----------\n",
      "Metrics for delta_T_depth = 6m:\n",
      "Average Precision: 0.78\n",
      "Average Recall: 0.78\n",
      "Average F1 Score: 0.78\n",
      "----------\n",
      "starting trainging for formation: 2000\n",
      "Epoch 1/200\n",
      "Training Loss: 0.52505, Validation Loss: 0.28989\n",
      "Epoch 2/200\n",
      "Training Loss: 0.28039, Validation Loss: 0.17057\n",
      "Epoch 3/200\n",
      "Training Loss: 0.16040, Validation Loss: 0.10528\n",
      "Epoch 4/200\n",
      "Training Loss: 0.10114, Validation Loss: 0.07421\n",
      "Epoch 5/200\n",
      "Training Loss: 0.07181, Validation Loss: 0.05655\n",
      "Epoch 6/200\n",
      "Training Loss: 0.05580, Validation Loss: 0.04628\n",
      "Epoch 7/200\n",
      "Training Loss: 0.04636, Validation Loss: 0.04011\n",
      "Epoch 8/200\n",
      "Training Loss: 0.04070, Validation Loss: 0.03619\n",
      "Epoch 9/200\n",
      "Training Loss: 0.03695, Validation Loss: 0.03349\n",
      "Epoch 10/200\n",
      "Training Loss: 0.03432, Validation Loss: 0.03161\n",
      "Epoch 11/200\n",
      "Training Loss: 0.03253, Validation Loss: 0.03018\n",
      "Epoch 12/200\n",
      "Training Loss: 0.03122, Validation Loss: 0.02923\n",
      "Epoch 13/200\n",
      "Training Loss: 0.03036, Validation Loss: 0.02852\n",
      "Epoch 14/200\n",
      "Training Loss: 0.02953, Validation Loss: 0.02795\n",
      "Epoch 15/200\n",
      "Training Loss: 0.02899, Validation Loss: 0.02744\n",
      "Epoch 16/200\n"
     ]
    }
   ],
   "source": [
    "# Initialize dictionaries to store metrics for each formation and delta_T\n",
    "recall_metrics = {0.5: [], 1: [], 2: [], 3: [], 6: []}\n",
    "precision_metrics = {0.5: [], 1: [], 2: [], 3: [], 6: []}\n",
    "f1_metrics = {0.5: [], 1: [], 2: [], 3: [], 6: []}\n",
    "\n",
    "models_list=[]\n",
    "model_metrics = {}\n",
    "\n",
    "# formations = ['9000','10000','11000','12000']\n",
    "\n",
    "for formation in formations:\n",
    "    print(f\"starting trainging for formation: {formation}\")\n",
    "    # get training data\n",
    "    formation_train_data = folder_path+f'{formation}/train/'\n",
    "    X_train, y_train,X_val, y_val, mean, std = get_train_data(formation_train_data) \n",
    "    # train model at depth\n",
    "    model = train_model(X_train, y_train,X_val, y_val, learning_rate = 0.001,epochs=200, nodes=4, dropout = 0.5)\n",
    "    models_list.append(model)\n",
    "    current_dir = os.getcwd()\n",
    "    model_path = current_dir + f\"/Model/{formation}/\"\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model.save(model_path)\n",
    "    \n",
    "    # get test data\n",
    "    formation_test_data = folder_path+f'/{formation}/test/'\n",
    "    X_test, y_test, test_dfs = get_test_data(formation_test_data, mean, std)\n",
    "    \n",
    "    # make predictions\n",
    "    for i, df in enumerate(test_dfs):\n",
    "        make_predictions(df,X_test[i],y_test[i], model, formation_test_data)\n",
    "    \n",
    "    model_deltaT_metrics= evaluate_model(test_dfs)\n",
    "    # Store metrics for each delta_T\n",
    "    for delta_T, metrics in model_deltaT_metrics.items():\n",
    "        recall_metrics[delta_T].append(metrics['average_recall'])\n",
    "        precision_metrics[delta_T].append(metrics['average_precision'])\n",
    "        f1_metrics[delta_T].append(metrics['average_f1'])\n",
    "        \n",
    "# Convert dictionaries to pandas DataFrames\n",
    "recall_df = pd.DataFrame(recall_metrics, index=formations)\n",
    "precision_df = pd.DataFrame(precision_metrics, index=formations)\n",
    "f1_df = pd.DataFrame(f1_metrics, index=formations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_54fb9 th {\n",
       "  font-size: 12pt;\n",
       "  text-align: center;\n",
       "  font-weight: bold;\n",
       "  color: Black;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_54fb9 td {\n",
       "  text-align: center;\n",
       "  font-size: 11pt;\n",
       "  color: black;\n",
       "}\n",
       "#T_54fb9 tr:nth-of-type(odd) {\n",
       "  background-color: #f2f2f2;\n",
       "}\n",
       "#T_54fb9 tr:nth-of-type(even) {\n",
       "  background-color: white;\n",
       "}\n",
       "#T_54fb9 tr:hover {\n",
       "  background-color: #ffff99;\n",
       "}\n",
       "#T_54fb9 table {\n",
       "  border-collapse: collapse;\n",
       "  margin: auto;\n",
       "}\n",
       "#T_54fb9 th {\n",
       "  border: 1px solid black;\n",
       "}\n",
       "#T_54fb9  td {\n",
       "  border: 1px solid black;\n",
       "}\n",
       "#T_54fb9 thead {\n",
       "  vertical-align: bottom;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_54fb9 tbody {\n",
       "  vertical-align: middle;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_54fb9 .index_name {\n",
       "  text-align: center;\n",
       "  vertical-align: middle;\n",
       "}\n",
       "#T_54fb9 .col_heading {\n",
       "  text-align: center;\n",
       "  vertical-align: bottom;\n",
       "}\n",
       "#T_54fb9_row0_col0, #T_54fb9_row0_col1, #T_54fb9_row0_col2, #T_54fb9_row0_col3, #T_54fb9_row0_col4, #T_54fb9_row1_col0, #T_54fb9_row1_col1, #T_54fb9_row1_col2, #T_54fb9_row1_col3, #T_54fb9_row1_col4, #T_54fb9_row2_col0, #T_54fb9_row2_col1, #T_54fb9_row2_col2, #T_54fb9_row2_col3, #T_54fb9_row2_col4, #T_54fb9_row3_col0, #T_54fb9_row3_col1, #T_54fb9_row3_col2, #T_54fb9_row3_col3, #T_54fb9_row3_col4, #T_54fb9_row4_col0, #T_54fb9_row4_col1, #T_54fb9_row4_col2, #T_54fb9_row4_col3, #T_54fb9_row4_col4, #T_54fb9_row5_col0, #T_54fb9_row5_col1, #T_54fb9_row5_col2, #T_54fb9_row5_col3, #T_54fb9_row5_col4, #T_54fb9_row6_col0, #T_54fb9_row6_col1, #T_54fb9_row6_col2, #T_54fb9_row6_col3, #T_54fb9_row6_col4, #T_54fb9_row7_col0, #T_54fb9_row7_col1, #T_54fb9_row7_col2, #T_54fb9_row7_col3, #T_54fb9_row7_col4, #T_54fb9_row8_col0, #T_54fb9_row8_col1, #T_54fb9_row8_col2, #T_54fb9_row8_col3, #T_54fb9_row8_col4 {\n",
       "  width: 100px;\n",
       "  height: 30px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_54fb9\">\n",
       "  <caption>Delta T</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_54fb9_level0_col0\" class=\"col_heading level0 col0\" >0.500000</th>\n",
       "      <th id=\"T_54fb9_level0_col1\" class=\"col_heading level0 col1\" >1.000000</th>\n",
       "      <th id=\"T_54fb9_level0_col2\" class=\"col_heading level0 col2\" >2.000000</th>\n",
       "      <th id=\"T_54fb9_level0_col3\" class=\"col_heading level0 col3\" >3.000000</th>\n",
       "      <th id=\"T_54fb9_level0_col4\" class=\"col_heading level0 col4\" >6.000000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_54fb9_level0_row0\" class=\"row_heading level0 row0\" >5000</th>\n",
       "      <td id=\"T_54fb9_row0_col0\" class=\"data row0 col0\" >0.280000</td>\n",
       "      <td id=\"T_54fb9_row0_col1\" class=\"data row0 col1\" >0.480000</td>\n",
       "      <td id=\"T_54fb9_row0_col2\" class=\"data row0 col2\" >0.580000</td>\n",
       "      <td id=\"T_54fb9_row0_col3\" class=\"data row0 col3\" >0.680000</td>\n",
       "      <td id=\"T_54fb9_row0_col4\" class=\"data row0 col4\" >0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54fb9_level0_row1\" class=\"row_heading level0 row1\" >6000</th>\n",
       "      <td id=\"T_54fb9_row1_col0\" class=\"data row1 col0\" >0.200000</td>\n",
       "      <td id=\"T_54fb9_row1_col1\" class=\"data row1 col1\" >0.240000</td>\n",
       "      <td id=\"T_54fb9_row1_col2\" class=\"data row1 col2\" >0.440000</td>\n",
       "      <td id=\"T_54fb9_row1_col3\" class=\"data row1 col3\" >0.520000</td>\n",
       "      <td id=\"T_54fb9_row1_col4\" class=\"data row1 col4\" >0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54fb9_level0_row2\" class=\"row_heading level0 row2\" >7000</th>\n",
       "      <td id=\"T_54fb9_row2_col0\" class=\"data row2 col0\" >0.080000</td>\n",
       "      <td id=\"T_54fb9_row2_col1\" class=\"data row2 col1\" >0.080000</td>\n",
       "      <td id=\"T_54fb9_row2_col2\" class=\"data row2 col2\" >0.240000</td>\n",
       "      <td id=\"T_54fb9_row2_col3\" class=\"data row2 col3\" >0.360000</td>\n",
       "      <td id=\"T_54fb9_row2_col4\" class=\"data row2 col4\" >0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54fb9_level0_row3\" class=\"row_heading level0 row3\" >9000</th>\n",
       "      <td id=\"T_54fb9_row3_col0\" class=\"data row3 col0\" >0.080000</td>\n",
       "      <td id=\"T_54fb9_row3_col1\" class=\"data row3 col1\" >0.140000</td>\n",
       "      <td id=\"T_54fb9_row3_col2\" class=\"data row3 col2\" >0.320000</td>\n",
       "      <td id=\"T_54fb9_row3_col3\" class=\"data row3 col3\" >0.460000</td>\n",
       "      <td id=\"T_54fb9_row3_col4\" class=\"data row3 col4\" >0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54fb9_level0_row4\" class=\"row_heading level0 row4\" >10000</th>\n",
       "      <td id=\"T_54fb9_row4_col0\" class=\"data row4 col0\" >0.040000</td>\n",
       "      <td id=\"T_54fb9_row4_col1\" class=\"data row4 col1\" >0.060000</td>\n",
       "      <td id=\"T_54fb9_row4_col2\" class=\"data row4 col2\" >0.220000</td>\n",
       "      <td id=\"T_54fb9_row4_col3\" class=\"data row4 col3\" >0.320000</td>\n",
       "      <td id=\"T_54fb9_row4_col4\" class=\"data row4 col4\" >0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54fb9_level0_row5\" class=\"row_heading level0 row5\" >11000</th>\n",
       "      <td id=\"T_54fb9_row5_col0\" class=\"data row5 col0\" >0.040000</td>\n",
       "      <td id=\"T_54fb9_row5_col1\" class=\"data row5 col1\" >0.040000</td>\n",
       "      <td id=\"T_54fb9_row5_col2\" class=\"data row5 col2\" >0.160000</td>\n",
       "      <td id=\"T_54fb9_row5_col3\" class=\"data row5 col3\" >0.240000</td>\n",
       "      <td id=\"T_54fb9_row5_col4\" class=\"data row5 col4\" >0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54fb9_level0_row6\" class=\"row_heading level0 row6\" >12000</th>\n",
       "      <td id=\"T_54fb9_row6_col0\" class=\"data row6 col0\" >0.060000</td>\n",
       "      <td id=\"T_54fb9_row6_col1\" class=\"data row6 col1\" >0.140000</td>\n",
       "      <td id=\"T_54fb9_row6_col2\" class=\"data row6 col2\" >0.300000</td>\n",
       "      <td id=\"T_54fb9_row6_col3\" class=\"data row6 col3\" >0.380000</td>\n",
       "      <td id=\"T_54fb9_row6_col4\" class=\"data row6 col4\" >0.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54fb9_level0_row7\" class=\"row_heading level0 row7\" >13000</th>\n",
       "      <td id=\"T_54fb9_row7_col0\" class=\"data row7 col0\" >0.040000</td>\n",
       "      <td id=\"T_54fb9_row7_col1\" class=\"data row7 col1\" >0.060000</td>\n",
       "      <td id=\"T_54fb9_row7_col2\" class=\"data row7 col2\" >0.160000</td>\n",
       "      <td id=\"T_54fb9_row7_col3\" class=\"data row7 col3\" >0.240000</td>\n",
       "      <td id=\"T_54fb9_row7_col4\" class=\"data row7 col4\" >0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54fb9_level0_row8\" class=\"row_heading level0 row8\" >14000</th>\n",
       "      <td id=\"T_54fb9_row8_col0\" class=\"data row8 col0\" >0.260000</td>\n",
       "      <td id=\"T_54fb9_row8_col1\" class=\"data row8 col1\" >0.440000</td>\n",
       "      <td id=\"T_54fb9_row8_col2\" class=\"data row8 col2\" >0.620000</td>\n",
       "      <td id=\"T_54fb9_row8_col3\" class=\"data row8 col3\" >0.680000</td>\n",
       "      <td id=\"T_54fb9_row8_col4\" class=\"data row8 col4\" >0.880000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14fb30669e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ee0c1 th {\n",
       "  font-size: 12pt;\n",
       "  text-align: center;\n",
       "  font-weight: bold;\n",
       "  color: Black;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_ee0c1 td {\n",
       "  text-align: center;\n",
       "  font-size: 11pt;\n",
       "  color: black;\n",
       "}\n",
       "#T_ee0c1 tr:nth-of-type(odd) {\n",
       "  background-color: #f2f2f2;\n",
       "}\n",
       "#T_ee0c1 tr:nth-of-type(even) {\n",
       "  background-color: white;\n",
       "}\n",
       "#T_ee0c1 tr:hover {\n",
       "  background-color: #ffff99;\n",
       "}\n",
       "#T_ee0c1 table {\n",
       "  border-collapse: collapse;\n",
       "  margin: auto;\n",
       "}\n",
       "#T_ee0c1 th {\n",
       "  border: 1px solid black;\n",
       "}\n",
       "#T_ee0c1  td {\n",
       "  border: 1px solid black;\n",
       "}\n",
       "#T_ee0c1 thead {\n",
       "  vertical-align: bottom;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_ee0c1 tbody {\n",
       "  vertical-align: middle;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_ee0c1 .index_name {\n",
       "  text-align: center;\n",
       "  vertical-align: middle;\n",
       "}\n",
       "#T_ee0c1 .col_heading {\n",
       "  text-align: center;\n",
       "  vertical-align: bottom;\n",
       "}\n",
       "#T_ee0c1_row0_col0, #T_ee0c1_row0_col1, #T_ee0c1_row0_col2, #T_ee0c1_row0_col3, #T_ee0c1_row0_col4, #T_ee0c1_row1_col0, #T_ee0c1_row1_col1, #T_ee0c1_row1_col2, #T_ee0c1_row1_col3, #T_ee0c1_row1_col4, #T_ee0c1_row2_col0, #T_ee0c1_row2_col1, #T_ee0c1_row2_col2, #T_ee0c1_row2_col3, #T_ee0c1_row2_col4, #T_ee0c1_row3_col0, #T_ee0c1_row3_col1, #T_ee0c1_row3_col2, #T_ee0c1_row3_col3, #T_ee0c1_row3_col4, #T_ee0c1_row4_col0, #T_ee0c1_row4_col1, #T_ee0c1_row4_col2, #T_ee0c1_row4_col3, #T_ee0c1_row4_col4, #T_ee0c1_row5_col0, #T_ee0c1_row5_col1, #T_ee0c1_row5_col2, #T_ee0c1_row5_col3, #T_ee0c1_row5_col4, #T_ee0c1_row6_col0, #T_ee0c1_row6_col1, #T_ee0c1_row6_col2, #T_ee0c1_row6_col3, #T_ee0c1_row6_col4, #T_ee0c1_row7_col0, #T_ee0c1_row7_col1, #T_ee0c1_row7_col2, #T_ee0c1_row7_col3, #T_ee0c1_row7_col4, #T_ee0c1_row8_col0, #T_ee0c1_row8_col1, #T_ee0c1_row8_col2, #T_ee0c1_row8_col3, #T_ee0c1_row8_col4 {\n",
       "  width: 100px;\n",
       "  height: 30px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ee0c1\">\n",
       "  <caption>Delta T</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ee0c1_level0_col0\" class=\"col_heading level0 col0\" >0.500000</th>\n",
       "      <th id=\"T_ee0c1_level0_col1\" class=\"col_heading level0 col1\" >1.000000</th>\n",
       "      <th id=\"T_ee0c1_level0_col2\" class=\"col_heading level0 col2\" >2.000000</th>\n",
       "      <th id=\"T_ee0c1_level0_col3\" class=\"col_heading level0 col3\" >3.000000</th>\n",
       "      <th id=\"T_ee0c1_level0_col4\" class=\"col_heading level0 col4\" >6.000000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ee0c1_level0_row0\" class=\"row_heading level0 row0\" >5000</th>\n",
       "      <td id=\"T_ee0c1_row0_col0\" class=\"data row0 col0\" >0.280000</td>\n",
       "      <td id=\"T_ee0c1_row0_col1\" class=\"data row0 col1\" >0.480000</td>\n",
       "      <td id=\"T_ee0c1_row0_col2\" class=\"data row0 col2\" >0.580000</td>\n",
       "      <td id=\"T_ee0c1_row0_col3\" class=\"data row0 col3\" >0.680000</td>\n",
       "      <td id=\"T_ee0c1_row0_col4\" class=\"data row0 col4\" >0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee0c1_level0_row1\" class=\"row_heading level0 row1\" >6000</th>\n",
       "      <td id=\"T_ee0c1_row1_col0\" class=\"data row1 col0\" >0.200000</td>\n",
       "      <td id=\"T_ee0c1_row1_col1\" class=\"data row1 col1\" >0.240000</td>\n",
       "      <td id=\"T_ee0c1_row1_col2\" class=\"data row1 col2\" >0.440000</td>\n",
       "      <td id=\"T_ee0c1_row1_col3\" class=\"data row1 col3\" >0.520000</td>\n",
       "      <td id=\"T_ee0c1_row1_col4\" class=\"data row1 col4\" >0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee0c1_level0_row2\" class=\"row_heading level0 row2\" >7000</th>\n",
       "      <td id=\"T_ee0c1_row2_col0\" class=\"data row2 col0\" >0.080000</td>\n",
       "      <td id=\"T_ee0c1_row2_col1\" class=\"data row2 col1\" >0.080000</td>\n",
       "      <td id=\"T_ee0c1_row2_col2\" class=\"data row2 col2\" >0.240000</td>\n",
       "      <td id=\"T_ee0c1_row2_col3\" class=\"data row2 col3\" >0.360000</td>\n",
       "      <td id=\"T_ee0c1_row2_col4\" class=\"data row2 col4\" >0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee0c1_level0_row3\" class=\"row_heading level0 row3\" >9000</th>\n",
       "      <td id=\"T_ee0c1_row3_col0\" class=\"data row3 col0\" >0.080000</td>\n",
       "      <td id=\"T_ee0c1_row3_col1\" class=\"data row3 col1\" >0.140000</td>\n",
       "      <td id=\"T_ee0c1_row3_col2\" class=\"data row3 col2\" >0.320000</td>\n",
       "      <td id=\"T_ee0c1_row3_col3\" class=\"data row3 col3\" >0.460000</td>\n",
       "      <td id=\"T_ee0c1_row3_col4\" class=\"data row3 col4\" >0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee0c1_level0_row4\" class=\"row_heading level0 row4\" >10000</th>\n",
       "      <td id=\"T_ee0c1_row4_col0\" class=\"data row4 col0\" >0.040000</td>\n",
       "      <td id=\"T_ee0c1_row4_col1\" class=\"data row4 col1\" >0.060000</td>\n",
       "      <td id=\"T_ee0c1_row4_col2\" class=\"data row4 col2\" >0.220000</td>\n",
       "      <td id=\"T_ee0c1_row4_col3\" class=\"data row4 col3\" >0.320000</td>\n",
       "      <td id=\"T_ee0c1_row4_col4\" class=\"data row4 col4\" >0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee0c1_level0_row5\" class=\"row_heading level0 row5\" >11000</th>\n",
       "      <td id=\"T_ee0c1_row5_col0\" class=\"data row5 col0\" >0.040000</td>\n",
       "      <td id=\"T_ee0c1_row5_col1\" class=\"data row5 col1\" >0.040000</td>\n",
       "      <td id=\"T_ee0c1_row5_col2\" class=\"data row5 col2\" >0.160000</td>\n",
       "      <td id=\"T_ee0c1_row5_col3\" class=\"data row5 col3\" >0.240000</td>\n",
       "      <td id=\"T_ee0c1_row5_col4\" class=\"data row5 col4\" >0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee0c1_level0_row6\" class=\"row_heading level0 row6\" >12000</th>\n",
       "      <td id=\"T_ee0c1_row6_col0\" class=\"data row6 col0\" >0.060000</td>\n",
       "      <td id=\"T_ee0c1_row6_col1\" class=\"data row6 col1\" >0.140000</td>\n",
       "      <td id=\"T_ee0c1_row6_col2\" class=\"data row6 col2\" >0.300000</td>\n",
       "      <td id=\"T_ee0c1_row6_col3\" class=\"data row6 col3\" >0.380000</td>\n",
       "      <td id=\"T_ee0c1_row6_col4\" class=\"data row6 col4\" >0.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee0c1_level0_row7\" class=\"row_heading level0 row7\" >13000</th>\n",
       "      <td id=\"T_ee0c1_row7_col0\" class=\"data row7 col0\" >0.040000</td>\n",
       "      <td id=\"T_ee0c1_row7_col1\" class=\"data row7 col1\" >0.060000</td>\n",
       "      <td id=\"T_ee0c1_row7_col2\" class=\"data row7 col2\" >0.160000</td>\n",
       "      <td id=\"T_ee0c1_row7_col3\" class=\"data row7 col3\" >0.240000</td>\n",
       "      <td id=\"T_ee0c1_row7_col4\" class=\"data row7 col4\" >0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee0c1_level0_row8\" class=\"row_heading level0 row8\" >14000</th>\n",
       "      <td id=\"T_ee0c1_row8_col0\" class=\"data row8 col0\" >0.260000</td>\n",
       "      <td id=\"T_ee0c1_row8_col1\" class=\"data row8 col1\" >0.440000</td>\n",
       "      <td id=\"T_ee0c1_row8_col2\" class=\"data row8 col2\" >0.620000</td>\n",
       "      <td id=\"T_ee0c1_row8_col3\" class=\"data row8 col3\" >0.680000</td>\n",
       "      <td id=\"T_ee0c1_row8_col4\" class=\"data row8 col4\" >0.880000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14fb3067730>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_283eb th {\n",
       "  font-size: 12pt;\n",
       "  text-align: center;\n",
       "  font-weight: bold;\n",
       "  color: Black;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_283eb td {\n",
       "  text-align: center;\n",
       "  font-size: 11pt;\n",
       "  color: black;\n",
       "}\n",
       "#T_283eb tr:nth-of-type(odd) {\n",
       "  background-color: #f2f2f2;\n",
       "}\n",
       "#T_283eb tr:nth-of-type(even) {\n",
       "  background-color: white;\n",
       "}\n",
       "#T_283eb tr:hover {\n",
       "  background-color: #ffff99;\n",
       "}\n",
       "#T_283eb table {\n",
       "  border-collapse: collapse;\n",
       "  margin: auto;\n",
       "}\n",
       "#T_283eb th {\n",
       "  border: 1px solid black;\n",
       "}\n",
       "#T_283eb  td {\n",
       "  border: 1px solid black;\n",
       "}\n",
       "#T_283eb thead {\n",
       "  vertical-align: bottom;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_283eb tbody {\n",
       "  vertical-align: middle;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_283eb .index_name {\n",
       "  text-align: center;\n",
       "  vertical-align: middle;\n",
       "}\n",
       "#T_283eb .col_heading {\n",
       "  text-align: center;\n",
       "  vertical-align: bottom;\n",
       "}\n",
       "#T_283eb_row0_col0, #T_283eb_row0_col1, #T_283eb_row0_col2, #T_283eb_row0_col3, #T_283eb_row0_col4, #T_283eb_row1_col0, #T_283eb_row1_col1, #T_283eb_row1_col2, #T_283eb_row1_col3, #T_283eb_row1_col4, #T_283eb_row2_col0, #T_283eb_row2_col1, #T_283eb_row2_col2, #T_283eb_row2_col3, #T_283eb_row2_col4, #T_283eb_row3_col0, #T_283eb_row3_col1, #T_283eb_row3_col2, #T_283eb_row3_col3, #T_283eb_row3_col4, #T_283eb_row4_col0, #T_283eb_row4_col1, #T_283eb_row4_col2, #T_283eb_row4_col3, #T_283eb_row4_col4, #T_283eb_row5_col0, #T_283eb_row5_col1, #T_283eb_row5_col2, #T_283eb_row5_col3, #T_283eb_row5_col4, #T_283eb_row6_col0, #T_283eb_row6_col1, #T_283eb_row6_col2, #T_283eb_row6_col3, #T_283eb_row6_col4, #T_283eb_row7_col0, #T_283eb_row7_col1, #T_283eb_row7_col2, #T_283eb_row7_col3, #T_283eb_row7_col4, #T_283eb_row8_col0, #T_283eb_row8_col1, #T_283eb_row8_col2, #T_283eb_row8_col3, #T_283eb_row8_col4 {\n",
       "  width: 100px;\n",
       "  height: 30px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_283eb\">\n",
       "  <caption>Delta T</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_283eb_level0_col0\" class=\"col_heading level0 col0\" >0.500000</th>\n",
       "      <th id=\"T_283eb_level0_col1\" class=\"col_heading level0 col1\" >1.000000</th>\n",
       "      <th id=\"T_283eb_level0_col2\" class=\"col_heading level0 col2\" >2.000000</th>\n",
       "      <th id=\"T_283eb_level0_col3\" class=\"col_heading level0 col3\" >3.000000</th>\n",
       "      <th id=\"T_283eb_level0_col4\" class=\"col_heading level0 col4\" >6.000000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_283eb_level0_row0\" class=\"row_heading level0 row0\" >5000</th>\n",
       "      <td id=\"T_283eb_row0_col0\" class=\"data row0 col0\" >0.280000</td>\n",
       "      <td id=\"T_283eb_row0_col1\" class=\"data row0 col1\" >0.480000</td>\n",
       "      <td id=\"T_283eb_row0_col2\" class=\"data row0 col2\" >0.580000</td>\n",
       "      <td id=\"T_283eb_row0_col3\" class=\"data row0 col3\" >0.680000</td>\n",
       "      <td id=\"T_283eb_row0_col4\" class=\"data row0 col4\" >0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_283eb_level0_row1\" class=\"row_heading level0 row1\" >6000</th>\n",
       "      <td id=\"T_283eb_row1_col0\" class=\"data row1 col0\" >0.200000</td>\n",
       "      <td id=\"T_283eb_row1_col1\" class=\"data row1 col1\" >0.240000</td>\n",
       "      <td id=\"T_283eb_row1_col2\" class=\"data row1 col2\" >0.440000</td>\n",
       "      <td id=\"T_283eb_row1_col3\" class=\"data row1 col3\" >0.520000</td>\n",
       "      <td id=\"T_283eb_row1_col4\" class=\"data row1 col4\" >0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_283eb_level0_row2\" class=\"row_heading level0 row2\" >7000</th>\n",
       "      <td id=\"T_283eb_row2_col0\" class=\"data row2 col0\" >0.080000</td>\n",
       "      <td id=\"T_283eb_row2_col1\" class=\"data row2 col1\" >0.080000</td>\n",
       "      <td id=\"T_283eb_row2_col2\" class=\"data row2 col2\" >0.240000</td>\n",
       "      <td id=\"T_283eb_row2_col3\" class=\"data row2 col3\" >0.360000</td>\n",
       "      <td id=\"T_283eb_row2_col4\" class=\"data row2 col4\" >0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_283eb_level0_row3\" class=\"row_heading level0 row3\" >9000</th>\n",
       "      <td id=\"T_283eb_row3_col0\" class=\"data row3 col0\" >0.080000</td>\n",
       "      <td id=\"T_283eb_row3_col1\" class=\"data row3 col1\" >0.140000</td>\n",
       "      <td id=\"T_283eb_row3_col2\" class=\"data row3 col2\" >0.320000</td>\n",
       "      <td id=\"T_283eb_row3_col3\" class=\"data row3 col3\" >0.460000</td>\n",
       "      <td id=\"T_283eb_row3_col4\" class=\"data row3 col4\" >0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_283eb_level0_row4\" class=\"row_heading level0 row4\" >10000</th>\n",
       "      <td id=\"T_283eb_row4_col0\" class=\"data row4 col0\" >0.040000</td>\n",
       "      <td id=\"T_283eb_row4_col1\" class=\"data row4 col1\" >0.060000</td>\n",
       "      <td id=\"T_283eb_row4_col2\" class=\"data row4 col2\" >0.220000</td>\n",
       "      <td id=\"T_283eb_row4_col3\" class=\"data row4 col3\" >0.320000</td>\n",
       "      <td id=\"T_283eb_row4_col4\" class=\"data row4 col4\" >0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_283eb_level0_row5\" class=\"row_heading level0 row5\" >11000</th>\n",
       "      <td id=\"T_283eb_row5_col0\" class=\"data row5 col0\" >0.040000</td>\n",
       "      <td id=\"T_283eb_row5_col1\" class=\"data row5 col1\" >0.040000</td>\n",
       "      <td id=\"T_283eb_row5_col2\" class=\"data row5 col2\" >0.160000</td>\n",
       "      <td id=\"T_283eb_row5_col3\" class=\"data row5 col3\" >0.240000</td>\n",
       "      <td id=\"T_283eb_row5_col4\" class=\"data row5 col4\" >0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_283eb_level0_row6\" class=\"row_heading level0 row6\" >12000</th>\n",
       "      <td id=\"T_283eb_row6_col0\" class=\"data row6 col0\" >0.060000</td>\n",
       "      <td id=\"T_283eb_row6_col1\" class=\"data row6 col1\" >0.140000</td>\n",
       "      <td id=\"T_283eb_row6_col2\" class=\"data row6 col2\" >0.300000</td>\n",
       "      <td id=\"T_283eb_row6_col3\" class=\"data row6 col3\" >0.380000</td>\n",
       "      <td id=\"T_283eb_row6_col4\" class=\"data row6 col4\" >0.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_283eb_level0_row7\" class=\"row_heading level0 row7\" >13000</th>\n",
       "      <td id=\"T_283eb_row7_col0\" class=\"data row7 col0\" >0.040000</td>\n",
       "      <td id=\"T_283eb_row7_col1\" class=\"data row7 col1\" >0.060000</td>\n",
       "      <td id=\"T_283eb_row7_col2\" class=\"data row7 col2\" >0.160000</td>\n",
       "      <td id=\"T_283eb_row7_col3\" class=\"data row7 col3\" >0.240000</td>\n",
       "      <td id=\"T_283eb_row7_col4\" class=\"data row7 col4\" >0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_283eb_level0_row8\" class=\"row_heading level0 row8\" >14000</th>\n",
       "      <td id=\"T_283eb_row8_col0\" class=\"data row8 col0\" >0.260000</td>\n",
       "      <td id=\"T_283eb_row8_col1\" class=\"data row8 col1\" >0.440000</td>\n",
       "      <td id=\"T_283eb_row8_col2\" class=\"data row8 col2\" >0.620000</td>\n",
       "      <td id=\"T_283eb_row8_col3\" class=\"data row8 col3\" >0.680000</td>\n",
       "      <td id=\"T_283eb_row8_col4\" class=\"data row8 col4\" >0.880000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14fb3064700>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def style_dataframe(df, title):\n",
    "    styled_df = df.style.set_table_styles(\n",
    "        [{'selector': 'th', 'props': [('font-size', '12pt'), ('text-align', 'center'), ('font-weight', 'bold'), ('color', 'Black'), ('background-color', 'lightgrey')]},\n",
    "         {'selector': 'td', 'props': [('text-align', 'center'), ('font-size', '11pt'), ('color', 'black')]},  # Text color set to black\n",
    "         {'selector': 'tr:nth-of-type(odd)', 'props': [('background-color', '#f2f2f2')]},\n",
    "         {'selector': 'tr:nth-of-type(even)', 'props': [('background-color', 'white')]},\n",
    "         {'selector': 'tr:hover', 'props': [('background-color', '#ffff99')]},\n",
    "         {'selector': 'table', 'props': [('border-collapse', 'collapse'), ('margin', 'auto')]},\n",
    "         {'selector': 'th, td', 'props': [('border', '1px solid black')]}]\n",
    "    ).set_properties(**{'width': '100px', 'height': '30px'}).set_caption(\"Delta T\")\n",
    "\n",
    "    # Custom CSS for positioning the index and column labels\n",
    "    styled_df = styled_df.set_table_styles([\n",
    "        {'selector': 'thead', 'props': [('vertical-align', 'bottom'), ('text-align', 'center')]},\n",
    "        {'selector': 'tbody', 'props': [('vertical-align', 'middle'), ('text-align', 'center')]},\n",
    "        {'selector': '.index_name', 'props': [('text-align', 'center'), ('vertical-align', 'middle')]},\n",
    "        {'selector': '.col_heading', 'props': [('text-align', 'center'), ('vertical-align', 'bottom')]}\n",
    "    ], overwrite=False, axis=0)\n",
    "\n",
    "    return styled_df\n",
    "\n",
    "# Apply styling to the DataFrames with titles\n",
    "styled_recall_df = style_dataframe(recall_df, \"Recall\")\n",
    "styled_precision_df = style_dataframe(precision_df, \"Precision\")\n",
    "styled_f1_df = style_dataframe(f1_df, \"F1\")\n",
    "\n",
    "# Display the styled DataFrames\n",
    "display(styled_recall_df)\n",
    "display(styled_precision_df)\n",
    "display(styled_f1_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_dir = os.getcwd()\n",
    "# # Train your model here\n",
    "# model_path = current_dir + \"/Model/\"\n",
    "\n",
    "# # Load the model\n",
    "# loaded_model = load_model(model_path, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming y_test is a list of 2D arrays with shape (n, 1)\n",
    "# y_test_smoothed = [smooth_labels(y, sigma=2) for y in y_test]\n",
    "\n",
    "# # Example usage\n",
    "# z_test = y_test[0].flatten()  # Flatten the array to 1D\n",
    "# smoothed_z_test = smooth_labels(z_test, sigma=2) # Flatten the smoothed labels to 1D\n",
    "\n",
    "# # Plot the results\n",
    "# plt.plot(y_test[0], label='Original Labels')\n",
    "# plt.plot(y_test_smoothed[0], label='Smoothed Labels')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # Define the range around the pick to focus on\n",
    "# focus_index = 15  # Index of the pick\n",
    "# range_around_pick = 10  # Number of indices to include on either side\n",
    "\n",
    "# # Plot the results focusing on the specified range\n",
    "# plt.figure(figsize=(10, 5))  # Increase figure size for better visibility\n",
    "# plt.plot(range(focus_index - range_around_pick, focus_index + range_around_pick + 1),\n",
    "#          y_test[0][focus_index - range_around_pick:focus_index + range_around_pick + 1],\n",
    "#          label='Original Labels')\n",
    "# plt.plot(range(focus_index - range_around_pick, focus_index + range_around_pick + 1),\n",
    "#          y_test_smoothed[0][focus_index - range_around_pick:focus_index + range_around_pick + 1],\n",
    "#          label='Smoothed Labels')\n",
    "# plt.legend()\n",
    "# plt.title(f\"Labels around index {focus_index}\")\n",
    "# plt.xlabel(\"Index\")\n",
    "# plt.ylabel(\"Label Value\")\n",
    "# plt.show()\n",
    "\n",
    "# print(max(y_test[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
